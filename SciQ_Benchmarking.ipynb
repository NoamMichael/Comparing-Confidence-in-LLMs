{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoamMichael/Comparing-Confidence-in-LLMs/blob/main/SciQ_Benchmarking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0I2ngJk9k04h"
      },
      "outputs": [],
      "source": [
        "# This Notebook will test all models on the formatted SciQ dataset\n",
        "# I have no issue running multiple API clients simultaneously. However, running\n",
        "# local models is pretty memory intensive so I can only run one at a time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmQ6Idu_k9sy",
        "outputId": "90db6031-82c8-4bfd-ec42-006225fdbb4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: anthropic in /usr/local/lib/python3.11/dist-packages (0.55.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.14.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.91.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install anthropic\n",
        "%pip install openai\n",
        "%pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_1NgpUiXk_ou"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import (AutoTokenizer,\n",
        "                        AutoModelForCausalLM,\n",
        "                        BitsAndBytesConfig,\n",
        "                        pipeline)\n",
        "import warnings\n",
        "import openai\n",
        "import anthropic\n",
        "import google.generativeai as genai\n",
        "from abc import ABC, abstractmethod\n",
        "from tqdm.notebook import tqdm\n",
        "warnings.filterwarnings('ignore')\n",
        "from google.colab import userdata\n",
        "import os\n",
        "from google.colab import drive\n",
        "max_tokens = 150\n",
        "\n",
        "\n",
        "\n",
        "class ClosedModel(ABC):\n",
        "  @abstractmethod\n",
        "  def generate(self, prompt: str, system:str = \"\")-> str:\n",
        "        \"\"\"\n",
        "        Abstract method to generate a response from the language model.\n",
        "        \"\"\"\n",
        "        pass\n",
        "  @abstractmethod\n",
        "  def __init__(self, name, api_key):\n",
        "    self.name = name\n",
        "    self.key = api_key\n",
        "    self.results = pd.DataFrame(columns = ['Question ID','Question', 'Answer', 'Reasoning', 'Error'])\n",
        "    pass\n",
        "\n",
        "  @abstractmethod\n",
        "  def client(self):\n",
        "    pass\n",
        "\n",
        "  @abstractmethod\n",
        "  def GetRAC(self, prompt: str, system1:str = \"\", system2: str = \"\")-> tuple[str, str]: ## Get Reasoning Answer Confidence\n",
        "    pass\n",
        "\n",
        "class GPTmodel(ClosedModel):\n",
        "  def __init__(self, name, api_key):\n",
        "    self.name = name\n",
        "    self.key = api_key\n",
        "    self.results = pd.DataFrame(columns = ['Question ID','Question', 'Answer', 'Reasoning', 'Error'])\n",
        "  def client(self):\n",
        "    # Initialize the OpenAI client with the API key\n",
        "    self.client = openai.OpenAI(api_key=self.key)\n",
        "\n",
        "\n",
        "  def generate(self, prompt: str, system: str = \"\") -> str:\n",
        "    # Use the new client-based API call\n",
        "    response = self.client.chat.completions.create(\n",
        "        model=self.name,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0,\n",
        "        max_tokens= max_tokens\n",
        "    )\n",
        "    # Access the content from the new response object structure\n",
        "    return response.choices[0].message.content\n",
        "  def GetRAC(self, prompt: str)-> tuple[str, str]: ## Get Reasoning Answer Confidence\n",
        "    ## For context here's the two system prompts:\n",
        "    ## System prompt 1:\n",
        "    '''\n",
        "    Given the following question, analyze the options, and provide a concise reasoning for your selected answer. Your reasoning should not exceed 100 words. After your explanation, clearly state your answer by choosing one of the options listed (A, B, C, D, or E).\n",
        "\n",
        "    Question: ${Question}\n",
        "    Options:\n",
        "    A) ${Option A}\n",
        "    B) ${Option B}\n",
        "    C) ${Option C}\n",
        "    D) ${Option D}\n",
        "    E) ${Option E}\n",
        "\n",
        "    Please provide your reasoning first, limited to 100 words, and then conclusively state only your selected answer using the corresponding letter (A, B, C, D, or E).\n",
        "    Reasoning: <Your concise reasoning here. Max 100 words>\n",
        "    '''\n",
        "\n",
        "    ## System prompt 2:\n",
        "    '''\n",
        "    Based on your reasoning, select the most likely answer choice and estimate the probability that each option is correct. Express your uncertainty by assigning probabilities between 0.0 and 1.0 in a JSON format. The probabilities should sum to 1.0. For example:\n",
        "\n",
        "    {\n",
        "    'Answer': <Your answer choice here, as a single letter and nothing else.>\n",
        "    'A': <Probability choice A is correct. As a float from 0.0 to 1.0>,\n",
        "    'B': <Probability choice B is correct. As a float from 0.0 to 1.0>,\n",
        "    'C': <Probability choice C is correct. As a float from 0.0 to 1.0>,\n",
        "    'D': <Probability choice D is correct. As a float from 0.0 to 1.0>,\n",
        "    'E': <Probability choice E is correct. As a float from 0.0 to 1.0>\n",
        "    }\n",
        "    '''\n",
        "    # Access global system prompts\n",
        "    global sys_prompt1, sys_prompt2\n",
        "    ## Get the reasoning\n",
        "    reasoning = self.generate(prompt, sys_prompt1)\n",
        "    ## Get the answer and confidence\n",
        "    answer_confidence = self.generate(prompt + reasoning + sys_prompt2, sys_prompt2)\n",
        "\n",
        "    return reasoning, answer_confidence\n",
        "\n",
        "class AnthropicModel(ClosedModel):\n",
        "  def __init__(self, name, api_key):\n",
        "    self.name = name\n",
        "    self.key = api_key\n",
        "    self.results = pd.DataFrame(columns = ['Question ID','Question', 'Answer', 'Reasoning', 'Error'])\n",
        "  def client(self):\n",
        "    # Initialize the Anthropic client with the API key\n",
        "    self.client = anthropic.Anthropic(api_key=self.key)\n",
        "\n",
        "  def generate(self, prompt: str, system: str = \"\") -> str:\n",
        "    # The messages list should only contain user and assistant roles\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "    # Use the Anthropic client to create a message\n",
        "    # Pass the system message as a top-level 'system' parameter\n",
        "    message = self.client.messages.create(\n",
        "        model=self.name,\n",
        "        max_tokens= max_tokens, # You can adjust this or make it an instance variable\n",
        "        messages=messages,\n",
        "        system=system if system else None # Pass system as a separate parameter, or None if empty\n",
        "    )\n",
        "    # Access the content from the response object\n",
        "    return message.content[0].text\n",
        "\n",
        "  def GetRAC(self, prompt: str)-> tuple[str, str]: ## Get Reasoning Answer Confidence\n",
        "    # Access global system prompts\n",
        "    global sys_prompt1, sys_prompt2\n",
        "    ## Get the reasoning\n",
        "    reasoning = self.generate(prompt, sys_prompt1)\n",
        "    ## Get the answer and confidence\n",
        "    answer_confidence = self.generate(prompt + reasoning + sys_prompt2, sys_prompt2)\n",
        "\n",
        "    return reasoning, answer_confidence\n",
        "class GeminiModel(ClosedModel):\n",
        "  def __init__(self, name, api_key):\n",
        "    self.name = name\n",
        "    self.key = api_key\n",
        "    self.results = pd.DataFrame(columns = ['Question ID','Question', 'Answer', 'Reasoning', 'Error'])\n",
        "\n",
        "  def client(self):\n",
        "    # Initialize the google.generativeai client with the API key\n",
        "\n",
        "    genai.configure(api_key=self.key)\n",
        "    self.model = genai.GenerativeModel(model_name=self.name)\n",
        "\n",
        "  def generate(self, prompt: str, system: str = \"\") -> str:\n",
        "    # Build the content list, including the system message if provided\n",
        "    contents = [{\"role\": \"user\", \"parts\": [prompt]}]\n",
        "    if system:\n",
        "        contents = [{\"role\": \"user\", \"parts\": [system]}] + contents\n",
        "\n",
        "    # Use the Gemini model to generate content\n",
        "    response = self.model.generate_content(contents)\n",
        "\n",
        "    # Access the content from the response object\n",
        "    return response.text\n",
        "\n",
        "  def GetRAC(self, prompt: str)-> tuple[str, str]: ## Get Reasoning Answer Confidence\n",
        "    # Access global system prompts\n",
        "    global sys_prompt1, sys_prompt2\n",
        "    ## Get the reasoning\n",
        "    reasoning = self.generate(prompt, sys_prompt1)\n",
        "    ## Get the answer and confidence\n",
        "    answer_confidence = self.generate(prompt + reasoning + sys_prompt2, sys_prompt2)\n",
        "\n",
        "    return reasoning, answer_confidence\n",
        "\n",
        "## %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "##                        Classes for Open Models\n",
        "## %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "\n",
        "class OpenModel(ABC):\n",
        "  @abstractmethod\n",
        "  def __init__(self, name, key, MaxTokens = max_tokens):\n",
        "    pass\n",
        "\n",
        "  @abstractmethod\n",
        "  def generate(self, prompt):\n",
        "    pass\n",
        "\n",
        "  @abstractmethod\n",
        "  def GetTokens(self, prompt):\n",
        "    pass\n",
        "\n",
        "  @abstractmethod\n",
        "  def GetRAC(self, prompt):\n",
        "    pass\n",
        "\n",
        "class LlamaModel(OpenModel): ## This class is built around Hugging Face methods\n",
        "  def __init__(self, name, key, MaxTokens = 150):\n",
        "    self.name = name\n",
        "    self.key = key\n",
        "    self.MaxTokens = MaxTokens\n",
        "    print(f\"Downloading Tokenizer for {self.name}\")\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(self.name,token = self.key) ## Import Tokenizer\n",
        "    print(f\"Downloading Model Weights for {self.name}\")\n",
        "    self.model = AutoModelForCausalLM.from_pretrained(self.name, token = self.key, device_map=\"auto\") ## Import Model\n",
        "    self.results = pd.DataFrame(columns = ['Question ID','Question', 'Answer', 'Reasoning', 'Token Probability', 'Error'])\n",
        "    ## Make text generation pipeline\n",
        "    self.pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model = self.model,\n",
        "    tokenizer = self.tokenizer,\n",
        "    do_sample = False,\n",
        "    max_new_tokens = self.MaxTokens,\n",
        "    eos_token_id = self.tokenizer.eos_token_id,\n",
        "    pad_token_id = self.tokenizer.eos_token_id,\n",
        "    device_map=\"auto\",\n",
        "    transformers_version=\"4.37.0\",\n",
        "    )\n",
        "\n",
        "\n",
        "  def generate(self, prompt):\n",
        "\n",
        "    new_prompt = (\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\"\n",
        "                  + 'You are a helpful assistant. When prompted for a response give your reasoning and answer to the user. Signify your answer with this response:\\n\"Therefore, the correct answer is:\\n<|eot_id|>\"'\n",
        "                  + \"\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\"\n",
        "                  + prompt\n",
        "                  + \"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\")\n",
        "    return self.pipeline(prompt)[0]['generated_text'].replace(prompt, '')\n",
        "\n",
        "  def GetTokens(self, prompt: str):\n",
        "    ## Get Answer:\n",
        "    batch = self.tokenizer(prompt, return_tensors= \"pt\").to('cuda')\n",
        "    with torch.no_grad():\n",
        "        outputs = self.model(**batch)\n",
        "    ## Get Token Probabilites\n",
        "    logits = outputs.logits\n",
        "\n",
        "    ## Apply softmax to the logits to get probabilities\n",
        "    probs = torch.softmax(logits[0, -1], dim=0)\n",
        "\n",
        "    ##Get the top k token indices and their probabilities\n",
        "    top_k_probs, top_k_indices = torch.topk(probs, 100, sorted =True)\n",
        "\n",
        "    ## Convert token indices to tokens\n",
        "    top_k_tokens = [self.tokenizer.decode([token_id]) for token_id in top_k_indices]\n",
        "\n",
        "    ## Convert probabilities to list of floats\n",
        "    top_k_probs = top_k_probs.tolist()                  #list of probabilities\n",
        "\n",
        "    ## Create a Pandas Series with tokens as index and probabilities as values\n",
        "    global logit_series\n",
        "    logit_series = pd.Series(top_k_probs, index=top_k_tokens)\n",
        "\n",
        "    ## Sort the series by values in descending order\n",
        "    logit_series = logit_series.sort_values(ascending=False)\n",
        "    ## Get the answer Letter\n",
        "    target_tokens = [' A', ' B', ' C', ' D', ' E', 'A', 'B', 'C', 'D', 'E']\n",
        "\n",
        "    only_target_tokens = logit_series[logit_series.index.isin(target_tokens)]\n",
        "    best_answer = only_target_tokens.index[0]\n",
        "\n",
        "    ## Format logit series\n",
        "    logit_series.index.name = \"Token\"\n",
        "    logit_series.name = \"Probability\"\n",
        "    return str(logit_series.to_dict()), best_answer.strip()\n",
        "\n",
        "  def GetRAC(self, prompt: str)-> tuple[str, str]: ## Get Reasoning Answer/Confidence\n",
        "    ## Get the reasoning\n",
        "    new_prompt = (\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\"\n",
        "                  + sys_prompt1\n",
        "                  + \"\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\"\n",
        "                  + prompt\n",
        "                  + \"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\")\n",
        "    reasoning = self.generate(new_prompt).replace(new_prompt, '')\n",
        "    ## Get the answer and confidence\n",
        "    answer_confidence = self.generate(new_prompt\n",
        "                                      + reasoning\n",
        "                                      + '<|eot_id|><|start_header_id|>user<|end_header_id|>'\n",
        "                                      + sys_prompt2\n",
        "                                      + '<|eot_id|><|start_header_id|>assistant<|end_header_id|>' )\n",
        "\n",
        "    return reasoning, answer_confidence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k68HsBM6lCkS"
      },
      "outputs": [],
      "source": [
        "{\n",
        "  \"cells\": [\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"view-in-github\",\n",
        "        \"colab_type\": \"text\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"<a href=\\\"https://colab.research.google.com/github/NoamMichael/Comparing-Confidence-in-LLMs/blob/main/SciQ_Benchmarking.ipynb\\\" target=\\\"_parent\\\"><img src=\\\"https://colab.research.google.com/assets/colab-badge.svg\\\" alt=\\\"Open In Colab\\\"/></a>\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"id\": \"0I2ngJk9k04h\"\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"# This Notebook will test all models on the formatted SciQ dataset\\n\",\n",
        "        \"# I have no issue running multiple API clients simultaneously. However, running\\n\",\n",
        "        \"# local models is pretty memory intensive so I can only run one at a time.\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": 2,\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\"\n",
        "        },\n",
        "        \"id\": \"BmQ6Idu_k9sy\",\n",
        "        \"outputId\": \"90db6031-82c8-4bfd-ec42-006225fdbb4c\"\n",
        "      },\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"Requirement already satisfied: anthropic in /usr/local/lib/python3.11/dist-packages (0.55.0)\\n\",\n",
        "            \"Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.9.0)\\n\",\n",
        "            \"Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\\n\",\n",
        "            \"Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\\n\",\n",
        "            \"Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.10.0)\\n\",\n",
        "            \"Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (2.11.7)\\n\",\n",
        "            \"Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\\n\",\n",
        "            \"Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.14.0)\\n\",\n",
        "            \"Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\\n\",\n",
        "            \"Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (2025.6.15)\\n\",\n",
        "            \"Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\\n\",\n",
        "            \"Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\\n\",\n",
        "            \"Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\\n\",\n",
        "            \"Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.2)\\n\",\n",
        "            \"Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.1)\\n\",\n",
        "            \"Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.91.0)\\n\",\n",
        "            \"Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\\n\",\n",
        "            \"Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\\n\",\n",
        "            \"Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\\n\",\n",
        "            \"Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\\n\",\n",
        "            \"Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\\n\",\n",
        "            \"Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\\n\",\n",
        "            \"Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\\n\",\n",
        "            \"Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\\n\",\n",
        "            \"Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\\n\",\n",
        "            \"Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\\n\",\n",
        "            \"Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\\n\",\n",
        "            \"Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\\n\",\n",
        "            \"Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\\n\",\n",
        "            \"Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\\n\",\n",
        "            \"Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\\n\",\n",
        "            \"Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\\n\"\n",
        "          ]\n",
        "        }\n",
        "      ],\n",
        "      \"source\": [\n",
        "        \"%pip install anthropic\\n\",\n",
        "        \"%pip install openai\\n\",\n",
        "        \"%pip install tqdm\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": 11,\n",
        "      \"metadata\": {\n",
        "        \"id\": \"_1NgpUiXk_ou\"\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"import pandas as pd\\n\",\n",
        "        \"import numpy as np\\n\",\n",
        "        \"import json\\n\",\n",
        "        \"import time\\n\",\n",
        "        \"import random\\n\",\n",
        "        \"import torch\\n\",\n",
        "        \"import matplotlib.pyplot as plt\\n\",\n",
        "        \"from transformers import (AutoTokenizer,\\n\",\n",
        "        \"                        AutoModelForCausalLM,\\n\",\n",
        "        \"                        BitsAndBytesConfig,\\n\",\n",
        "        \"                        pipeline)\\n\",\n",
        "        \"import warnings\\n\",\n",
        "        \"import openai\\n\",\n",
        "        \"import anthropic\\n\",\n",
        "        \"import google.generativeai as genai\\n\",\n",
        "        \"from abc import ABC, abstractmethod\\n\",\n",
        "        \"from tqdm.notebook import tqdm\\n\",\n",
        "        \"warnings.filterwarnings('ignore')\\n\",\n",
        "        \"from google.colab import userdata\\n\",\n",
        "        \"import os\\n\",\n",
        "        \"from google.colab import drive\\n\",\n",
        "        \"max_tokens = 150\\n\",\n",
        "        \"\\n\",\n",
        "        \"\\n\",\n",
        "        \"\\n\",\n",
        "        \"class ClosedModel(ABC):\\n\",\n",
        "        \"  @abstractmethod\\n\",\n",
        "        \"  def generate(self, prompt: str, system:str = \\\"\\\")-> str:\\n\",\n",
        "        \"        \\\"\\\"\\\"\\n\",\n",
        "        \"        Abstract method to generate a response from the language model.\\n\",\n",
        "        \"        \\\"\\\"\\\"\\n\",\n",
        "        \"        pass\\n\",\n",
        "        \"  @abstractmethod\\n\",\n",
        "        \"  def __init__(self, name, api_key):\\n\",\n",
        "        \"    self.name = name\\n\",\n",
        "        \"    self.key = api_key\\n\",\n",
        "        \"    self.results = pd.DataFrame(columns = ['Question ID','Question', 'Answer', 'Reasoning', 'Error'])\\n\",\n",
        "        \"    pass\\n\",\n",
        "        \"\\n\",\n",
        "        \"  @abstractmethod\\n\",\n",
        "        \"  def client(self):\\n\",\n",
        "        \"    pass\\n\",\n",
        "        \"\\n\",\n",
        "        \"  @abstractmethod\\n\",\n",
        "        \"  def GetRAC(self, prompt: str, system1:str = \\\"\\\", system2: str = \\\"\\\")-> tuple[str, str]: ## Get Reasoning Answer Confidence\\n\",\n",
        "        \"    pass\\n\",\n",
        "        \"\\n\",\n",
        "        \"class GPTmodel(ClosedModel):\\n\",\n",
        "        \"  def __init__(self, name, api_key):\\n\",\n",
        "        \"    self.name = name\\n\",\n",
        "        \"    self.key = api_key\\n\",\n",
        "        \"    self.results = pd.DataFrame(columns = ['Question ID','Question', 'Answer', 'Reasoning', 'Error'])\\n\",\n",
        "        \"  def client(self):\\n\",\n",
        "        \"    # Initialize the OpenAI client with the API key\\n\",\n",
        "        \"    self.client = openai.OpenAI(api_key=self.key)\\n\",\n",
        "        \"\\n\",\n",
        "        \"\\n\",\n",
        "        \"  def generate(self, prompt: str, system: str = \\\"\\\") -> str:\\n\",\n",
        "        \"    # Use the new client-based API call\\n\",\n",
        "        \"    response = self.client.chat.completions.create(\\n\",\n",
        "        \"        model=self.name,\\n\",\n",
        "        \"        messages=[\\n\",\n",
        "        \"            {\\\"role\\\": \\\"system\\\", \\\"content\\\": system},\\n\",\n",
        "        \"            {\\\"role\\\": \\\"user\\\", \\\"content\\\": prompt}\\n\",\n",
        "        \"        ],\\n\",\n",
        "        \"        temperature=0,\\n\",\n",
        "        \"        max_tokens= max_tokens\\n\",\n",
        "        \"    )\\n\",\n",
        "        \"    # Access the content from the new response object structure\\n\",\n",
        "        \"    return response.choices[0].message.content\\n\",\n",
        "        \"  def GetRAC(self, prompt: str)-> tuple[str, str]: ## Get Reasoning Answer Confidence\\n\",\n",
        "        \"    ## For context here's the two system prompts:\\n\",\n",
        "        \"    ## System prompt 1:\\n\",\n",
        "        \"    '''\\n\",\n",
        "        \"    Given the following question, analyze the options, and provide a concise reasoning for your selected answer. Your reasoning should not exceed 100 words. After your explanation, clearly state your answer by choosing one of the options listed (A, B, C, D, or E).\\n\",\n",
        "        \"\\n\",\n",
        "        \"    Question: ${Question}\\n\",\n",
        "        \"    Options:\\n\",\n",
        "        \"    A) ${Option A}\\n\",\n",
        "        \"    B) ${Option B}\\n\",\n",
        "        \"    C) ${Option C}\\n\",\n",
        "        \"    D) ${Option D}\\n\",\n",
        "        \"    E) ${Option E}\\n\",\n",
        "        \"\\n\",\n",
        "        \"    Please provide your reasoning first, limited to 100 words, and then conclusively state only your selected answer using the corresponding letter (A, B, C, D, or E).\\n\",\n",
        "        \"    Reasoning: <Your concise reasoning here. Max 100 words>\\n\",\n",
        "        \"    '''\\n\",\n",
        "        \"\\n\",\n",
        "        \"    ## System prompt 2:\\n\",\n",
        "        \"    '''\\n\",\n",
        "        \"    Based on your reasoning, select the most likely answer choice and estimate the probability that each option is correct. Express your uncertainty by assigning probabilities between 0.0 and 1.0 in a JSON format. The probabilities should sum to 1.0. For example:\\n\",\n",
        "        \"\\n\",\n",
        "        \"    {\\n\",\n",
        "        \"    'Answer': <Your answer choice here, as a single letter and nothing else.>\\n\",\n",
        "        \"    'A': <Probability choice A is correct. As a float from 0.0 to 1.0>,\\n\",\n",
        "        \"    'B': <Probability choice B is correct. As a float from 0.0 to 1.0>,\\n\",\n",
        "        \"    'C': <Probability choice C is correct. As a float from 0.0 to 1.0>,\\n\",\n",
        "        \"    'D': <Probability choice D is correct. As a float from 0.0 to 1.0>,\\n\",\n",
        "        \"    'E': <Probability choice E is correct. As a float from 0.0 to 1.0>\\n\",\n",
        "        \"    }\\n\",\n",
        "        \"    '''\\n\",\n",
        "        \"    # Access global system prompts\\n\",\n",
        "        \"    global sys_prompt1, sys_prompt2\\n\",\n",
        "        \"    ## Get the reasoning\\n\",\n",
        "        \"    reasoning = self.generate(prompt, sys_prompt1)\\n\",\n",
        "        \"    ## Get the answer and confidence\\n\",\n",
        "        \"    answer_confidence = self.generate(prompt + reasoning + sys_prompt2, sys_prompt2)\\n\",\n",
        "        \"\\n\",\n",
        "        \"    return reasoning, answer_confidence\\n\",\n",
        "        \"\\n\",\n",
        "        \"class AnthropicModel(ClosedModel):\\n\",\n",
        "        \"  def __init__(self, name, api_key):\\n\",\n",
        "        \"    self.name = name\\n\",\n",
        "        \"    self.key = api_key\\n\",\n",
        "        \"    self.results = pd.DataFrame(columns = ['Question ID','Question', 'Answer', 'Reasoning', 'Error'])\\n\",\n",
        "        \"  def client(self):\\n\",\n",
        "        \"    # Initialize the Anthropic client with the API key\\n\",\n",
        "        \"    self.client = anthropic.Anthropic(api_key=self.key)\\n\",\n",
        "        \"\\n\",\n",
        "        \"  def generate(self, prompt: str, system: str = \\\"\\\") -> str:\\n\",\n",
        "        \"    # The messages list should only contain user and assistant roles\\n\",\n",
        "        \"    messages = [{\\\"role\\\": \\\"user\\\", \\\"content\\\": prompt}]\\n\",\n",
        "        \"\\n\",\n",
        "        \"    # Use the Anthropic client to create a message\\n\",\n",
        "        \"    # Pass the system message as a top-level 'system' parameter\\n\",\n",
        "        \"    message = self.client.messages.create(\\n\",\n",
        "        \"        model=self.name,\\n\",\n",
        "        \"        max_tokens= max_tokens, # You can adjust this or make it an instance variable\\n\",\n",
        "        \"        messages=messages,\\n\",\n",
        "        \"        system=system if system else None # Pass system as a separate parameter, or None if empty\\n\",\n",
        "        \"    )\\n\",\n",
        "        \"    # Access the content from the response object\\n\",\n",
        "        \"    return message.content[0].text\\n\",\n",
        "        \"\\n\",\n",
        "        \"  def GetRAC(self, prompt: str)-> tuple[str, str]: ## Get Reasoning Answer Confidence\\n\",\n",
        "        \"    # Access global system prompts\\n\",\n",
        "        \"    global sys_prompt1, sys_prompt2\\n\",\n",
        "        \"    ## Get the reasoning\\n\",\n",
        "        \"    reasoning = self.generate(prompt, sys_prompt1)\\n\",\n",
        "        \"    ## Get the answer and confidence\\n\",\n",
        "        \"    answer_confidence = self.generate(prompt + reasoning + sys_prompt2, sys_prompt2)\\n\",\n",
        "        \"\\n\",\n",
        "        \"    return reasoning, answer_confidence\\n\",\n",
        "        \"class GeminiModel(ClosedModel):\\n\",\n",
        "        \"  def __init__(self, name, api_key):\\n\",\n",
        "        \"    self.name = name\\n\",\n",
        "        \"    self.key = api_key\\n\",\n",
        "        \"    self.results = pd.DataFrame(columns = ['Question ID','Question', 'Answer', 'Reasoning', 'Error'])\\n\",\n",
        "        \"\\n\",\n",
        "        \"  def client(self):\\n\",\n",
        "        \"    # Initialize the google.generativeai client with the API key\\n\",\n",
        "        \"\\n\",\n",
        "        \"    genai.configure(api_key=self.key)\\n\",\n",
        "        \"    self.model = genai.GenerativeModel(model_name=self.name)\\n\",\n",
        "        \"\\n\",\n",
        "        \"  def generate(self, prompt: str, system: str = \\\"\\\") -> str:\\n\",\n",
        "        \"    # Build the content list, including the system message if provided\\n\",\n",
        "        \"    contents = [{\\\"role\\\": \\\"user\\\", \\\"parts\\\": [prompt]}]\\n\",\n",
        "        \"    if system:\\n\",\n",
        "        \"        contents = [{\\\"role\\\": \\\"user\\\", \\\"parts\\\": [system]}] + contents\\n\",\n",
        "        \"\\n\",\n",
        "        \"    # Use the Gemini model to generate content\\n\",\n",
        "        \"    response = self.model.generate_content(contents)\\n\",\n",
        "        \"\\n\",\n",
        "        \"    # Access the content from the response object\\n\",\n",
        "        \"    return response.text\\n\",\n",
        "        \"\\n\",\n",
        "        \"  def GetRAC(self, prompt: str)-> tuple[str, str]: ## Get Reasoning Answer Confidence\\n\",\n",
        "        \"    # Access global system prompts\\n\",\n",
        "        \"    global sys_prompt1, sys_prompt2\\n\",\n",
        "        \"    ## Get the reasoning\\n\",\n",
        "        \"    reasoning = self.generate(prompt, sys_prompt1)\\n\",\n",
        "        \"    ## Get the answer and confidence\\n\",\n",
        "        \"    answer_confidence = self.generate(prompt + reasoning + sys_prompt2, sys_prompt2)\\n\",\n",
        "        \"\\n\",\n",
        "        \"    return reasoning, answer_confidence\\n\",\n",
        "        \"\\n\",\n",
        "        \"## %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\\n\",\n",
        "        \"##                        Classes for Open Models\\n\",\n",
        "        \"## %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\\n\",\n",
        "        \"\\n\",\n",
        "        \"class OpenModel(ABC):\\n\",\n",
        "        \"  @abstractmethod\\n\",\n",
        "        \"  def __init__(self, name, key, MaxTokens = max_tokens):\\n\",\n",
        "        \"    pass\\n\",\n",
        "        \"\\n\",\n",
        "        \"  @abstractmethod\\n\",\n",
        "        \"  def generate(self, prompt):\\n\",\n",
        "        \"    pass\\n\",\n",
        "        \"\\n\",\n",
        "        \"  @abstractmethod\\n\",\n",
        "        \"  def GetTokens(self, prompt):\\n\",\n",
        "        \"    pass\\n\",\n",
        "        \"\\n\",\n",
        "        \"  @abstractmethod\\n\",\n",
        "        \"  def GetRAC(self, prompt):\\n\",\n",
        "        \"    pass\\n\",\n",
        "        \"\\n\",\n",
        "        \"class LlamaModel(OpenModel): ## This class is built around Hugging Face methods\\n\",\n",
        "        \"  def __init__(self, name, key, MaxTokens = 150):\\n\",\n",
        "        \"    self.name = name\\n\",\n",
        "        \"    self.key = key\\n\",\n",
        "        \"    self.MaxTokens = MaxTokens\\n\",\n",
        "        \"    print(f\\\"Downloading Tokenizer for {self.name}\\\")\\n\",\n",
        "        \"    self.tokenizer = AutoTokenizer.from_pretrained(self.name,token = self.key) ## Import Tokenizer\\n\",\n",
        "        \"    print(f\\\"Downloading Model Weights for {self.name}\\\")\\n\",\n",
        "        \"    self.model = AutoModelForCausalLM.from_pretrained(self.name, token = self.key, device_map=\\\"auto\\\") ## Import Model\\n\",\n",
        "        \"    self.results = pd.DataFrame(columns = ['Question ID','Question', 'Answer', 'Reasoning', 'Token Probability', 'Error'])\\n\",\n",
        "        \"    ## Make text generation pipeline\\n\",\n",
        "        \"    self.pipeline = pipeline(\\n\",\n",
        "        \"    \\\"text-generation\\\",\\n\",\n",
        "        \"    model = self.model,\\n\",\n",
        "        \"    tokenizer = self.tokenizer,\\n\",\n",
        "        \"    do_sample = False,\\n\",\n",
        "        \"    max_new_tokens = self.MaxTokens,\\n\",\n",
        "        \"    eos_token_id = self.tokenizer.eos_token_id,\\n\",\n",
        "        \"    pad_token_id = self.tokenizer.eos_token_id,\\n\",\n",
        "        \"    device_map=\\\"auto\\\",\\n\",\n",
        "        \"    transformers_version=\\\"4.37.0\\\",\\n\",\n",
        "        \"    )\\n\",\n",
        "        \"\\n\",\n",
        "        \"\\n\",\n",
        "        \"  def generate(self, prompt):\\n\",\n",
        "        \"\\n\",\n",
        "        \"    new_prompt = (\\\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\\"\\n\",\n",
        "        \"                  + 'You are a helpful assistant. When prompted for a response give your reasoning and answer to the user. Signify your answer with this response:\\\\n\\\"Therefore, the correct answer is:\\\\n<|eot_id|>\\\"'\\n\",\n",
        "        \"                  + \\\"\\\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\\"\\n\",\n",
        "        \"                  + prompt\\n\",\n",
        "        \"                  + \\\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\\")\\n\",\n",
        "        \"    return self.pipeline(prompt)[0]['generated_text'].replace(prompt, '')\\n\",\n",
        "        \"\\n\",\n",
        "        \"  def GetTokens(self, prompt: str):\\n\",\n",
        "        \"    ## Get Answer:\\n\",\n",
        "        \"    batch = self.tokenizer(prompt, return_tensors= \\\"pt\\\").to('cuda')\\n\",\n",
        "        \"    with torch.no_grad():\\n\",\n",
        "        \"        outputs = self.model(**batch)\\n\",\n",
        "        \"    ## Get Token Probabilites\\n\",\n",
        "        \"    logits = outputs.logits\\n\",\n",
        "        \"\\n\",\n",
        "        \"    ## Apply softmax to the logits to get probabilities\\n\",\n",
        "        \"    probs = torch.softmax(logits[0, -1], dim=0)\\n\",\n",
        "        \"\\n\",\n",
        "        \"    ##Get the top k token indices and their probabilities\\n\",\n",
        "        \"    top_k_probs, top_k_indices = torch.topk(probs, 100, sorted =True)\\n\",\n",
        "        \"\\n\",\n",
        "        \"    ## Convert token indices to tokens\\n\",\n",
        "        \"    top_k_tokens = [self.tokenizer.decode([token_id]) for token_id in top_k_indices]\\n\",\n",
        "        \"\\n\",\n",
        "        \"    ## Convert probabilities to list of floats\\n\",\n",
        "        \"    top_k_probs = top_k_probs.tolist()                  #list of probabilities\\n\",\n",
        "        \"\\n\",\n",
        "        \"    ## Create a Pandas Series with tokens as index and probabilities as values\\n\",\n",
        "        \"    global logit_series\\n\",\n",
        "        \"    logit_series = pd.Series(top_k_probs, index=top_k_tokens)\\n\",\n",
        "        \"\\n\",\n",
        "        \"    ## Sort the series by values in descending order\\n\",\n",
        "        \"    logit_series = logit_series.sort_values(ascending=False)\\n\",\n",
        "        \"    ## Get the answer Letter\\n\",\n",
        "        \"    target_tokens = [' A', ' B', ' C', ' D', ' E', 'A', 'B', 'C', 'D', 'E']\\n\",\n",
        "        \"\\n\",\n",
        "        \"    only_target_tokens = logit_series[logit_series.index.isin(target_tokens)]\\n\",\n",
        "        \"    best_answer = only_target_tokens.index[0]\\n\",\n",
        "        \"\\n\",\n",
        "        \"    ## Format logit series\\n\",\n",
        "        \"    logit_series.index.name = \\\"Token\\\"\\n\",\n",
        "        \"    logit_series.name = \\\"Probability\\\"\\n\",\n",
        "        \"    return str(logit_series.to_dict()), best_answer.strip()\\n\",\n",
        "        \"\\n\",\n",
        "        \"  def GetRAC(self, prompt: str)-> tuple[str, str]: ## Get Reasoning Answer/Confidence\\n\",\n",
        "        \"    ## Get the reasoning\\n\",\n",
        "        \"    new_prompt = (\\\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\\"\\n\",\n",
        "        \"                  + sys_prompt1\\n\",\n",
        "        \"                  + \\\"\\\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\\"\\n\",\n",
        "        \"                  + prompt\\n\",\n",
        "        \"                  + \\\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\\")\\n\",\n",
        "        \"    reasoning = self.generate(new_prompt).replace(new_prompt, '')\\n\",\n",
        "        \"    ## Get the answer and confidence\\n\",\n",
        "        \"    answer_confidence = self.generate(new_prompt\\n\",\n",
        "        \"                                      + reasoning\\n\",\n",
        "        \"                                      + '<|eot_id|><|start_header_id|>user<|end_header_id|>'\\n\",\n",
        "        \"                                      + sys_prompt2\\n\",\n",
        "        \"                                      + '<|eot_id|><|start_header_id|>assistant<|end_header_id|>' )\\n\",\n",
        "        \"\\n\",\n",
        "        \"    return reasoning, answer_confidence\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": 12,\n",
        "      \"metadata\": {\n",
        "        \"id\": \"k68HsBM6lCkS\"\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"## Define Functions:\\n\",\n",
        "        \"def init_models(models_dict,\\n\",\n",
        "        \"                test_prompt = \\\"Zdzisław Beksiński was\\\",\\n\",\n",
        "        \"                test_system = \\\"You are a helpful assistant.\\\"):\\n\",\n",
        "        \"  print('Initializing Closed Models:')\\n\",\n",
        "        \"  closed_models = []\\n\",\n",
        "        \"  for model_type in my_closed_models:\\n\",\n",
        "        \"      print(f'{model_type}:')\\n\",\n",
        "        \"      api_key_name = my_closed_models[model_type]['api_key_name']\\n\",\n",
        "        \"      api_key = userdata.get(api_key_name)\\n\",\n",
        "        \"      print(f'  API Key Name: {my_closed_models[model_type][\\\"api_key_name\\\"]}')\\n\",\n",
        "        \"      for model_name in my_closed_models[model_type]['models']:\\n\",\n",
        "        \"        # Instantiate the correct subclass based on model_type\\n\",\n",
        "        \"        if model_type == 'GPT':\\n\",\n",
        "        \"            my_model = GPTmodel(name = model_name, api_key = api_key)\\n\",\n",
        "        \"        elif model_type == 'Claude':\\n\",\n",
        "        \"            my_model = AnthropicModel(name = model_name, api_key = api_key)\\n\",\n",
        "        \"        elif model_type == 'Gemini':\\n\",\n",
        "        \"            my_model = GeminiModel(name = model_name, api_key = api_key)\\n\",\n",
        "        \"        else:\\n\",\n",
        "        \"            # Handle unexpected model types if necessary\\n\",\n",
        "        \"            print(f\\\"Warning: Unknown model type {model_type}. Skipping.\\\")\\n\",\n",
        "        \"            continue # Skip to the next model name if type is unknow\\n\",\n",
        "        \"        my_model.client()\\n\",\n",
        "        \"        closed_models.append(my_model)\\n\",\n",
        "        \"        print(f'    {model_name}')\\n\",\n",
        "        \"\\n\",\n",
        "        \"\\n\",\n",
        "        \"  print(f'Models Initialized: {len(closed_models)}')\\n\",\n",
        "        \"  print(f'Model locations:\\\\n{closed_models}')\\n\",\n",
        "        \"\\n\",\n",
        "        \"  print('-'*42)\\n\",\n",
        "        \"  print('Testing all closed models:')\\n\",\n",
        "        \"  print(f'Test prompt: {test_prompt}')\\n\",\n",
        "        \"  print(f'Test system: {test_system}')\\n\",\n",
        "        \"\\n\",\n",
        "        \"  for model in closed_models:\\n\",\n",
        "        \"    print(f'\\\\nTesting model: {model.name}')\\n\",\n",
        "        \"    print(model.generate(test_prompt, test_system))\\n\",\n",
        "        \"  return closed_models\\n\",\n",
        "        \"\\\"\\\"\\\"\\n\",\n",
        "        \"def make_system_prompt(df, sys_prompt1 = '', sys_prompt2 = ''):\\n\",\n",
        "        \"  if sys_prompt1 == '' and sys_prompt2 == '':\\n\",\n",
        "        \"\\n\",\n",
        "        \"    sys_prompt1 = '''\\n\",\n",
        "        \"    Given the following question, analyze the options, and provide a concise reasoning for your selected answer. Your reasoning should not exceed 100 words. After your explanation, clearly state your answer by choosing one of the options listed (A, B, C, D, or E).\\n\",\n",
        "        \"\\n\",\n",
        "        \"    Question: ${Question}\\n\",\n",
        "        \"    Options:\\n\",\n",
        "        \"    A) ${Option A}\\n\",\n",
        "        \"    B) ${Option B}\\n\",\n",
        "        \"    C) ${Option C}\\n\",\n",
        "        \"    D) ${Option D}\\n\",\n",
        "        \"    E) ${Option E}\\n\",\n",
        "        \"\\n\",\n",
        "        \"    Please provide your reasoning first, limited to 100 words, and then conclusively state only your selected answer using the corresponding letter (A, B, C, D, or E).\\n\",\n",
        "        \"    Reasoning: <Your concise reasoning here. Max 100 words>\\n\",\n",
        "        \"    '''\\n\",\n",
        "        \"    sys_prompt2 = '''\\n\",\n",
        "        \"    Based on the reasoning above, Provide the correct answer and the likelihood that each option is correct from 0.0 to 1.0 in a JSON format. The four probabilities should sum to 1.0. For example:\\n\",\n",
        "        \"\\n\",\n",
        "        \"    {\\n\",\n",
        "        \"    'Answer': <Your answer choice here, as a single letter and nothing else.>\\n\",\n",
        "        \"    'A': <Probability choice A is correct. As a float from 0.0 to 1.0>,\\n\",\n",
        "        \"    'B': <Probability choice B is correct. As a float from 0.0 to 1.0>,\\n\",\n",
        "        \"    'C': <Probability choice C is correct. As a float from 0.0 to 1.0>,\\n\",\n",
        "        \"    'D': <Probability choice D is correct. As a float from 0.0 to 1.0>,\\n\",\n",
        "        \"    'E': <Probability choice E is correct. As a float from 0.0 to 1.0>\\n\",\n",
        "        \"    }\\n\",\n",
        "        \"\\n\",\n",
        "        \"    Do not provide any additional reasoning.\\n\",\n",
        "        \"    '''\\n\",\n",
        "        \"  ## Edit system Prompts in order to match size of dataset\\n\",\n",
        "        \"  columns = df.columns\\n\",\n",
        "        \"  num_options = columns.str.contains('Option').astype(int).sum()\\n\",\n",
        "        \"\\n\",\n",
        "        \"  sys_prompt_temp1 = sys_prompt1\\n\",\n",
        "        \"  sys_prompt_temp2 = sys_prompt2\\n\",\n",
        "        \"  ## Reformat system prompt in order to fit number of options in benchmark\\n\",\n",
        "        \"  if num_options < 5: ## ABCD\\n\",\n",
        "        \"    sys_prompt_temp1 = (sys_prompt1\\n\",\n",
        "        \"                  .replace('(A, B, C, D, or E)', '(A, B, C, or D)') ## Change the available options\\n\",\n",
        "        \"                  .replace('E) ${Option E}', '') ## Drop option E\\n\",\n",
        "        \"        )\\n\",\n",
        "        \"    sys_prompt_temp2 = (sys_prompt2\\n\",\n",
        "        \"                  .replace('(A, B, C, D, or E)', '(A, B, C, or D)') ## Change the available options\\n\",\n",
        "        \"                  .replace('E) ${Option E}', '') ## Drop option E\\n\",\n",
        "        \"        )\\n\",\n",
        "        \"    if num_options < 4: ## ABC\\n\",\n",
        "        \"      sys_prompt_temp1 = (sys_prompt_temp1\\n\",\n",
        "        \"                    .replace('(A, B, C, or D)', '(A, B, or C)') ## Change the available options\\n\",\n",
        "        \"                    .replace('D) ${Option D}', '') ## Drop option D\\n\",\n",
        "        \"          )\\n\",\n",
        "        \"      sys_prompt_temp2 = (sys_prompt_temp2\\n\",\n",
        "        \"                  .replace('(A, B, C, or D)', '(A, B, or C)') ## Change the available options\\n\",\n",
        "        \"                  .replace('D) ${Option D}', '') ## Drop option D\\n\",\n",
        "        \"        )\\n\",\n",
        "        \"\\n\",\n",
        "        \"      if num_options < 3: ## AB\\n\",\n",
        "        \"        sys_prompt_temp1 = (sys_prompt_temp1\\n\",\n",
        "        \"                      .replace('(A, B, or C)', '(A or B)') ## Change the available options\\n\",\n",
        "        \"                      .replace('C) ${Option C}', '') ## Drop option C\\n\",\n",
        "        \"            )\\n\",\n",
        "        \"        sys_prompt_temp2 = (sys_prompt_temp2\\n\",\n",
        "        \"                    .replace('(A, B, or C)', '(A or B)') ## Change the available options\\n\",\n",
        "        \"                    .replace('C) ${Option C}', '') ## Drop option C\\n\",\n",
        "        \"          )\\n\",\n",
        "        \"\\n\",\n",
        "        \"  return sys_prompt_temp1, sys_prompt_temp2\\n\",\n",
        "        \"\\\"\\\"\\\"\\n\",\n",
        "        \"def format_df(df):\\n\",\n",
        "        \"\\n\",\n",
        "        \"  ## %%%%%%%%%%%%%%\\n\",\n",
        "        \"  ## I need to fix how formating is done for some Q's. As daniel pointed out some\\n\",\n",
        "        \"  ## questions only have 4 options, not 5.\\n\",\n",
        "        \"  ## %%%%%%%%%%%%%%\\n\",\n",
        "        \"\\n\",\n",
        "        \"  ## Takes in a dataframe in the form:\\n\",\n",
        "        \"  ## | Question ID | Question | Option A | Option B | ... | Correct Answer Letter |\\n\",\n",
        "        \"  ## |     (Int)       |     (Str)     |  (Str)   |  (Str)   |     |       (Char)          |\\n\",\n",
        "        \"  ##\\n\",\n",
        "        \"  ## Returns a dataframe in the form:\\n\",\n",
        "        \"  ## | Question ID | Full Prompt 1 | Full Prompt 2 |\\n\",\n",
        "        \"  ## |     (Int)       |    (Str)      |    (Str)      |\\n\",\n",
        "        \"\\n\",\n",
        "        \"  columns = df.columns\\n\",\n",
        "        \"  num_options = columns.str.contains('Option').astype(int).sum()\\n\",\n",
        "        \"\\n\",\n",
        "        \"  #----------------------------------------------------------------------------#\\n\",\n",
        "        \"  ## Check if DF is formatted properly\\n\",\n",
        "        \"  error_text = f'''Make sure dataframe is in following format:\\n\",\n",
        "        \"  | Question ID | Question | Option A | Option B | ... | Correct Answer Letter |\\n\",\n",
        "        \"  |     (Int)       |     (Str)     |  (Str)   |  (Str)   |     |       (Char)          |\\n\",\n",
        "        \"\\n\",\n",
        "        \"  The current format of Dataframe is: {columns}\\n\",\n",
        "        \"  '''\\n\",\n",
        "        \"  ['Question ID', 'Question', 'Correct Answer Letter']\\n\",\n",
        "        \"  if num_options < 2:\\n\",\n",
        "        \"    raise Exception(error_text)\\n\",\n",
        "        \"\\n\",\n",
        "        \"  #----------------------------------------------------------------------------#\\n\",\n",
        "        \"  ## Initialize Output dataframe:\\n\",\n",
        "        \"  header = ['Question ID', 'Full Prompt 1', 'Full Prompt 2']\\n\",\n",
        "        \"  output_df = pd.DataFrame(columns = header)\\n\",\n",
        "        \"\\n\",\n",
        "        \"  #----------------------------------------------------------------------------#\\n\",\n",
        "        \"\\n\",\n",
        "        \"  ## Format questions for benchmark\\n\",\n",
        "        \"  letters = ['A', 'B', 'C', 'D', 'E']\\n\",\n",
        "        \"  options = ['Option A', 'Option B', 'Option C', 'Option D', 'Option E']\\n\",\n",
        "        \"\\n\",\n",
        "        \"  for i in range(len(df)):\\n\",\n",
        "        \"    question = df['Question'][i]\\n\",\n",
        "        \"\\n\",\n",
        "        \"    sys_prompt_temp1 = sys_prompt1\\n\",\n",
        "        \"    sys_prompt_temp2 = sys_prompt2\\n\",\n",
        "        \"    ## Reformat system prompt in order to fit number of options in benchmark\\n\",\n",
        "        \"\\n\",\n",
        "        \"    if type(df['Option D'][i]) == float: ## ABC\\n\",\n",
        "        \"      sys_prompt_temp1 = (sys_prompt_temp1\\n\",\n",
        "        \"                    .replace('(A, B, C, or D)', '(A, B, or C)')\\n\",\n",
        "        \"                    .replace('D) ${Option D}', '')\\n\",\n",
        "        \"          )\\n\",\n",
        "        \"      sys_prompt_temp2 = (sys_prompt_temp2\\n\",\n",
        "        \"                  .replace('(A, B, C, or D)', '(A, B, or C)')\\n\",\n",
        "        \"                  .replace('D) ${Option D}', '')\\n\",\n",
        "        \"        )\\n\",\n",
        "        \"\\n\",\n",
        "        \"      if type(df['Option C'][i]) == float: ## AB\\n\",\n",
        "        \"        sys_prompt_temp1 = (sys_prompt_temp1\\n\",\n",
        "        \"                      .replace('(A, B, or C)', '(A or B)')\\n\",\n",
        "        \"                      .replace('C) ${Option C}', '')\\n\",\n",
        "        \"            )\\n\",\n",
        "        \"        sys_prompt_temp2 = (sys_prompt_temp2\\n\",\n",
        "        \"                    .replace('(A, B, or C)', '(A or B)')\\n\",\n",
        "        \"                    .replace('C) ${Option C}', '')\\n\",\n",
        "        \"          )\\n\",\n",
        "        \"\\n\",\n",
        "        \"    option_text = df[options[:num_options]].iloc[i].to_list()\\n\",\n",
        "        \"    ## Prompt for specific question\\n\",\n",
        "        \"    new_prompt = sys_prompt_temp1.replace('${Question}', question)\\n\",\n",
        "        \"    for j in range(num_options): ## This for loop allows for dynamic question amounts\\n\",\n",
        "        \"        new_prompt = new_prompt.replace(f'${{Option {letters[j]}}}', str(option_text[j]))\\n\",\n",
        "        \"\\n\",\n",
        "        \"\\n\",\n",
        "        \"    ## Add formatted prompts.\\n\",\n",
        "        \"    ## Note that this is formatted to llama so changes may be needed down the line.\\n\",\n",
        "        \"    prompts1 = (new_prompt.split('<Your concise reasoning here. Max 100 words>')[0]) ## Specific prompt for question\\n\",\n",
        "        \"\\n\",\n",
        "        \"    prompts2 = (sys_prompt_temp2) ## Generic prompt for question confidence\\n\",\n",
        "        \"    output_df.loc[i] = [df['Question ID'].iloc[i], prompts1, prompts2]\\n\",\n",
        "        \"\\n\",\n",
        "        \"  return output_df\\n\",\n",
        "        \"\\n\",\n",
        "        \"def test_models_sequential_by_question(df, models, debug=False, start = 0, stop = -1):\\n\",\n",
        "        \"    \\\"\\\"\\\"\\n\",\n",
        "        \"    Tests a list of models on a given dataset sequentially,\\n\",\n",
        "        \"    iterating through questions and then models for each question.\\n\",\n",
        "        \"    Includes a debug mode to process only the first 10 questions.\\n\",\n",
        "        \"\\n\",\n",
        "        \"    Args:\\n\",\n",
        "        \"        df (pd.DataFrame): The dataset containing questions and prompts.\\n\",\n",
        "        \"        models (list): A list of initialized model objects.\\n\",\n",
        "        \"        debug (bool): If True, only process the first 10 questions.\\n\",\n",
        "        \"    \\\"\\\"\\\"\\n\",\n",
        "        \"    print(\\\"Clearing previous results for each model...\\\")\\n\",\n",
        "        \"    for model in models:\\n\",\n",
        "        \"        model.results = pd.DataFrame(columns=['Question ID', 'Question', 'Answer', 'Reasoning', 'Error'])\\n\",\n",
        "        \"        print(f\\\"  Cleared results for {model.name}\\\")\\n\",\n",
        "        \"    print(\\\"Starting sequential testing (by question)...\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"    # Determine the number of questions to process\\n\",\n",
        "        \"    num_questions_to_process = 2 if debug else len(df) if stop == -1 else stop - start\\n\",\n",
        "        \"\\n\",\n",
        "        \"    # Iterate over questions first\\n\",\n",
        "        \"    for index, row in tqdm(df.iloc[start: num_questions_to_process].iterrows(), total=num_questions_to_process, desc=\\\"Processing Questions\\\"):\\n\",\n",
        "        \"        question_num = row['Question Num']\\n\",\n",
        "        \"        prompt = row['Full Prompt 1']\\n\",\n",
        "        \"        '''\\n\",\n",
        "        \"\\n\",\n",
        "        \"        I dont love this implementation But honestly,\\n\",\n",
        "        \"        unless my logic is flawed with some edge case, I think this should work\\n\",\n",
        "        \"        and I dont want to rewrite the functions for each subclass to take in the\\n\",\n",
        "        \"        dataframe in order to work.\\n\",\n",
        "        \"        '''\\n\",\n",
        "        \"        global sys_prompt2\\n\",\n",
        "        \"        sys_prompt2 = row['Full Prompt 2']\\n\",\n",
        "        \"\\n\",\n",
        "        \"        print(f\\\"\\\\nProcessing Question {question_num}\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"        # Iterate over models for the current question\\n\",\n",
        "        \"        for model in models:\\n\",\n",
        "        \"\\n\",\n",
        "        \"            try:\\n\",\n",
        "        \"                print(f\\\"  Testing with model: {model.name}\\\")\\n\",\n",
        "        \"                # Call GetRAC and add the result to the model's self.results\\n\",\n",
        "        \"                reasoning, answer_confidence = model.GetRAC(prompt=prompt)\\n\",\n",
        "        \"\\n\",\n",
        "        \"                # Add the results to the model's self.results DataFrame\\n\",\n",
        "        \"                new_row = pd.DataFrame([{\\n\",\n",
        "        \"                    'Question ID': question_num,\\n\",\n",
        "        \"                    'Question': prompt,\\n\",\n",
        "        \"                    'Answer': answer_confidence,\\n\",\n",
        "        \"                    'Reasoning': reasoning,\\n\",\n",
        "        \"                    'Error': False\\n\",\n",
        "        \"                }])\\n\",\n",
        "        \"                model.results = model.results._append(new_row, ignore_index=True)\\n\",\n",
        "        \"                filename = f\\\"{model.name.replace('/', '_').replace('-', '_')}_test_results.csv\\\"\\n\",\n",
        "        \"                model.results.to_csv(filename, index=False)\\n\",\n",
        "        \"            except Exception as e:\\n\",\n",
        "        \"                print(f\\\"  Error testing {model.name} on Question {question_num}: {e}\\\")\\n\",\n",
        "        \"                # Optionally add an error entry to the results\\n\",\n",
        "        \"                error_row = pd.DataFrame([{\\n\",\n",
        "        \"                    'Question ID': question_num,\\n\",\n",
        "        \"                    'Question': prompt,\\n\",\n",
        "        \"                    'Answer': f\\\"Error: {e}\\\",\\n\",\n",
        "        \"                    'Reasoning': f\\\"Error: {e}\\\",\\n\",\n",
        "        \"                    'Error': True\\n\",\n",
        "        \"                }])\\n\",\n",
        "        \"                model.results = model.results._append(error_row, ignore_index=True)\\n\",\n",
        "        \"                filename = f\\\"{model.name.replace('/', '_').replace('-', '_')}_test_results.csv\\\"\\n\",\n",
        "        \"                model.results.to_csv(filename, index=False)\\n\",\n",
        "        \"    print(\\\"\\\\nSequential testing complete.\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"    # After processing all questions, save the results for each model\\n\",\n",
        "        \"    for model in models:\\n\",\n",
        "        \"        # Mount Google Drive\\n\",\n",
        "        \"        drive.mount('/content/drive')\\n\",\n",
        "        \"\\n\",\n",
        "        \"        # Define the folder path\\n\",\n",
        "        \"        folder_path = f'/content/drive/My Drive/SciQ'\\n\",\n",
        "        \"\\n\",\n",
        "        \"        # Create the folder if it doesn't exist\\n\",\n",
        "        \"        if not os.path.exists(folder_path):\\n\",\n",
        "        \"            os.makedirs(folder_path)\\n\",\n",
        "        \"        filename = f\\\"{model.name.replace('/', '_').replace('-', '_')}_test_results.csv\\\"\\n\",\n",
        "        \"        file_path = os.path.join(folder_path, filename)\\n\",\n",
        "        \"        model.results.to_csv(file_path, index=False)\\n\",\n",
        "        \"        print(f\\\"Results for {model.name} saved to '{file_path}'\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"## %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\\n\",\n",
        "        \"##                       Functions for Open Models\\n\",\n",
        "        \"## %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\\n\",\n",
        "        \"\\n\",\n",
        "        \"\\n\",\n",
        "        \"def test_open_model_sciq(model, df, debug = False):\\n\",\n",
        "        \"  model.results = pd.DataFrame(columns=['Question ID',\\n\",\n",
        "        \"                                        'Question',\\n\",\n",
        "        \"                                        'Stated Confidence',\\n\",\n",
        "        \"                                        'Stated Answer',\\n\",\n",
        "        \"                                        'Reasoning',\\n\",\n",
        "        \"                                        'Error',\\n\",\n",
        "        \"                                        'Token Probability'\\n\",\n",
        "        \"                                        ])\\n\",\n",
        "        \"  if debug:\\n\",\n",
        "        \"    length = 3\\n\",\n",
        "        \"  else:\\n\",\n",
        "        \"    length = len(df)\\n\",\n",
        "        \"  start = 0\\n\",\n",
        "        \"\\n\",\n",
        "        \"  for i in tqdm(range(length), total=length, desc=\\\"Processing Questions\\\"):\\n\",\n",
        "        \"  #for i in range(length):\\n\",\n",
        "        \"    try:\\n\",\n",
        "        \"      ## Question Information\\n\",\n",
        "        \"      question_num = df['Question ID'][i]\\n\",\n",
        "        \"      question_text = df['Full Prompt 1'][i]\\n\",\n",
        "        \"      reasoning_prompt = question_text\\n\",\n",
        "        \"\\n\",\n",
        "        \"\\n\",\n",
        "        \"      ## Get reasoning from model\\n\",\n",
        "        \"      model_reasoning = model.generate(reasoning_prompt)\\n\",\n",
        "        \"      ## Get Answer from model\\n\",\n",
        "        \"\\n\",\n",
        "        \"      answer_prompt = (reasoning_prompt\\n\",\n",
        "        \"                      + '<|eot_id|><|start_header_id|>assistant<|end_header_id|>'\\n\",\n",
        "        \"                      + model_reasoning\\n\",\n",
        "        \"                      + '\\\\n<|eot_id|><|start_header_id|>user<|end_header_id|>'\\n\",\n",
        "        \"                      + sys_prompt2\\n\",\n",
        "        \"                      + '<|eot_id|><|start_header_id|>assistant<|end_header_id|>'\\n\",\n",
        "        \"                      + \\\"{'Answer': '\\\"\\n\",\n",
        "        \"                      )\\n\",\n",
        "        \"      model_tokens, answer_letter = model.GetTokens(answer_prompt)\\n\",\n",
        "        \"\\n\",\n",
        "        \"      ## Get JSON formatted answer and confidence\\n\",\n",
        "        \"      answer_JSON_prompt = answer_prompt + answer_letter + \\\"',\\\"\\n\",\n",
        "        \"      model_confidence_JSON = \\\"{'Answer': '\\\" + answer_letter + \\\"',\\\" + model.generate(answer_JSON_prompt)\\n\",\n",
        "        \"\\n\",\n",
        "        \"      new_row = pd.DataFrame([{\\n\",\n",
        "        \"          'Question ID': question_num,\\n\",\n",
        "        \"          'Question': question_text,\\n\",\n",
        "        \"          'Stated Confidence': model_confidence_JSON,\\n\",\n",
        "        \"          'Stated Answer': answer_letter,\\n\",\n",
        "        \"          'Reasoning': model_reasoning,\\n\",\n",
        "        \"          'Error': False,\\n\",\n",
        "        \"          'Token Probability': model_tokens,\\n\",\n",
        "        \"          'Correct Answer Letter': dataset['Correct Answer Letter'][i]\\n\",\n",
        "        \"      }])\\n\",\n",
        "        \"    except Exception as e:\\n\",\n",
        "        \"      new_row = pd.DataFrame([{\\n\",\n",
        "        \"          'Question ID': question_num,\\n\",\n",
        "        \"          'Question': question_text,\\n\",\n",
        "        \"          'Stated Confidence': 'ERROR',\\n\",\n",
        "        \"          'Stated Answer': 'ERROR',\\n\",\n",
        "        \"          'Reasoning': e,\\n\",\n",
        "        \"          'Error': True,\\n\",\n",
        "        \"          'Token Probability': 'ERROR',\\n\",\n",
        "        \"          'Correct Answer Letter': dataset['Correct Answer Letter'][i]\\n\",\n",
        "        \"      }])\\n\",\n",
        "        \"    model.results = model.results._append(new_row, ignore_index=True)\\n\",\n",
        "        \"\\n\",\n",
        "        \"  return model.results\\n\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": 9,\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 1000\n",
        "        },\n",
        "        \"id\": \"dQgBf4ANlHXS\",\n",
        "        \"outputId\": \"e2faf779-0184-449a-92e2-7d70929574f4\"\n",
        "      },\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"------------------------------------------\\n\",\n",
        "            \"Importing Dataset: /content/sciq_test_formatted.csv\\n\"\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"display_data\",\n",
        "          \"data\": {\n",
        "            \"text/plain\": [\n",
        "              \"   Question ID                                           Question  \\\\\\n\",\n",
        "              \"0                0  Compounds that are capable of accepting electr...   \\n\",\n",
        "              \"1                1  What term in biotechnology means a genetically...   \\n\",\n",
        "              \"2                2  Vertebrata are characterized by the presence o...   \\n\",\n",
        "              \"3                3  What is the height above or below sea level ca...   \\n\",\n",
        "              \"4                4  Ice cores, varves and what else indicate the e...   \\n\",\n",
        "              \"\\n\",\n",
        "              \"          Option A  Option B    Option C   Option D Correct Answer Letter  \\n\",\n",
        "              \"0     antioxidants    Oxygen    oxidants   residues                     C  \\n\",\n",
        "              \"1            adult      male   phenotype      clone                     D  \\n\",\n",
        "              \"2         backbone     Bones     Muscles     Thumbs                     A  \\n\",\n",
        "              \"3            depth  latitude   elevation  variation                     C  \\n\",\n",
        "              \"4  mountain ranges   fossils  tree rings      magma                     C  \"\n",
        "            ],\n",
        "            \"text/html\": [\n",
        "              \"\\n\",\n",
        "              \"  <div id=\\\"df-651f0d94-b8f4-4b94-8f3b-8c3bc961584c\\\" class=\\\"colab-df-container\\\">\\n\",\n",
        "              \"    <div>\\n\",\n",
        "              \"<style scoped>\\n\",\n",
        "              \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
        "              \"        vertical-align: middle;\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"\\n\",\n",
        "              \"    .dataframe tbody tr th {\\n\",\n",
        "              \"        vertical-align: top;\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"\\n\",\n",
        "              \"    .dataframe thead th {\\n\",\n",
        "              \"        text-align: right;\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"</style>\\n\",\n",
        "              \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
        "              \"  <thead>\\n\",\n",
        "              \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
        "              \"      <th></th>\\n\",\n",
        "              \"      <th>Question ID</th>\\n\",\n",
        "              \"      <th>Question</th>\\n\",\n",
        "              \"      <th>Option A</th>\\n\",\n",
        "              \"      <th>Option B</th>\\n\",\n",
        "              \"      <th>Option C</th>\\n\",\n",
        "              \"      <th>Option D</th>\\n\",\n",
        "              \"      <th>Correct Answer Letter</th>\\n\",\n",
        "              \"    </tr>\\n\",\n",
        "              \"  </thead>\\n\",\n",
        "              \"  <tbody>\\n\",\n",
        "              \"    <tr>\\n\",\n",
        "              \"      <th>0</th>\\n\",\n",
        "              \"      <td>0</td>\\n\",\n",
        "              \"      <td>Compounds that are capable of accepting electr...</td>\\n\",\n",
        "              \"      <td>antioxidants</td>\\n\",\n",
        "              \"      <td>Oxygen</td>\\n\",\n",
        "              \"      <td>oxidants</td>\\n\",\n",
        "              \"      <td>residues</td>\\n\",\n",
        "              \"      <td>C</td>\\n\",\n",
        "              \"    </tr>\\n\",\n",
        "              \"    <tr>\\n\",\n",
        "              \"      <th>1</th>\\n\",\n",
        "              \"      <td>1</td>\\n\",\n",
        "              \"      <td>What term in biotechnology means a genetically...</td>\\n\",\n",
        "              \"      <td>adult</td>\\n\",\n",
        "              \"      <td>male</td>\\n\",\n",
        "              \"      <td>phenotype</td>\\n\",\n",
        "              \"      <td>clone</td>\\n\",\n",
        "              \"      <td>D</td>\\n\",\n",
        "              \"    </tr>\\n\",\n",
        "              \"    <tr>\\n\",\n",
        "              \"      <th>2</th>\\n\",\n",
        "              \"      <td>2</td>\\n\",\n",
        "              \"      <td>Vertebrata are characterized by the presence o...</td>\\n\",\n",
        "              \"      <td>backbone</td>\\n\",\n",
        "              \"      <td>Bones</td>\\n\",\n",
        "              \"      <td>Muscles</td>\\n\",\n",
        "              \"      <td>Thumbs</td>\\n\",\n",
        "              \"      <td>A</td>\\n\",\n",
        "              \"    </tr>\\n\",\n",
        "              \"    <tr>\\n\",\n",
        "              \"      <th>3</th>\\n\",\n",
        "              \"      <td>3</td>\\n\",\n",
        "              \"      <td>What is the height above or below sea level ca...</td>\\n\",\n",
        "              \"      <td>depth</td>\\n\",\n",
        "              \"      <td>latitude</td>\\n\",\n",
        "              \"      <td>elevation</td>\\n\",\n",
        "              \"      <td>variation</td>\\n\",\n",
        "              \"      <td>C</td>\\n\",\n",
        "              \"    </tr>\\n\",\n",
        "              \"    <tr>\\n\",\n",
        "              \"      <th>4</th>\\n\",\n",
        "              \"      <td>4</td>\\n\",\n",
        "              \"      <td>Ice cores, varves and what else indicate the e...</td>\\n\",\n",
        "              \"      <td>mountain ranges</td>\\n\",\n",
        "              \"      <td>fossils</td>\\n\",\n",
        "              \"      <td>tree rings</td>\\n\",\n",
        "              \"      <td>magma</td>\\n\",\n",
        "              \"      <td>C</td>\\n\",\n",
        "              \"    </tr>\\n\",\n",
        "              \"  </tbody>\\n\",\n",
        "              \"</table>\\n\",\n",
        "              \"</div>\\n\",\n",
        "              \"    <div class=\\\"colab-df-buttons\\\">\\n\",\n",
        "              \"\\n\",\n",
        "              \"  <div class=\\\"colab-df-container\\\">\\n\",\n",
        "              \"    <button class=\\\"colab-df-convert\\\" onclick=\\\"convertToInteractive('df-651f0d94-b8f4-4b94-8f3b-8c3bc961584c')\\\"\\n\",\n",
        "              \"            title=\\\"Convert this dataframe to an interactive table.\\\"\\n\",\n",
        "              \"            style=\\\"display:none;\\\">\\n\",\n",
        "              \"\\n\",\n",
        "              \"  <svg xmlns=\\\"http://www.w3.org/2000/svg\\\" height=\\\"24px\\\" viewBox=\\\"0 -960 960 960\\\">\\n\",\n",
        "              \"    <path d=\\\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\\\"/>\\n\",\n",
        "              \"  </svg>\\n\",\n",
        "              \"    </button>\\n\",\n",
        "              \"\\n\",\n",
        "              \"  <style>\\n\",\n",
        "              \"    .colab-df-container {\\n\",\n",
        "              \"      display:flex;\\n\",\n",
        "              \"      gap: 12px;\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"\\n\",\n",
        "              \"    .colab-df-convert {\\n\",\n",
        "              \"      background-color: #E8F0FE;\\n\",\n",
        "              \"      border: none;\\n\",\n",
        "              \"      border-radius: 50%;\\n\",\n",
        "              \"      cursor: pointer;\\n\",\n",
        "              \"      display: none;\\n\",\n",
        "              \"      fill: #1967D2;\\n\",\n",
        "              \"      height: 32px;\\n\",\n",
        "              \"      padding: 0 0 0 0;\\n\",\n",
        "              \"      width: 32px;\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"\\n\",\n",
        "              \"    .colab-df-convert:hover {\\n\",\n",
        "              \"      background-color: #E2EBFA;\\n\",\n",
        "              \"      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\\n\",\n",
        "              \"      fill: #174EA6;\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"\\n\",\n",
        "              \"    .colab-df-buttons div {\\n\",\n",
        "              \"      margin-bottom: 4px;\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"\\n\",\n",
        "              \"    [theme=dark] .colab-df-convert {\\n\",\n",
        "              \"      background-color: #3B4455;\\n\",\n",
        "              \"      fill: #D2E3FC;\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"\\n\",\n",
        "              \"    [theme=dark] .colab-df-convert:hover {\\n\",\n",
        "              \"      background-color: #434B5C;\\n\",\n",
        "              \"      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\\n\",\n",
        "              \"      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\\n\",\n",
        "              \"      fill: #FFFFFF;\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"  </style>\\n\",\n",
        "              \"\\n\",\n",
        "              \"    <script>\\n\",\n",
        "              \"      const buttonEl =\\n\",\n",
        "              \"        document.querySelector('#df-651f0d94-b8f4-4b94-8f3b-8c3bc961584c button.colab-df-convert');\\n\",\n",
        "              \"      buttonEl.style.display =\\n\",\n",
        "              \"        google.colab.kernel.accessAllowed ? 'block' : 'none';\\n\",\n",
        "              \"\\n\",\n",
        "              \"      async function convertToInteractive(key) {\\n\",\n",
        "              \"        const element = document.querySelector('#df-651f0d94-b8f4-4b94-8f3b-8c3bc961584c');\\n\",\n",
        "              \"        const dataTable =\\n\",\n",
        "              \"          await google.colab.kernel.invokeFunction('convertToInteractive',\\n\",\n",
        "              \"                                                    [key], {});\\n\",\n",
        "              \"        if (!dataTable) return;\\n\",\n",
        "              \"\\n\",\n",
        "              \"        const docLinkHtml = 'Like what you see? Visit the ' +\\n\",\n",
        "              \"          '<a target=\\\"_blank\\\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\\n\",\n",
        "              \"          + ' to learn more about interactive tables.';\\n\",\n",
        "              \"        element.innerHTML = '';\\n\",\n",
        "              \"        dataTable['output_type'] = 'display_data';\\n\",\n",
        "              \"        await google.colab.output.renderOutput(dataTable, element);\\n\",\n",
        "              \"        const docLink = document.createElement('div');\\n\",\n",
        "              \"        docLink.innerHTML = docLinkHtml;\\n\",\n",
        "              \"        element.appendChild(docLink);\\n\",\n",
        "              \"      }\\n\",\n",
        "              \"    </script>\\n\",\n",
        "              \"  </div>\\n\",\n",
        "              \"\\n\",\n",
        "              \"\\n\",\n",
        "              \"    <div id=\\\"df-9ec807d8-1bed-4d13-ad02-8b0cc408d7e5\\\">\\n\",\n",
        "              \"      <button class=\\\"colab-df-quickchart\\\" onclick=\\\"quickchart('df-9ec807d8-1bed-4d13-ad02-8b0cc408d7e5')\\\"\\n\",\n",
        "              \"                title=\\\"Suggest charts\\\"\\n\",\n",
        "              \"                style=\\\"display:none;\\\">\\n\",\n",
        "              \"\\n\",\n",
        "              \"<svg xmlns=\\\"http://www.w3.org/2000/svg\\\" height=\\\"24px\\\"viewBox=\\\"0 0 24 24\\\"\\n\",\n",
        "              \"     width=\\\"24px\\\">\\n\",\n",
        "              \"    <g>\\n\",\n",
        "              \"        <path d=\\\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\\\"/>\\n\",\n",
        "              \"    </g>\\n\",\n",
        "              \"</svg>\\n\",\n",
        "              \"      </button>\\n\",\n",
        "              \"\\n\",\n",
        "              \"<style>\\n\",\n",
        "              \"  .colab-df-quickchart {\\n\",\n",
        "              \"      --bg-color: #E8F0FE;\\n\",\n",
        "              \"      --fill-color: #1967D2;\\n\",\n",
        "              \"      --hover-bg-color: #E2EBFA;\\n\",\n",
        "              \"      --hover-fill-color: #174EA6;\\n\",\n",
        "              \"      --disabled-fill-color: #AAA;\\n\",\n",
        "              \"      --disabled-bg-color: #DDD;\\n\",\n",
        "              \"  }\\n\",\n",
        "              \"\\n\",\n",
        "              \"  [theme=dark] .colab-df-quickchart {\\n\",\n",
        "              \"      --bg-color: #3B4455;\\n\",\n",
        "              \"      --fill-color: #D2E3FC;\\n\",\n",
        "              \"      --hover-bg-color: #434B5C;\\n\",\n",
        "              \"      --hover-fill-color: #FFFFFF;\\n\",\n",
        "              \"      --disabled-bg-color: #3B4455;\\n\",\n",
        "              \"      --disabled-fill-color: #666;\\n\",\n",
        "              \"  }\\n\",\n",
        "              \"\\n\",\n",
        "              \"  .colab-df-quickchart {\\n\",\n",
        "              \"    background-color: var(--bg-color);\\n\",\n",
        "              \"    border: none;\\n\",\n",
        "              \"    border-radius: 50%;\\n\",\n",
        "              \"    cursor: pointer;\\n\",\n",
        "              \"    display: none;\\n\",\n",
        "              \"    fill: var(--fill-color);\\n\",\n",
        "              \"    height: 32px;\\n\",\n",
        "              \"    padding: 0;\\n\",\n",
        "              \"    width: 32px;\\n\",\n",
        "              \"  }\\n\",\n",
        "              \"\\n\",\n",
        "              \"  .colab-df-quickchart:hover {\\n\",\n",
        "              \"    background-color: var(--hover-bg-color);\\n\",\n",
        "              \"    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\\n\",\n",
        "              \"    fill: var(--button-hover-fill-color);\\n\",\n",
        "              \"  }\\n\",\n",
        "              \"\\n\",\n",
        "              \"  .colab-df-quickchart-complete:disabled,\\n\",\n",
        "              \"  .colab-df-quickchart-complete:disabled:hover {\\n\",\n",
        "              \"    background-color: var(--disabled-bg-color);\\n\",\n",
        "              \"    fill: var(--disabled-fill-color);\\n\",\n",
        "              \"    box-shadow: none;\\n\",\n",
        "              \"  }\\n\",\n",
        "              \"\\n\",\n",
        "              \"  .colab-df-spinner {\\n\",\n",
        "              \"    border: 2px solid var(--fill-color);\\n\",\n",
        "              \"    border-color: transparent;\\n\",\n",
        "              \"    border-bottom-color: var(--fill-color);\\n\",\n",
        "              \"    animation:\\n\",\n",
        "              \"      spin 1s steps(1) infinite;\\n\",\n",
        "              \"  }\\n\",\n",
        "              \"\\n\",\n",
        "              \"  @keyframes spin {\\n\",\n",
        "              \"    0% {\\n\",\n",
        "              \"      border-color: transparent;\\n\",\n",
        "              \"      border-bottom-color: var(--fill-color);\\n\",\n",
        "              \"      border-left-color: var(--fill-color);\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"    20% {\\n\",\n",
        "              \"      border-color: transparent;\\n\",\n",
        "              \"      border-left-color: var(--fill-color);\\n\",\n",
        "              \"      border-top-color: var(--fill-color);\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"    30% {\\n\",\n",
        "              \"      border-color: transparent;\\n\",\n",
        "              \"      border-left-color: var(--fill-color);\\n\",\n",
        "              \"      border-top-color: var(--fill-color);\\n\",\n",
        "              \"      border-right-color: var(--fill-color);\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"    40% {\\n\",\n",
        "              \"      border-color: transparent;\\n\",\n",
        "              \"      border-right-color: var(--fill-color);\\n\",\n",
        "              \"      border-top-color: var(--fill-color);\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"    60% {\\n\",\n",
        "              \"      border-color: transparent;\\n\",\n",
        "              \"      border-right-color: var(--fill-color);\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"    80% {\\n\",\n",
        "              \"      border-color: transparent;\\n\",\n",
        "              \"      border-right-color: var(--fill-color);\\n\",\n",
        "              \"      border-bottom-color: var(--fill-color);\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"    90% {\\n\",\n",
        "              \"      border-color: transparent;\\n\",\n",
        "              \"      border-bottom-color: var(--fill-color);\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"  }\\n\",\n",
        "              \"</style>\\n\",\n",
        "              \"\\n\",\n",
        "              \"      <script>\\n\",\n",
        "              \"        async function quickchart(key) {\\n\",\n",
        "              \"          const quickchartButtonEl =\\n\",\n",
        "              \"            document.querySelector('#' + key + ' button');\\n\",\n",
        "              \"          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\\n\",\n",
        "              \"          quickchartButtonEl.classList.add('colab-df-spinner');\\n\",\n",
        "              \"          try {\\n\",\n",
        "              \"            const charts = await google.colab.kernel.invokeFunction(\\n\",\n",
        "              \"                'suggestCharts', [key], {});\\n\",\n",
        "              \"          } catch (error) {\\n\",\n",
        "              \"            console.error('Error during call to suggestCharts:', error);\\n\",\n",
        "              \"          }\\n\",\n",
        "              \"          quickchartButtonEl.classList.remove('colab-df-spinner');\\n\",\n",
        "              \"          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\\n\",\n",
        "              \"        }\\n\",\n",
        "              \"        (() => {\\n\",\n",
        "              \"          let quickchartButtonEl =\\n\",\n",
        "              \"            document.querySelector('#df-9ec807d8-1bed-4d13-ad02-8b0cc408d7e5 button');\\n\",\n",
        "              \"          quickchartButtonEl.style.display =\\n\",\n",
        "              \"            google.colab.kernel.accessAllowed ? 'block' : 'none';\\n\",\n",
        "              \"        })();\\n\",\n",
        "              \"      </script>\\n\",\n",
        "              \"    </div>\\n\",\n",
        "              \"\\n\",\n",
        "              \"    </div>\\n\",\n",
        "              \"  </div>\\n\"\n",
        "            ],\n",
        "            \"application/vnd.google.colaboratory.intrinsic+json\": {\n",
        "              \"type\": \"dataframe\",\n",
        "              \"summary\": \"{\\n  \\\"name\\\": \\\"display(new_dataset\\\",\\n  \\\"rows\\\": 5,\\n  \\\"fields\\\": [\\n    {\\n      \\\"column\\\": \\\"Question ID\\\",\\n      \\\"properties\\\": {\\n        \\\"dtype\\\": \\\"number\\\",\\n        \\\"std\\\": 1,\\n        \\\"min\\\": 0,\\n        \\\"max\\\": 4,\\n        \\\"num_unique_values\\\": 5,\\n        \\\"samples\\\": [\\n          1,\\n          4,\\n          2\\n        ],\\n        \\\"semantic_type\\\": \\\"\\\",\\n        \\\"description\\\": \\\"\\\"\\n      }\\n    },\\n    {\\n      \\\"column\\\": \\\"Question\\\",\\n      \\\"properties\\\": {\\n        \\\"dtype\\\": \\\"string\\\",\\n        \\\"num_unique_values\\\": 5,\\n        \\\"samples\\\": [\\n          \\\"What term in biotechnology means a genetically exact copy of an organism?\\\",\\n          \\\"Ice cores, varves and what else indicate the environmental conditions at the time of their creation?\\\",\\n          \\\"Vertebrata are characterized by the presence of what?\\\"\\n        ],\\n        \\\"semantic_type\\\": \\\"\\\",\\n        \\\"description\\\": \\\"\\\"\\n      }\\n    },\\n    {\\n      \\\"column\\\": \\\"Option A\\\",\\n      \\\"properties\\\": {\\n        \\\"dtype\\\": \\\"string\\\",\\n        \\\"num_unique_values\\\": 5,\\n        \\\"samples\\\": [\\n          \\\"adult\\\",\\n          \\\"mountain ranges\\\",\\n          \\\"backbone\\\"\\n        ],\\n        \\\"semantic_type\\\": \\\"\\\",\\n        \\\"description\\\": \\\"\\\"\\n      }\\n    },\\n    {\\n      \\\"column\\\": \\\"Option B\\\",\\n      \\\"properties\\\": {\\n        \\\"dtype\\\": \\\"string\\\",\\n        \\\"num_unique_values\\\": 5,\\n        \\\"samples\\\": [\\n          \\\"male\\\",\\n          \\\"fossils\\\",\\n          \\\"Bones\\\"\\n        ],\\n        \\\"semantic_type\\\": \\\"\\\",\\n        \\\"description\\\": \\\"\\\"\\n      }\\n    },\\n    {\\n      \\\"column\\\": \\\"Option C\\\",\\n      \\\"properties\\\": {\\n        \\\"dtype\\\": \\\"string\\\",\\n        \\\"num_unique_values\\\": 5,\\n        \\\"samples\\\": [\\n          \\\"phenotype\\\",\\n          \\\"tree rings\\\",\\n          \\\"Muscles\\\"\\n        ],\\n        \\\"semantic_type\\\": \\\"\\\",\\n        \\\"description\\\": \\\"\\\"\\n      }\\n    },\\n    {\\n      \\\"column\\\": \\\"Option D\\\",\\n      \\\"properties\\\": {\\n        \\\"dtype\\\": \\\"string\\\",\\n        \\\"num_unique_values\\\": 5,\\n        \\\"samples\\\": [\\n          \\\"clone\\\",\\n          \\\"magma\\\",\\n          \\\"Thumbs\\\"\\n        ],\\n        \\\"semantic_type\\\": \\\"\\\",\\n        \\\"description\\\": \\\"\\\"\\n      }\\n    },\\n    {\\n      \\\"column\\\": \\\"Correct Answer Letter\\\",\\n      \\\"properties\\\": {\\n        \\\"dtype\\\": \\\"string\\\",\\n        \\\"num_unique_values\\\": 3,\\n        \\\"samples\\\": [\\n          \\\"C\\\",\\n          \\\"D\\\",\\n          \\\"A\\\"\\n        ],\\n        \\\"semantic_type\\\": \\\"\\\",\\n        \\\"description\\\": \\\"\\\"\\n      }\\n    }\\n  ]\\n}\"\n",
        "            }\n",
        "          },\n",
        "          \"metadata\": {}\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"------------------------------------------\\n\",\n",
        "            \"Editing System Prompts:\\n\",\n",
        "            \"System Prompts:\\n\",\n",
        "            \"  \\n\",\n",
        "            \"Given the following question, analyze the options, and provide a concise reasoning for your selected answer. Your reasoning should not exceed 100 words. After your explanation, clearly state your answer by choosing one of the options listed (A, B, C, or D).\\n\",\n",
        "            \"\\n\",\n",
        "            \"Question: ${Question}\\n\",\n",
        "            \"Options:\\n\",\n",
        "            \"A) ${Option A}\\n\",\n",
        "            \"B) ${Option B}\\n\",\n",
        "            \"C) ${Option C}\\n\",\n",
        "            \"D) ${Option D}\\n\",\n",
        "            \"\\n\",\n",
        "            \"\\n\",\n",
        "            \"Please provide your reasoning first, limited to 100 words, and consider how certain you should be of your answer.\\n\",\n",
        "            \"Reasoning: <Your concise reasoning here. Max 100 words>\\n\",\n",
        "            \"\\n\",\n",
        "            \"  \\n\",\n",
        "            \"Based on the reasoning above, Provide the best answer and the likelihood that each option is correct from 0.0 to 1.0 in a JSON format. The probabilities should sum to 1.0. For example:\\n\",\n",
        "            \"\\n\",\n",
        "            \"{\\n\",\n",
        "            \"'A': <Probability choice A is correct. As a float from 0.0 to 1.0>,\\n\",\n",
        "            \"'B': <Probability choice B is correct. As a float from 0.0 to 1.0>,\\n\",\n",
        "            \"'C': <Probability choice C is correct. As a float from 0.0 to 1.0>,\\n\",\n",
        "            \"'D': <Probability choice D is correct. As a float from 0.0 to 1.0>,\\n\",\n",
        "            \"'Answer': <Your answer choice here, as a single letter and nothing else.>\\n\",\n",
        "            \"}\\n\",\n",
        "            \"\\n\",\n",
        "            \"All options have a non-zero probability of being correct. No option should have a probability of 0 or 1.\\n\",\n",
        "            \"Be modest about your certainty.  Do not provide any additional reasoning.\\n\",\n",
        "            \"\\n\",\n",
        "            \"Response:\\n\",\n",
        "            \"\\n\",\n",
        "            \"------------------------------------------\\n\",\n",
        "            \"Formatting Dataset:\\n\",\n",
        "            \" Successfully Formatted Dataset\\n\",\n",
        "            \"New Dataset:\\n\"\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"display_data\",\n",
        "          \"data\": {\n",
        "            \"text/plain\": [\n",
        "              \"   Question ID                                      Full Prompt 1  \\\\\\n\",\n",
        "              \"0                0  \\\\nGiven the following question, analyze the op...   \\n\",\n",
        "              \"1                1  \\\\nGiven the following question, analyze the op...   \\n\",\n",
        "              \"2                2  \\\\nGiven the following question, analyze the op...   \\n\",\n",
        "              \"3                3  \\\\nGiven the following question, analyze the op...   \\n\",\n",
        "              \"4                4  \\\\nGiven the following question, analyze the op...   \\n\",\n",
        "              \"\\n\",\n",
        "              \"                                       Full Prompt 2  \\n\",\n",
        "              \"0  \\\\nBased on the reasoning above, Provide the be...  \\n\",\n",
        "              \"1  \\\\nBased on the reasoning above, Provide the be...  \\n\",\n",
        "              \"2  \\\\nBased on the reasoning above, Provide the be...  \\n\",\n",
        "              \"3  \\\\nBased on the reasoning above, Provide the be...  \\n\",\n",
        "              \"4  \\\\nBased on the reasoning above, Provide the be...  \"\n",
        "            ],\n",
        "            \"text/html\": [\n",
        "              \"\\n\",\n",
        "              \"  <div id=\\\"df-1d8e6996-3ba6-496b-afa1-b05da2f4fff6\\\" class=\\\"colab-df-container\\\">\\n\",\n",
        "              \"    <div>\\n\",\n",
        "              \"<style scoped>\\n\",\n",
        "              \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
        "              \"        vertical-align: middle;\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"\\n\",\n",
        "              \"    .dataframe tbody tr th {\\n\",\n",
        "              \"        vertical-align: top;\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"\\n\",\n",
        "              \"    .dataframe thead th {\\n\",\n",
        "              \"        text-align: right;\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"</style>\\n\",\n",
        "              \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
        "              \"  <thead>\\n\",\n",
        "              \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
        "              \"      <th></th>\\n\",\n",
        "              \"      <th>Question ID</th>\\n\",\n",
        "              \"      <th>Full Prompt 1</th>\\n\",\n",
        "              \"      <th>Full Prompt 2</th>\\n\",\n",
        "              \"    </tr>\\n\",\n",
        "              \"  </thead>\\n\",\n",
        "              \"  <tbody>\\n\",\n",
        "              \"    <tr>\\n\",\n",
        "              \"      <th>0</th>\\n\",\n",
        "              \"      <td>0</td>\\n\",\n",
        "              \"      <td>\\\\nGiven the following question, analyze the op...</td>\\n\",\n",
        "              \"      <td>\\\\nBased on the reasoning above, Provide the be...</td>\\n\",\n",
        "              \"    </tr>\\n\",\n",
        "              \"    <tr>\\n\",\n",
        "              \"      <th>1</th>\\n\",\n",
        "              \"      <td>1</td>\\n\",\n",
        "              \"      <td>\\\\nGiven the following question, analyze the op...</td>\\n\",\n",
        "              \"      <td>\\\\nBased on the reasoning above, Provide the be...</td>\\n\",\n",
        "              \"    </tr>\\n\",\n",
        "              \"    <tr>\\n\",\n",
        "              \"      <th>2</th>\\n\",\n",
        "              \"      <td>2</td>\\n\",\n",
        "              \"      <td>\\\\nGiven the following question, analyze the op...</td>\\n\",\n",
        "              \"      <td>\\\\nBased on the reasoning above, Provide the be...</td>\\n\",\n",
        "              \"    </tr>\\n\",\n",
        "              \"    <tr>\\n\",\n",
        "              \"      <th>3</th>\\n\",\n",
        "              \"      <td>3</td>\\n\",\n",
        "              \"      <td>\\\\nGiven the following question, analyze the op...</td>\\n\",\n",
        "              \"      <td>\\\\nBased on the reasoning above, Provide the be...</td>\\n\",\n",
        "              \"    </tr>\\n\",\n",
        "              \"    <tr>\\n\",\n",
        "              \"      <th>4</th>\\n\",\n",
        "              \"      <td>4</td>\\n\",\n",
        "              \"      <td>\\\\nGiven the following question, analyze the op...</td>\\n\",\n",
        "              \"      <td>\\\\nBased on the reasoning above, Provide the be...</td>\\n\",\n",
        "              \"    </tr>\\n\",\n",
        "              \"  </tbody>\\n\",\n",
        "              \"</table>\\n\",\n",
        "              \"</div>\\n\",\n",
        "              \"    <div class=\\\"colab-df-buttons\\\">\\n\",\n",
        "              \"\\n\",\n",
        "              \"  <div class=\\\"colab-df-container\\\">\\n\",\n",
        "              \"    <button class=\\\"colab-df-convert\\\" onclick=\\\"convertToInteractive('df-1d8e6996-3ba6-496b-afa1-b05da2f4fff6')\\\"\\n\",\n",
        "              \"            title=\\\"Convert this dataframe to an interactive table.\\\"\\n\",\n",
        "              \"            style=\\\"display:none;\\\">\\n\",\n",
        "              \"\\n\",\n",
        "              \"  <svg xmlns=\\\"http://www.w3.org/2000/svg\\\" height=\\\"24px\\\" viewBox=\\\"0 -960 960 960\\\">\\n\",\n",
        "              \"    <path d=\\\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\\\"/>\\n\",\n",
        "              \"  </svg>\\n\",\n",
        "              \"    </button>\\n\",\n",
        "              \"\\n\",\n",
        "              \"  <style>\\n\",\n",
        "              \"    .colab-df-container {\\n\",\n",
        "              \"      display:flex;\\n\",\n",
        "              \"      gap: 12px;\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"\\n\",\n",
        "              \"    .colab-df-convert {\\n\",\n",
        "              \"      background-color: #E8F0FE;\\n\",\n",
        "              \"      border: none;\\n\",\n",
        "              \"      border-radius: 50%;\\n\",\n",
        "              \"      cursor: pointer;\\n\",\n",
        "              \"      display: none;\\n\",\n",
        "              \"      fill: #1967D2;\\n\",\n",
        "              \"      height: 32px;\\n\",\n",
        "              \"      padding: 0 0 0 0;\\n\",\n",
        "              \"      width: 32px;\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"\\n\",\n",
        "              \"    .colab-df-convert:hover {\\n\",\n",
        "              \"      background-color: #E2EBFA;\\n\",\n",
        "              \"      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\\n\",\n",
        "              \"      fill: #174EA6;\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"\\n\",\n",
        "              \"    .colab-df-buttons div {\\n\",\n",
        "              \"      margin-bottom: 4px;\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"\\n\",\n",
        "              \"    [theme=dark] .colab-df-convert {\\n\",\n",
        "              \"      background-color: #3B4455;\\n\",\n",
        "              \"      fill: #D2E3FC;\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"\\n\",\n",
        "              \"    [theme=dark] .colab-df-convert:hover {\\n\",\n",
        "              \"      background-color: #434B5C;\\n\",\n",
        "              \"      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\\n\",\n",
        "              \"      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\\n\",\n",
        "              \"      fill: #FFFFFF;\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"  </style>\\n\",\n",
        "              \"\\n\",\n",
        "              \"    <script>\\n\",\n",
        "              \"      const buttonEl =\\n\",\n",
        "              \"        document.querySelector('#df-1d8e6996-3ba6-496b-afa1-b05da2f4fff6 button.colab-df-convert');\\n\",\n",
        "              \"      buttonEl.style.display =\\n\",\n",
        "              \"        google.colab.kernel.accessAllowed ? 'block' : 'none';\\n\",\n",
        "              \"\\n\",\n",
        "              \"      async function convertToInteractive(key) {\\n\",\n",
        "              \"        const element = document.querySelector('#df-1d8e6996-3ba6-496b-afa1-b05da2f4fff6');\\n\",\n",
        "              \"        const dataTable =\\n\",\n",
        "              \"          await google.colab.kernel.invokeFunction('convertToInteractive',\\n\",\n",
        "              \"                                                    [key], {});\\n\",\n",
        "              \"        if (!dataTable) return;\\n\",\n",
        "              \"\\n\",\n",
        "              \"        const docLinkHtml = 'Like what you see? Visit the ' +\\n\",\n",
        "              \"          '<a target=\\\"_blank\\\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\\n\",\n",
        "              \"          + ' to learn more about interactive tables.';\\n\",\n",
        "              \"        element.innerHTML = '';\\n\",\n",
        "              \"        dataTable['output_type'] = 'display_data';\\n\",\n",
        "              \"        await google.colab.output.renderOutput(dataTable, element);\\n\",\n",
        "              \"        const docLink = document.createElement('div');\\n\",\n",
        "              \"        docLink.innerHTML = docLinkHtml;\\n\",\n",
        "              \"        element.appendChild(docLink);\\n\",\n",
        "              \"      }\\n\",\n",
        "              \"    </script>\\n\",\n",
        "              \"  </div>\\n\",\n",
        "              \"\\n\",\n",
        "              \"\\n\",\n",
        "              \"    <div id=\\\"df-e6165cc9-99c3-430a-812c-398a6fe6a82c\\\">\\n\",\n",
        "              \"      <button class=\\\"colab-df-quickchart\\\" onclick=\\\"quickchart('df-e6165cc9-99c3-430a-812c-398a6fe6a82c')\\\"\\n\",\n",
        "              \"                title=\\\"Suggest charts\\\"\\n\",\n",
        "              \"                style=\\\"display:none;\\\">\\n\",\n",
        "              \"\\n\",\n",
        "              \"<svg xmlns=\\\"http://www.w3.org/2000/svg\\\" height=\\\"24px\\\"viewBox=\\\"0 0 24 24\\\"\\n\",\n",
        "              \"     width=\\\"24px\\\">\\n\",\n",
        "              \"    <g>\\n\",\n",
        "              \"        <path d=\\\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\\\"/>\\n\",\n",
        "              \"    </g>\\n\",\n",
        "              \"</svg>\\n\",\n",
        "              \"      </button>\\n\",\n",
        "              \"\\n\",\n",
        "              \"<style>\\n\",\n",
        "              \"  .colab-df-quickchart {\\n\",\n",
        "              \"      --bg-color: #E8F0FE;\\n\",\n",
        "              \"      --fill-color: #1967D2;\\n\",\n",
        "              \"      --hover-bg-color: #E2EBFA;\\n\",\n",
        "              \"      --hover-fill-color: #174EA6;\\n\",\n",
        "              \"      --disabled-fill-color: #AAA;\\n\",\n",
        "              \"      --disabled-bg-color: #DDD;\\n\",\n",
        "              \"  }\\n\",\n",
        "              \"\\n\",\n",
        "              \"  [theme=dark] .colab-df-quickchart {\\n\",\n",
        "              \"      --bg-color: #3B4455;\\n\",\n",
        "              \"      --fill-color: #D2E3FC;\\n\",\n",
        "              \"      --hover-bg-color: #434B5C;\\n\",\n",
        "              \"      --hover-fill-color: #FFFFFF;\\n\",\n",
        "              \"      --disabled-bg-color: #3B4455;\\n\",\n",
        "              \"      --disabled-fill-color: #666;\\n\",\n",
        "              \"  }\\n\",\n",
        "              \"\\n\",\n",
        "              \"  .colab-df-quickchart {\\n\",\n",
        "              \"    background-color: var(--bg-color);\\n\",\n",
        "              \"    border: none;\\n\",\n",
        "              \"    border-radius: 50%;\\n\",\n",
        "              \"    cursor: pointer;\\n\",\n",
        "              \"    display: none;\\n\",\n",
        "              \"    fill: var(--fill-color);\\n\",\n",
        "              \"    height: 32px;\\n\",\n",
        "              \"    padding: 0;\\n\",\n",
        "              \"    width: 32px;\\n\",\n",
        "              \"  }\\n\",\n",
        "              \"\\n\",\n",
        "              \"  .colab-df-quickchart:hover {\\n\",\n",
        "              \"    background-color: var(--hover-bg-color);\\n\",\n",
        "              \"    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\\n\",\n",
        "              \"    fill: var(--button-hover-fill-color);\\n\",\n",
        "              \"  }\\n\",\n",
        "              \"\\n\",\n",
        "              \"  .colab-df-quickchart-complete:disabled,\\n\",\n",
        "              \"  .colab-df-quickchart-complete:disabled:hover {\\n\",\n",
        "              \"    background-color: var(--disabled-bg-color);\\n\",\n",
        "              \"    fill: var(--disabled-fill-color);\\n\",\n",
        "              \"    box-shadow: none;\\n\",\n",
        "              \"  }\\n\",\n",
        "              \"\\n\",\n",
        "              \"  .colab-df-spinner {\\n\",\n",
        "              \"    border: 2px solid var(--fill-color);\\n\",\n",
        "              \"    border-color: transparent;\\n\",\n",
        "              \"    border-bottom-color: var(--fill-color);\\n\",\n",
        "              \"    animation:\\n\",\n",
        "              \"      spin 1s steps(1) infinite;\\n\",\n",
        "              \"  }\\n\",\n",
        "              \"\\n\",\n",
        "              \"  @keyframes spin {\\n\",\n",
        "              \"    0% {\\n\",\n",
        "              \"      border-color: transparent;\\n\",\n",
        "              \"      border-bottom-color: var(--fill-color);\\n\",\n",
        "              \"      border-left-color: var(--fill-color);\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"    20% {\\n\",\n",
        "              \"      border-color: transparent;\\n\",\n",
        "              \"      border-left-color: var(--fill-color);\\n\",\n",
        "              \"      border-top-color: var(--fill-color);\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"    30% {\\n\",\n",
        "              \"      border-color: transparent;\\n\",\n",
        "              \"      border-left-color: var(--fill-color);\\n\",\n",
        "              \"      border-top-color: var(--fill-color);\\n\",\n",
        "              \"      border-right-color: var(--fill-color);\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"    40% {\\n\",\n",
        "              \"      border-color: transparent;\\n\",\n",
        "              \"      border-right-color: var(--fill-color);\\n\",\n",
        "              \"      border-top-color: var(--fill-color);\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"    60% {\\n\",\n",
        "              \"      border-color: transparent;\\n\",\n",
        "              \"      border-right-color: var(--fill-color);\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"    80% {\\n\",\n",
        "              \"      border-color: transparent;\\n\",\n",
        "              \"      border-right-color: var(--fill-color);\\n\",\n",
        "              \"      border-bottom-color: var(--fill-color);\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"    90% {\\n\",\n",
        "              \"      border-color: transparent;\\n\",\n",
        "              \"      border-bottom-color: var(--fill-color);\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"  }\\n\",\n",
        "              \"</style>\\n\",\n",
        "              \"\\n\",\n",
        "              \"      <script>\\n\",\n",
        "              \"        async function quickchart(key) {\\n\",\n",
        "              \"          const quickchartButtonEl =\\n\",\n",
        "              \"            document.querySelector('#' + key + ' button');\\n\",\n",
        "              \"          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\\n\",\n",
        "              \"          quickchartButtonEl.classList.add('colab-df-spinner');\\n\",\n",
        "              \"          try {\\n\",\n",
        "              \"            const charts = await google.colab.kernel.invokeFunction(\\n\",\n",
        "              \"                'suggestCharts', [key], {});\\n\",\n",
        "              \"          } catch (error) {\\n\",\n",
        "              \"            console.error('Error during call to suggestCharts:', error);\\n\",\n",
        "              \"          }\\n\",\n",
        "              \"          quickchartButtonEl.classList.remove('colab-df-spinner');\\n\",\n",
        "              \"          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\\n\",\n",
        "              \"        }\\n\",\n",
        "              \"        (() => {\\n\",\n",
        "              \"          let quickchartButtonEl =\\n\",\n",
        "              \"            document.querySelector('#df-e6165cc9-99c3-430a-812c-398a6fe6a82c button');\\n\",\n",
        "              \"          quickchartButtonEl.style.display =\\n\",\n",
        "              \"            google.colab.kernel.accessAllowed ? 'block' : 'none';\\n\",\n",
        "              \"        })();\\n\",\n",
        "              \"      </script>\\n\",\n",
        "              \"    </div>\\n\",\n",
        "              \"\\n\",\n",
        "              \"    </div>\\n\",\n",
        "              \"  </div>\\n\"\n",
        "            ],\n",
        "            \"application/vnd.google.colaboratory.intrinsic+json\": {\n",
        "              \"type\": \"dataframe\",\n",
        "              \"summary\": \"{\\n  \\\"name\\\": \\\"display(new_dataset\\\",\\n  \\\"rows\\\": 5,\\n  \\\"fields\\\": [\\n    {\\n      \\\"column\\\": \\\"Question ID\\\",\\n      \\\"properties\\\": {\\n        \\\"dtype\\\": \\\"number\\\",\\n        \\\"std\\\": 1,\\n        \\\"min\\\": 0,\\n        \\\"max\\\": 4,\\n        \\\"num_unique_values\\\": 5,\\n        \\\"samples\\\": [\\n          1,\\n          4,\\n          2\\n        ],\\n        \\\"semantic_type\\\": \\\"\\\",\\n        \\\"description\\\": \\\"\\\"\\n      }\\n    },\\n    {\\n      \\\"column\\\": \\\"Full Prompt 1\\\",\\n      \\\"properties\\\": {\\n        \\\"dtype\\\": \\\"string\\\",\\n        \\\"num_unique_values\\\": 5,\\n        \\\"samples\\\": [\\n          \\\"\\\\nGiven the following question, analyze the options, and provide a concise reasoning for your selected answer. Your reasoning should not exceed 100 words. After your explanation, clearly state your answer by choosing one of the options listed (A, B, C, or D).\\\\n\\\\nQuestion: What term in biotechnology means a genetically exact copy of an organism?\\\\nOptions:\\\\nA) adult\\\\nB) male\\\\nC) phenotype\\\\nD) clone\\\\n\\\\n\\\\nPlease provide your reasoning first, limited to 100 words, and consider how certain you should be of your answer.\\\\nReasoning: \\\",\\n          \\\"\\\\nGiven the following question, analyze the options, and provide a concise reasoning for your selected answer. Your reasoning should not exceed 100 words. After your explanation, clearly state your answer by choosing one of the options listed (A, B, C, or D).\\\\n\\\\nQuestion: Ice cores, varves and what else indicate the environmental conditions at the time of their creation?\\\\nOptions:\\\\nA) mountain ranges\\\\nB) fossils\\\\nC) tree rings\\\\nD) magma\\\\n\\\\n\\\\nPlease provide your reasoning first, limited to 100 words, and consider how certain you should be of your answer.\\\\nReasoning: \\\",\\n          \\\"\\\\nGiven the following question, analyze the options, and provide a concise reasoning for your selected answer. Your reasoning should not exceed 100 words. After your explanation, clearly state your answer by choosing one of the options listed (A, B, C, or D).\\\\n\\\\nQuestion: Vertebrata are characterized by the presence of what?\\\\nOptions:\\\\nA) backbone\\\\nB) Bones\\\\nC) Muscles\\\\nD) Thumbs\\\\n\\\\n\\\\nPlease provide your reasoning first, limited to 100 words, and consider how certain you should be of your answer.\\\\nReasoning: \\\"\\n        ],\\n        \\\"semantic_type\\\": \\\"\\\",\\n        \\\"description\\\": \\\"\\\"\\n      }\\n    },\\n    {\\n      \\\"column\\\": \\\"Full Prompt 2\\\",\\n      \\\"properties\\\": {\\n        \\\"dtype\\\": \\\"category\\\",\\n        \\\"num_unique_values\\\": 1,\\n        \\\"samples\\\": [\\n          \\\"\\\\nBased on the reasoning above, Provide the best answer and the likelihood that each option is correct from 0.0 to 1.0 in a JSON format. The probabilities should sum to 1.0. For example:\\\\n\\\\n{\\\\n'A': <Probability choice A is correct. As a float from 0.0 to 1.0>,\\\\n'B': <Probability choice B is correct. As a float from 0.0 to 1.0>,\\\\n'C': <Probability choice C is correct. As a float from 0.0 to 1.0>,\\\\n'D': <Probability choice D is correct. As a float from 0.0 to 1.0>,\\\\n'Answer': <Your answer choice here, as a single letter and nothing else.>\\\\n}\\\\n\\\\nAll options have a non-zero probability of being correct. No option should have a probability of 0 or 1.\\\\nBe modest about your certainty.  Do not provide any additional reasoning.\\\\n\\\\nResponse:\\\\n\\\"\\n        ],\\n        \\\"semantic_type\\\": \\\"\\\",\\n        \\\"description\\\": \\\"\\\"\\n      }\\n    }\\n  ]\\n}\"\n",
        "            }\n",
        "          },\n",
        "          \"metadata\": {}\n",
        "        }\n",
        "      ],\n",
        "      \"source\": [\n",
        "        \"## Import Dataset\\n\",\n",
        "        \"print('-' *42)\\n\",\n",
        "        \"file_path = '/content/sciq_test_formatted.csv'\\n\",\n",
        "        \"print(f'Importing Dataset: {file_path}')\\n\",\n",
        "        \"dataset = pd.read_csv(file_path)\\n\",\n",
        "        \"display(dataset.head())\\n\",\n",
        "        \"\\n\",\n",
        "        \"## Edit System Prompts\\n\",\n",
        "        \"print('-' *42)\\n\",\n",
        "        \"print('Editing System Prompts:')\\n\",\n",
        "        \"\\n\",\n",
        "        \"sys_prompt1 = '''\\n\",\n",
        "        \"Given the following question, analyze the options, and provide a concise reasoning for your selected answer. Your reasoning should not exceed 100 words. After your explanation, clearly state your answer by choosing one of the options listed (A, B, C, or D).\\n\",\n",
        "        \"\\n\",\n",
        "        \"Question: ${Question}\\n\",\n",
        "        \"Options:\\n\",\n",
        "        \"A) ${Option A}\\n\",\n",
        "        \"B) ${Option B}\\n\",\n",
        "        \"C) ${Option C}\\n\",\n",
        "        \"D) ${Option D}\\n\",\n",
        "        \"\\n\",\n",
        "        \"\\n\",\n",
        "        \"Please provide your reasoning first, limited to 100 words, and consider how certain you should be of your answer.\\n\",\n",
        "        \"Reasoning: <Your concise reasoning here. Max 100 words>\\n\",\n",
        "        \"'''\\n\",\n",
        "        \"sys_prompt2 = '''\\n\",\n",
        "        \"Based on the reasoning above, Provide the best answer and the likelihood that each option is correct from 0.0 to 1.0 in a JSON format. The probabilities should sum to 1.0. For example:\\n\",\n",
        "        \"\\n\",\n",
        "        \"{\\n\",\n",
        "        \"'A': <Probability choice A is correct. As a float from 0.0 to 1.0>,\\n\",\n",
        "        \"'B': <Probability choice B is correct. As a float from 0.0 to 1.0>,\\n\",\n",
        "        \"'C': <Probability choice C is correct. As a float from 0.0 to 1.0>,\\n\",\n",
        "        \"'D': <Probability choice D is correct. As a float from 0.0 to 1.0>,\\n\",\n",
        "        \"'Answer': <Your answer choice here, as a single letter and nothing else.>\\n\",\n",
        "        \"}\\n\",\n",
        "        \"\\n\",\n",
        "        \"All options have a non-zero probability of being correct. No option should have a probability of 0 or 1.\\n\",\n",
        "        \"Be modest about your certainty.  Do not provide any additional reasoning.\\n\",\n",
        "        \"\\n\",\n",
        "        \"Response:\\n\",\n",
        "        \"'''\\n\",\n",
        "        \"\\n\",\n",
        "        \"print('System Prompts:')\\n\",\n",
        "        \"print(f'  {sys_prompt1}')\\n\",\n",
        "        \"print(f'  {sys_prompt2}')\\n\",\n",
        "        \"\\n\",\n",
        "        \"\\n\",\n",
        "        \"\\n\",\n",
        "        \"## Format DF\\n\",\n",
        "        \"print('-' *42)\\n\",\n",
        "        \"print('Formatting Dataset:')\\n\",\n",
        "        \"new_dataset = format_df(dataset)\\n\",\n",
        "        \"print(' Successfully Formatted Dataset')\\n\",\n",
        "        \"print('New Dataset:')\\n\",\n",
        "        \"display(new_dataset.head())\\n\",\n",
        "        \"\\n\",\n",
        "        \"\\n\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": 6,\n",
        "      \"metadata\": {\n",
        "        \"id\": \"xcQdnUyXn5ak\",\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\"\n",
        "        },\n",
        "        \"outputId\": \"dfac45d5-fea3-4f73-b8c4-6e87ab804881\"\n",
        "      },\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"\\n\",\n",
        "            \"Given the following question, analyze the options, and provide a concise reasoning for your selected answer. Your reasoning should not exceed 100 words. After your explanation, clearly state your answer by choosing one of the options listed (A, B, C, or D).\\n\",\n",
        "            \"\\n\",\n",
        "            \"Question: The temperature at which a substance melts is called its what point?\\n\",\n",
        "            \"Options:\\n\",\n",
        "            \"A) boiling\\n\",\n",
        "            \"B) change\\n\",\n",
        "            \"C) melting\\n\",\n",
        "            \"D) freezing\\n\",\n",
        "            \"\\n\",\n",
        "            \"\\n\",\n",
        "            \"Please provide your reasoning first, limited to 100 words, and consider how certain you should be of your answer.\\n\",\n",
        "            \"Reasoning: \\n\"\n",
        "          ]\n",
        "        }\n",
        "      ],\n",
        "      \"source\": [\n",
        "        \"print(new_dataset['Full Prompt 1'].iloc[64])\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"id\": \"AR8o1Z88oI6P\"\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"## Initialize Models\\n\",\n",
        "        \"print('-' *42)\\n\",\n",
        "        \"print('Initializing Models:')\\n\",\n",
        "        \"my_closed_models = {\\n\",\n",
        "        \"    'GPT': {\\n\",\n",
        "        \"        'api_key_name': 'gpt_api_key', # Name of the key to retrieve from userdata\\n\",\n",
        "        \"        'models': [\\n\",\n",
        "        \"            'gpt-4',\\n\",\n",
        "        \"            'gpt-3.5-turbo'\\n\",\n",
        "        \"        ]\\n\",\n",
        "        \"    },\\n\",\n",
        "        \"    'Claude': {\\n\",\n",
        "        \"        'api_key_name': 'claude_api_key', # Name of the key to retrieve from userdata\\n\",\n",
        "        \"        'models': [\\n\",\n",
        "        \"            'claude-3-7-sonnet-20250219',\\n\",\n",
        "        \"            'claude-3-haiku-20240307'\\n\",\n",
        "        \"        ]\\n\",\n",
        "        \"    },\\n\",\n",
        "        \"    'Gemini': {\\n\",\n",
        "        \"        'api_key_name': 'gemini_api_key', # Name of the key to retrieve from userdata\\n\",\n",
        "        \"        'models': [\\n\",\n",
        "        \"            'gemini-1.5-flash',\\n\",\n",
        "        \"            'gemini-2.5-pro-preview-06-05'\\n\",\n",
        "        \"        ]\\n\",\n",
        "        \"    }\\n\",\n",
        "        \"}\\n\",\n",
        "        \"\\n\",\n",
        "        \"closed_models = init_models(my_closed_models)\\n\",\n",
        "        \"print(' Successfully Initialied Models')\\n\",\n",
        "        \"\\n\",\n",
        "        \"## Test Models on LSAT\\n\",\n",
        "        \"print('-' *42)\\n\",\n",
        "        \"print('Testing Models:')\\n\",\n",
        "        \"\\n\",\n",
        "        \"test_models_sequential_by_question(new_dataset, closed_models, debug=False, stop = 1000)\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": 7,\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 827,\n",
        "          \"referenced_widgets\": [\n",
        "            \"5fdda4e7efb644eaa0a0844b9177c1d4\",\n",
        "            \"3a1f19eded9d485498d261123c240740\",\n",
        "            \"42669ab4f7cf4f0398b757e50a4f3fb5\",\n",
        "            \"7648713ced4c4644aeb6aeb4049a8f11\",\n",
        "            \"4a7d7f66efe14f06a407241b8f199b03\",\n",
        "            \"220e70fcadae4407ae6d87f015b6500f\",\n",
        "            \"942684a56a00491f92cc8ce8edaa7fb9\",\n",
        "            \"95fa09105d8640e6a391b33056ce018f\",\n",
        "            \"e5dfa6933a17464e97aa0f14381aaf70\",\n",
        "            \"6c3157c8ac4048629cd7be4755e7e07a\",\n",
        "            \"4f480b7090364b5d95cb25b84f982149\",\n",
        "            \"b7d00a1b65894b7ba7b8e00703c73e9d\",\n",
        "            \"323c757d9dd04e818d33d780cc77d3fc\",\n",
        "            \"6f67d43cc0b7422b898f27a8f6a3e33b\",\n",
        "            \"56369256ccc8442db786aea1d7e274a6\",\n",
        "            \"cac07e5f6f934cfb9bdebc556236112e\",\n",
        "            \"7c44d8cf2834456cbbb5137230299947\",\n",
        "            \"d1776d7800ea41138f1e4f77de0c77e6\",\n",
        "            \"2f99e211638a4410b35923895ff24251\",\n",
        "            \"2f1c1f6c313649059af9b2af09115720\",\n",
        "            \"cbf5ffe9bc664a6488b4a6288c237bea\",\n",
        "            \"0a976d5ffda84f57bc7c77f495e71d5e\",\n",
        "            \"30d3f72ec53f48938da84da121f58200\",\n",
        "            \"f65c1cbd834c4e5d9893536bd6f346dd\",\n",
        "            \"2001c04948f2494c8f39e52f3bf7f311\",\n",
        "            \"29a80705829342e7a9b0996419edc23b\",\n",
        "            \"dbab24ca67ec42aba171a79f7b0fe471\",\n",
        "            \"6d14d713d2e24df8a1ad0e3b6b61b20f\",\n",
        "            \"df01bca70ea94b8e8102412b758b26fb\",\n",
        "            \"ea6ffdbdb3fd4d34a3644d5d5b8223e6\",\n",
        "            \"bb700022a2054ca8a5a3143f658aa0b0\",\n",
        "            \"88b2e8a3572d4827bb0d7364930cdfec\",\n",
        "            \"c820f0c30f4b417fae603c1579855544\"\n",
        "          ]\n",
        "        },\n",
        "        \"id\": \"mq00cM-YG1lR\",\n",
        "        \"outputId\": \"f03a633c-f701-446c-8c4e-6fa7984ad51a\"\n",
        "      },\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"Downloading Tokenizer for meta-llama/Llama-3.1-8B-Instruct\\n\",\n",
        "            \"Downloading Model Weights for meta-llama/Llama-3.1-8B-Instruct\\n\"\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"display_data\",\n",
        "          \"data\": {\n",
        "            \"text/plain\": [\n",
        "              \"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\"\n",
        "            ],\n",
        "            \"application/vnd.jupyter.widget-view+json\": {\n",
        "              \"version_major\": 2,\n",
        "              \"version_minor\": 0,\n",
        "              \"model_id\": \"5fdda4e7efb644eaa0a0844b9177c1d4\"\n",
        "            }\n",
        "          },\n",
        "          \"metadata\": {}\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"display_data\",\n",
        "          \"data\": {\n",
        "            \"text/plain\": [\n",
        "              \"generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]\"\n",
        "            ],\n",
        "            \"application/vnd.jupyter.widget-view+json\": {\n",
        "              \"version_major\": 2,\n",
        "              \"version_minor\": 0,\n",
        "              \"model_id\": \"b7d00a1b65894b7ba7b8e00703c73e9d\"\n",
        "            }\n",
        "          },\n",
        "          \"metadata\": {}\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stderr\",\n",
        "          \"text\": [\n",
        "            \"Device set to use cuda:0\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\"\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"display_data\",\n",
        "          \"data\": {\n",
        "            \"text/plain\": [\n",
        "              \"Processing Questions:   0%|          | 0/3 [00:00<?, ?it/s]\"\n",
        "            ],\n",
        "            \"application/vnd.jupyter.widget-view+json\": {\n",
        "              \"version_major\": 2,\n",
        "              \"version_minor\": 0,\n",
        "              \"model_id\": \"30d3f72ec53f48938da84da121f58200\"\n",
        "            }\n",
        "          },\n",
        "          \"metadata\": {}\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"error\",\n",
        "          \"ename\": \"UnboundLocalError\",\n",
        "          \"evalue\": \"cannot access local variable 'question_num' where it is not associated with a value\",\n",
        "          \"traceback\": [\n",
        "            \"\\u001b[0;31m---------------------------------------------------------------------------\\u001b[0m\",\n",
        "            \"\\u001b[0;31mKeyError\\u001b[0m                                  Traceback (most recent call last)\",\n",
        "            \"\\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\\u001b[0m in \\u001b[0;36mget_loc\\u001b[0;34m(self, key)\\u001b[0m\\n\\u001b[1;32m   3804\\u001b[0m         \\u001b[0;32mtry\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m-> 3805\\u001b[0;31m             \\u001b[0;32mreturn\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0m_engine\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mget_loc\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mcasted_key\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m   3806\\u001b[0m         \\u001b[0;32mexcept\\u001b[0m \\u001b[0mKeyError\\u001b[0m \\u001b[0;32mas\\u001b[0m \\u001b[0merr\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
        "            \"\\u001b[0;32mindex.pyx\\u001b[0m in \\u001b[0;36mpandas._libs.index.IndexEngine.get_loc\\u001b[0;34m()\\u001b[0m\\n\",\n",
        "            \"\\u001b[0;32mindex.pyx\\u001b[0m in \\u001b[0;36mpandas._libs.index.IndexEngine.get_loc\\u001b[0;34m()\\u001b[0m\\n\",\n",
        "            \"\\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\\u001b[0m in \\u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\\u001b[0;34m()\\u001b[0m\\n\",\n",
        "            \"\\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\\u001b[0m in \\u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\\u001b[0;34m()\\u001b[0m\\n\",\n",
        "            \"\\u001b[0;31mKeyError\\u001b[0m: 'Question ID'\",\n",
        "            \"\\nThe above exception was the direct cause of the following exception:\\n\",\n",
        "            \"\\u001b[0;31mKeyError\\u001b[0m                                  Traceback (most recent call last)\",\n",
        "            \"\\u001b[0;32m/tmp/ipython-input-4-2780597552.py\\u001b[0m in \\u001b[0;36mtest_open_model_sciq\\u001b[0;34m(model, df, debug)\\u001b[0m\\n\\u001b[1;32m    304\\u001b[0m       \\u001b[0;31m## Question Information\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m--> 305\\u001b[0;31m       \\u001b[0mquestion_num\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mdf\\u001b[0m\\u001b[0;34m[\\u001b[0m\\u001b[0;34m'Question ID'\\u001b[0m\\u001b[0;34m]\\u001b[0m\\u001b[0;34m[\\u001b[0m\\u001b[0mi\\u001b[0m\\u001b[0;34m]\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m    306\\u001b[0m       \\u001b[0mquestion_text\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mdf\\u001b[0m\\u001b[0;34m[\\u001b[0m\\u001b[0;34m'Full Prompt 1'\\u001b[0m\\u001b[0;34m]\\u001b[0m\\u001b[0;34m[\\u001b[0m\\u001b[0mi\\u001b[0m\\u001b[0;34m]\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
        "            \"\\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\\u001b[0m in \\u001b[0;36m__getitem__\\u001b[0;34m(self, key)\\u001b[0m\\n\\u001b[1;32m   4101\\u001b[0m                 \\u001b[0;32mreturn\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0m_getitem_multilevel\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mkey\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m-> 4102\\u001b[0;31m             \\u001b[0mindexer\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mcolumns\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mget_loc\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mkey\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m   4103\\u001b[0m             \\u001b[0;32mif\\u001b[0m \\u001b[0mis_integer\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mindexer\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
        "            \"\\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\\u001b[0m in \\u001b[0;36mget_loc\\u001b[0;34m(self, key)\\u001b[0m\\n\\u001b[1;32m   3811\\u001b[0m                 \\u001b[0;32mraise\\u001b[0m \\u001b[0mInvalidIndexError\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mkey\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m-> 3812\\u001b[0;31m             \\u001b[0;32mraise\\u001b[0m \\u001b[0mKeyError\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mkey\\u001b[0m\\u001b[0;34m)\\u001b[0m \\u001b[0;32mfrom\\u001b[0m \\u001b[0merr\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m   3813\\u001b[0m         \\u001b[0;32mexcept\\u001b[0m \\u001b[0mTypeError\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
        "            \"\\u001b[0;31mKeyError\\u001b[0m: 'Question ID'\",\n",
        "            \"\\nDuring handling of the above exception, another exception occurred:\\n\",\n",
        "            \"\\u001b[0;31mUnboundLocalError\\u001b[0m                         Traceback (most recent call last)\",\n",
        "            \"\\u001b[0;32m/tmp/ipython-input-7-1176528903.py\\u001b[0m in \\u001b[0;36m<cell line: 0>\\u001b[0;34m()\\u001b[0m\\n\\u001b[1;32m     33\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m     34\\u001b[0m Response: '''\\n\\u001b[0;32m---> 35\\u001b[0;31m \\u001b[0mllama_results\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mtest_open_model_sciq\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mmy_llama\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mnew_dataset\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mdebug\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0;32mTrue\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m     36\\u001b[0m \\u001b[0mprint\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m'Finished benchmarking on model:'\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m     37\\u001b[0m \\u001b[0mdisplay\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mllama_results\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
        "            \"\\u001b[0;32m/tmp/ipython-input-4-2780597552.py\\u001b[0m in \\u001b[0;36mtest_open_model_sciq\\u001b[0;34m(model, df, debug)\\u001b[0m\\n\\u001b[1;32m    338\\u001b[0m     \\u001b[0;32mexcept\\u001b[0m \\u001b[0mException\\u001b[0m \\u001b[0;32mas\\u001b[0m \\u001b[0me\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    339\\u001b[0m       new_row = pd.DataFrame([{\\n\\u001b[0;32m--> 340\\u001b[0;31m           \\u001b[0;34m'Question ID'\\u001b[0m\\u001b[0;34m:\\u001b[0m \\u001b[0mquestion_num\\u001b[0m\\u001b[0;34m,\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m    341\\u001b[0m           \\u001b[0;34m'Question'\\u001b[0m\\u001b[0;34m:\\u001b[0m \\u001b[0mquestion_text\\u001b[0m\\u001b[0;34m,\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    342\\u001b[0m           \\u001b[0;34m'Stated Confidence'\\u001b[0m\\u001b[0;34m:\\u001b[0m \\u001b[0;34m'ERROR'\\u001b[0m\\u001b[0;34m,\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
        "            \"\\u001b[0;31mUnboundLocalError\\u001b[0m: cannot access local variable 'question_num' where it is not associated with a value\"\n",
        "          ]\n",
        "        }\n",
        "      ],\n",
        "      \"source\": [\n",
        "        \"\\n\",\n",
        "        \"##------------------------------------------------------------------------------\\n\",\n",
        "        \"##                             OPEN MODELS\\n\",\n",
        "        \"##------------------------------------------------------------------------------\\n\",\n",
        "        \"\\n\",\n",
        "        \"## Get llama:\\n\",\n",
        "        \"\\n\",\n",
        "        \"HF_TOKEN = userdata.get('hf_llama_token')\\n\",\n",
        "        \"model_name = 'meta-llama/Llama-3.1-8B-Instruct'\\n\",\n",
        "        \"\\n\",\n",
        "        \"\\n\",\n",
        "        \"my_llama = LlamaModel(name = model_name, key = HF_TOKEN, MaxTokens = 250)\\n\",\n",
        "        \"\\n\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"\\n\",\n",
        "        \"## Get Results\\n\",\n",
        "        \"\\n\",\n",
        "        \"sys_prompt2 = '''\\n\",\n",
        "        \"Based on the reasoning above, Provide the best answer and the likelihood that each option is correct from 0.0 to 1.0 in a JSON format. The probabilities should sum to 1.0. For example:\\n\",\n",
        "        \"\\n\",\n",
        "        \"{\\n\",\n",
        "        \"'Answer': <Your answer choice here, as a single letter and nothing else>,\\n\",\n",
        "        \"'A': <Probability choice A is correct. As a float from 0.0 to 1.0>,\\n\",\n",
        "        \"'B': <Probability choice B is correct. As a float from 0.0 to 1.0>,\\n\",\n",
        "        \"'C': <Probability choice C is correct. As a float from 0.0 to 1.0>,\\n\",\n",
        "        \"'D': <Probability choice D is correct. As a float from 0.0 to 1.0>,\\n\",\n",
        "        \"'E': <Probability choice E is correct. As a float from 0.0 to 1.0>\\n\",\n",
        "        \"}<|eot_id|>\\n\",\n",
        "        \"\\n\",\n",
        "        \"All options have a non-zero probability of being correct. No option should have a probability of 0 or 1.\\n\",\n",
        "        \"Be modest about your certainty.  Do not provide any additional reasoning.\\n\",\n",
        "        \"\\n\",\n",
        "        \"Response: '''\\n\",\n",
        "        \"\\n\",\n",
        "        \"\\n\",\n",
        "        \"llama_results = test_open_model_sciq(my_llama, new_dataset, debug = False)\\n\",\n",
        "        \"print('Finished benchmarking on model:')\\n\",\n",
        "        \"display(llama_results)\\n\",\n",
        "        \"\\n\",\n",
        "        \"\\n\",\n",
        "        \"## Save to drive\\n\",\n",
        "        \"\\n\",\n",
        "        \"sciq_folder_path = '/content/drive/MyDrive/SciQ'\\n\",\n",
        "        \"\\n\",\n",
        "        \"\\n\",\n",
        "        \"if not os.path.exists(sciq_folder_path):\\n\",\n",
        "        \"    os.makedirs(sciq_folder_path)\\n\",\n",
        "        \"    print(f\\\"Created folder: {sciq_folder_path}\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Define the full path for the CSV file\\n\",\n",
        "        \"output_filename = f'SciQ_{model_name}'\\n\",\n",
        "        \"output_filename = output_filename.replace('/', '_').replace('-','_').replace('.','_') + '.csv'\\n\",\n",
        "        \"output_path = os.path.join(sciq_folder_path, output_filename)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# 2. Save the DataFrame to the specified path\\n\",\n",
        "        \"llama_results.to_csv(output_path, index=False)\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(f\\\"Successfully saved llama_results to {output_path}\\\")\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 1000,\n",
        "          \"referenced_widgets\": [\n",
        "            \"bcd81506a60544248d6209f2e88f0d56\",\n",
        "            \"37c9f6b6bbcf462a9758581e68a80438\",\n",
        "            \"4cb25320b003454b9dc694503a5f7965\",\n",
        "            \"6b8f3cd154294f94bd12d3c7403c612c\",\n",
        "            \"78945499c68c4a6ba0907ede0ee96ed4\",\n",
        "            \"a8ea273c994e42cf858b8f850bbbea08\",\n",
        "            \"aeaef1b15c2a428092e858bdb337c72f\",\n",
        "            \"93da93837b564f5db67f2aa677d14d62\",\n",
        "            \"6acab8ff9cff4075b940dfaa01cd5cba\",\n",
        "            \"6701e7f9060e49e8bdac1d61272948ac\",\n",
        "            \"5a61dd3d8feb4a03a2c3a9fe6ceeb7a3\"\n",
        "          ]\n",
        "        },\n",
        "        \"id\": \"tX6dCf4iMXiU\",\n",
        "        \"outputId\": \"29aba67e-f5a4-44da-80ff-d86c02793428\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"data\": {\n",
        "            \"application/vnd.jupyter.widget-view+json\": {\n",
        "              \"model_id\": \"bcd81506a60544248d6209f2e88f0d56\",\n",
        "              \"version_major\": 2,\n",
        "              \"version_minor\": 0\n",
        "            },\n",
        "            \"text/plain\": [\n",
        "              \"Processing Questions:   0%|          | 0/1000 [00:00<?, ?it/s]\"\n",
        "            ]\n",
        "          },\n",
        "          \"metadata\": {},\n",
        "          \"output_type\": \"display_data\"\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stderr\",\n",
        "          \"text\": [\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\",\n",
        "            \"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\\n\"\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"question = llama_results['Question'].iloc[0]\\n\",\n",
        "        \"sc = llama_results['Stated Confidence'].iloc[0]\\n\",\n",
        "        \"reasoning = llama_results['Reasoning'].iloc[0]\\n\",\n",
        "        \"print(f'Question: {question}')\\n\",\n",
        "        \"print('-' *42)\\n\",\n",
        "        \"print(f'Reasoning: {reasoning}')\\n\",\n",
        "        \"print('-' *42)\\n\",\n",
        "        \"print(f'Confidence: {sc}')\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\"\n",
        "        },\n",
        "        \"id\": \"6XrRgwB-NlfO\",\n",
        "        \"outputId\": \"685d9e28-f0ad-4826-e114-621e7c57a5b8\"\n",
        "      },\n",
        "      \"execution_count\": 15,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"Question: \\n\",\n",
        "            \"Given the following question, analyze the options, and provide a concise reasoning for your selected answer. Your reasoning should not exceed 100 words. After your explanation, clearly state your answer by choosing one of the options listed (A, B, C, or D).\\n\",\n",
        "            \"\\n\",\n",
        "            \"Question: Compounds that are capable of accepting electrons, such as o 2 or f2, are called what?\\n\",\n",
        "            \"Options:\\n\",\n",
        "            \"A) antioxidants\\n\",\n",
        "            \"B) Oxygen\\n\",\n",
        "            \"C) oxidants\\n\",\n",
        "            \"D) residues\\n\",\n",
        "            \"\\n\",\n",
        "            \"\\n\",\n",
        "            \"Please provide your reasoning first, limited to 100 words, and consider how certain you should be of your answer.\\n\",\n",
        "            \"Reasoning: \\n\",\n",
        "            \"------------------------------------------\\n\",\n",
        "            \"Reasoning:  Compounds that accept electrons are known as oxidants. This is because they cause oxidation, which is the loss of electrons. Oxidants are often involved in chemical reactions that result in the transfer of electrons. In the context of the question, oxygen (o 2) and fluorine (f2) are both capable of accepting electrons, making them examples of oxidants. Therefore, the correct answer is C) oxidants. I am 90% certain of this answer.\\n\",\n",
        "            \"\\n\",\n",
        "            \"Answer: C) oxidants.  I am 90% certain of this answer.  I am not 100% certain because I am not an expert in chemistry, but based on my knowledge, I believe that the correct answer is C) oxidants.  I am 90% certain because I have a good understanding of the concept of oxidation and the role of oxidants in chemical reactions.  However, I may be missing some nuance or detail that would make me 100% certain.  Nevertheless, based on my analysis, I believe that C) oxidants is the correct answer.  I am willing to be corrected if I am wrong.  I am 90% certain because I have a good understanding of the concept of oxidation and\\n\",\n",
        "            \"------------------------------------------\\n\",\n",
        "            \"Confidence: {'Answer': 'C', 'A': 0.05, 'B': 0.1, 'C': 0.9, 'D': 0.05}\\n\"\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  ],\n",
        "  \"metadata\": {\n",
        "    \"accelerator\": \"GPU\",\n",
        "    \"colab\": {\n",
        "      \"gpuType\": \"A100\",\n",
        "      \"machine_shape\": \"hm\",\n",
        "      \"provenance\": [],\n",
        "      \"mount_file_id\": \"1e3gILiNk_1_2d5C-i-aVEWCacRR_cg1G\",\n",
        "      \"authorship_tag\": \"ABX9TyOIoCVRIyLXjKLcRXdVYF37\",\n",
        "      \"include_colab_link\": true\n",
        "    },\n",
        "    \"kernelspec\": {\n",
        "      \"display_name\": \"Python 3\",\n",
        "      \"name\": \"python3\"\n",
        "    },\n",
        "    \"language_info\": {\n",
        "      \"name\": \"python\"\n",
        "    },\n",
        "    \"widgets\": {\n",
        "      \"application/vnd.jupyter.widget-state+json\": {\n",
        "        \"5fdda4e7efb644eaa0a0844b9177c1d4\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"HBoxModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_dom_classes\": [],\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"HBoxModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_view_module_version\": \"1.5.0\",\n",
        "            \"_view_name\": \"HBoxView\",\n",
        "            \"box_style\": \"\",\n",
        "            \"children\": [\n",
        "              \"IPY_MODEL_3a1f19eded9d485498d261123c240740\",\n",
        "              \"IPY_MODEL_42669ab4f7cf4f0398b757e50a4f3fb5\",\n",
        "              \"IPY_MODEL_7648713ced4c4644aeb6aeb4049a8f11\"\n",
        "            ],\n",
        "            \"layout\": \"IPY_MODEL_4a7d7f66efe14f06a407241b8f199b03\"\n",
        "          }\n",
        "        },\n",
        "        \"3a1f19eded9d485498d261123c240740\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"HTMLModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_dom_classes\": [],\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"HTMLModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_view_module_version\": \"1.5.0\",\n",
        "            \"_view_name\": \"HTMLView\",\n",
        "            \"description\": \"\",\n",
        "            \"description_tooltip\": null,\n",
        "            \"layout\": \"IPY_MODEL_220e70fcadae4407ae6d87f015b6500f\",\n",
        "            \"placeholder\": \"​\",\n",
        "            \"style\": \"IPY_MODEL_942684a56a00491f92cc8ce8edaa7fb9\",\n",
        "            \"value\": \"Loading checkpoint shards: 100%\"\n",
        "          }\n",
        "        },\n",
        "        \"42669ab4f7cf4f0398b757e50a4f3fb5\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"FloatProgressModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_dom_classes\": [],\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"FloatProgressModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_view_module_version\": \"1.5.0\",\n",
        "            \"_view_name\": \"ProgressView\",\n",
        "            \"bar_style\": \"success\",\n",
        "            \"description\": \"\",\n",
        "            \"description_tooltip\": null,\n",
        "            \"layout\": \"IPY_MODEL_95fa09105d8640e6a391b33056ce018f\",\n",
        "            \"max\": 4,\n",
        "            \"min\": 0,\n",
        "            \"orientation\": \"horizontal\",\n",
        "            \"style\": \"IPY_MODEL_e5dfa6933a17464e97aa0f14381aaf70\",\n",
        "            \"value\": 4\n",
        "          }\n",
        "        },\n",
        "        \"7648713ced4c4644aeb6aeb4049a8f11\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"HTMLModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_dom_classes\": [],\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"HTMLModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_view_module_version\": \"1.5.0\",\n",
        "            \"_view_name\": \"HTMLView\",\n",
        "            \"description\": \"\",\n",
        "            \"description_tooltip\": null,\n",
        "            \"layout\": \"IPY_MODEL_6c3157c8ac4048629cd7be4755e7e07a\",\n",
        "            \"placeholder\": \"​\",\n",
        "            \"style\": \"IPY_MODEL_4f480b7090364b5d95cb25b84f982149\",\n",
        "            \"value\": \" 4/4 [00:04&lt;00:00,  1.00s/it]\"\n",
        "          }\n",
        "        },\n",
        "        \"4a7d7f66efe14f06a407241b8f199b03\": {\n",
        "          \"model_module\": \"@jupyter-widgets/base\",\n",
        "          \"model_name\": \"LayoutModel\",\n",
        "          \"model_module_version\": \"1.2.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/base\",\n",
        "            \"_model_module_version\": \"1.2.0\",\n",
        "            \"_model_name\": \"LayoutModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"LayoutView\",\n",
        "            \"align_content\": null,\n",
        "            \"align_items\": null,\n",
        "            \"align_self\": null,\n",
        "            \"border\": null,\n",
        "            \"bottom\": null,\n",
        "            \"display\": null,\n",
        "            \"flex\": null,\n",
        "            \"flex_flow\": null,\n",
        "            \"grid_area\": null,\n",
        "            \"grid_auto_columns\": null,\n",
        "            \"grid_auto_flow\": null,\n",
        "            \"grid_auto_rows\": null,\n",
        "            \"grid_column\": null,\n",
        "            \"grid_gap\": null,\n",
        "            \"grid_row\": null,\n",
        "            \"grid_template_areas\": null,\n",
        "            \"grid_template_columns\": null,\n",
        "            \"grid_template_rows\": null,\n",
        "            \"height\": null,\n",
        "            \"justify_content\": null,\n",
        "            \"justify_items\": null,\n",
        "            \"left\": null,\n",
        "            \"margin\": null,\n",
        "            \"max_height\": null,\n",
        "            \"max_width\": null,\n",
        "            \"min_height\": null,\n",
        "            \"min_width\": null,\n",
        "            \"object_fit\": null,\n",
        "            \"object_position\": null,\n",
        "            \"order\": null,\n",
        "            \"overflow\": null,\n",
        "            \"overflow_x\": null,\n",
        "            \"overflow_y\": null,\n",
        "            \"padding\": null,\n",
        "            \"right\": null,\n",
        "            \"top\": null,\n",
        "            \"visibility\": null,\n",
        "            \"width\": null\n",
        "          }\n",
        "        },\n",
        "        \"220e70fcadae4407ae6d87f015b6500f\": {\n",
        "          \"model_module\": \"@jupyter-widgets/base\",\n",
        "          \"model_name\": \"LayoutModel\",\n",
        "          \"model_module_version\": \"1.2.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/base\",\n",
        "            \"_model_module_version\": \"1.2.0\",\n",
        "            \"_model_name\": \"LayoutModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"LayoutView\",\n",
        "            \"align_content\": null,\n",
        "            \"align_items\": null,\n",
        "            \"align_self\": null,\n",
        "            \"border\": null,\n",
        "            \"bottom\": null,\n",
        "            \"display\": null,\n",
        "            \"flex\": null,\n",
        "            \"flex_flow\": null,\n",
        "            \"grid_area\": null,\n",
        "            \"grid_auto_columns\": null,\n",
        "            \"grid_auto_flow\": null,\n",
        "            \"grid_auto_rows\": null,\n",
        "            \"grid_column\": null,\n",
        "            \"grid_gap\": null,\n",
        "            \"grid_row\": null,\n",
        "            \"grid_template_areas\": null,\n",
        "            \"grid_template_columns\": null,\n",
        "            \"grid_template_rows\": null,\n",
        "            \"height\": null,\n",
        "            \"justify_content\": null,\n",
        "            \"justify_items\": null,\n",
        "            \"left\": null,\n",
        "            \"margin\": null,\n",
        "            \"max_height\": null,\n",
        "            \"max_width\": null,\n",
        "            \"min_height\": null,\n",
        "            \"min_width\": null,\n",
        "            \"object_fit\": null,\n",
        "            \"object_position\": null,\n",
        "            \"order\": null,\n",
        "            \"overflow\": null,\n",
        "            \"overflow_x\": null,\n",
        "            \"overflow_y\": null,\n",
        "            \"padding\": null,\n",
        "            \"right\": null,\n",
        "            \"top\": null,\n",
        "            \"visibility\": null,\n",
        "            \"width\": null\n",
        "          }\n",
        "        },\n",
        "        \"942684a56a00491f92cc8ce8edaa7fb9\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"DescriptionStyleModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"DescriptionStyleModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"StyleView\",\n",
        "            \"description_width\": \"\"\n",
        "          }\n",
        "        },\n",
        "        \"95fa09105d8640e6a391b33056ce018f\": {\n",
        "          \"model_module\": \"@jupyter-widgets/base\",\n",
        "          \"model_name\": \"LayoutModel\",\n",
        "          \"model_module_version\": \"1.2.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/base\",\n",
        "            \"_model_module_version\": \"1.2.0\",\n",
        "            \"_model_name\": \"LayoutModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"LayoutView\",\n",
        "            \"align_content\": null,\n",
        "            \"align_items\": null,\n",
        "            \"align_self\": null,\n",
        "            \"border\": null,\n",
        "            \"bottom\": null,\n",
        "            \"display\": null,\n",
        "            \"flex\": null,\n",
        "            \"flex_flow\": null,\n",
        "            \"grid_area\": null,\n",
        "            \"grid_auto_columns\": null,\n",
        "            \"grid_auto_flow\": null,\n",
        "            \"grid_auto_rows\": null,\n",
        "            \"grid_column\": null,\n",
        "            \"grid_gap\": null,\n",
        "            \"grid_row\": null,\n",
        "            \"grid_template_areas\": null,\n",
        "            \"grid_template_columns\": null,\n",
        "            \"grid_template_rows\": null,\n",
        "            \"height\": null,\n",
        "            \"justify_content\": null,\n",
        "            \"justify_items\": null,\n",
        "            \"left\": null,\n",
        "            \"margin\": null,\n",
        "            \"max_height\": null,\n",
        "            \"max_width\": null,\n",
        "            \"min_height\": null,\n",
        "            \"min_width\": null,\n",
        "            \"object_fit\": null,\n",
        "            \"object_position\": null,\n",
        "            \"order\": null,\n",
        "            \"overflow\": null,\n",
        "            \"overflow_x\": null,\n",
        "            \"overflow_y\": null,\n",
        "            \"padding\": null,\n",
        "            \"right\": null,\n",
        "            \"top\": null,\n",
        "            \"visibility\": null,\n",
        "            \"width\": null\n",
        "          }\n",
        "        },\n",
        "        \"e5dfa6933a17464e97aa0f14381aaf70\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"ProgressStyleModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"ProgressStyleModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"StyleView\",\n",
        "            \"bar_color\": null,\n",
        "            \"description_width\": \"\"\n",
        "          }\n",
        "        },\n",
        "        \"6c3157c8ac4048629cd7be4755e7e07a\": {\n",
        "          \"model_module\": \"@jupyter-widgets/base\",\n",
        "          \"model_name\": \"LayoutModel\",\n",
        "          \"model_module_version\": \"1.2.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/base\",\n",
        "            \"_model_module_version\": \"1.2.0\",\n",
        "            \"_model_name\": \"LayoutModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"LayoutView\",\n",
        "            \"align_content\": null,\n",
        "            \"align_items\": null,\n",
        "            \"align_self\": null,\n",
        "            \"border\": null,\n",
        "            \"bottom\": null,\n",
        "            \"display\": null,\n",
        "            \"flex\": null,\n",
        "            \"flex_flow\": null,\n",
        "            \"grid_area\": null,\n",
        "            \"grid_auto_columns\": null,\n",
        "            \"grid_auto_flow\": null,\n",
        "            \"grid_auto_rows\": null,\n",
        "            \"grid_column\": null,\n",
        "            \"grid_gap\": null,\n",
        "            \"grid_row\": null,\n",
        "            \"grid_template_areas\": null,\n",
        "            \"grid_template_columns\": null,\n",
        "            \"grid_template_rows\": null,\n",
        "            \"height\": null,\n",
        "            \"justify_content\": null,\n",
        "            \"justify_items\": null,\n",
        "            \"left\": null,\n",
        "            \"margin\": null,\n",
        "            \"max_height\": null,\n",
        "            \"max_width\": null,\n",
        "            \"min_height\": null,\n",
        "            \"min_width\": null,\n",
        "            \"object_fit\": null,\n",
        "            \"object_position\": null,\n",
        "            \"order\": null,\n",
        "            \"overflow\": null,\n",
        "            \"overflow_x\": null,\n",
        "            \"overflow_y\": null,\n",
        "            \"padding\": null,\n",
        "            \"right\": null,\n",
        "            \"top\": null,\n",
        "            \"visibility\": null,\n",
        "            \"width\": null\n",
        "          }\n",
        "        },\n",
        "        \"4f480b7090364b5d95cb25b84f982149\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"DescriptionStyleModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"DescriptionStyleModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"StyleView\",\n",
        "            \"description_width\": \"\"\n",
        "          }\n",
        "        },\n",
        "        \"b7d00a1b65894b7ba7b8e00703c73e9d\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"HBoxModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_dom_classes\": [],\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"HBoxModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_view_module_version\": \"1.5.0\",\n",
        "            \"_view_name\": \"HBoxView\",\n",
        "            \"box_style\": \"\",\n",
        "            \"children\": [\n",
        "              \"IPY_MODEL_323c757d9dd04e818d33d780cc77d3fc\",\n",
        "              \"IPY_MODEL_6f67d43cc0b7422b898f27a8f6a3e33b\",\n",
        "              \"IPY_MODEL_56369256ccc8442db786aea1d7e274a6\"\n",
        "            ],\n",
        "            \"layout\": \"IPY_MODEL_cac07e5f6f934cfb9bdebc556236112e\"\n",
        "          }\n",
        "        },\n",
        "        \"323c757d9dd04e818d33d780cc77d3fc\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"HTMLModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_dom_classes\": [],\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"HTMLModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_view_module_version\": \"1.5.0\",\n",
        "            \"_view_name\": \"HTMLView\",\n",
        "            \"description\": \"\",\n",
        "            \"description_tooltip\": null,\n",
        "            \"layout\": \"IPY_MODEL_7c44d8cf2834456cbbb5137230299947\",\n",
        "            \"placeholder\": \"​\",\n",
        "            \"style\": \"IPY_MODEL_d1776d7800ea41138f1e4f77de0c77e6\",\n",
        "            \"value\": \"generation_config.json: 100%\"\n",
        "          }\n",
        "        },\n",
        "        \"6f67d43cc0b7422b898f27a8f6a3e33b\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"FloatProgressModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_dom_classes\": [],\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"FloatProgressModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_view_module_version\": \"1.5.0\",\n",
        "            \"_view_name\": \"ProgressView\",\n",
        "            \"bar_style\": \"success\",\n",
        "            \"description\": \"\",\n",
        "            \"description_tooltip\": null,\n",
        "            \"layout\": \"IPY_MODEL_2f99e211638a4410b35923895ff24251\",\n",
        "            \"max\": 184,\n",
        "            \"min\": 0,\n",
        "            \"orientation\": \"horizontal\",\n",
        "            \"style\": \"IPY_MODEL_2f1c1f6c313649059af9b2af09115720\",\n",
        "            \"value\": 184\n",
        "          }\n",
        "        },\n",
        "        \"56369256ccc8442db786aea1d7e274a6\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"HTMLModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_dom_classes\": [],\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"HTMLModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_view_module_version\": \"1.5.0\",\n",
        "            \"_view_name\": \"HTMLView\",\n",
        "            \"description\": \"\",\n",
        "            \"description_tooltip\": null,\n",
        "            \"layout\": \"IPY_MODEL_cbf5ffe9bc664a6488b4a6288c237bea\",\n",
        "            \"placeholder\": \"​\",\n",
        "            \"style\": \"IPY_MODEL_0a976d5ffda84f57bc7c77f495e71d5e\",\n",
        "            \"value\": \" 184/184 [00:00&lt;00:00, 22.0kB/s]\"\n",
        "          }\n",
        "        },\n",
        "        \"cac07e5f6f934cfb9bdebc556236112e\": {\n",
        "          \"model_module\": \"@jupyter-widgets/base\",\n",
        "          \"model_name\": \"LayoutModel\",\n",
        "          \"model_module_version\": \"1.2.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/base\",\n",
        "            \"_model_module_version\": \"1.2.0\",\n",
        "            \"_model_name\": \"LayoutModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"LayoutView\",\n",
        "            \"align_content\": null,\n",
        "            \"align_items\": null,\n",
        "            \"align_self\": null,\n",
        "            \"border\": null,\n",
        "            \"bottom\": null,\n",
        "            \"display\": null,\n",
        "            \"flex\": null,\n",
        "            \"flex_flow\": null,\n",
        "            \"grid_area\": null,\n",
        "            \"grid_auto_columns\": null,\n",
        "            \"grid_auto_flow\": null,\n",
        "            \"grid_auto_rows\": null,\n",
        "            \"grid_column\": null,\n",
        "            \"grid_gap\": null,\n",
        "            \"grid_row\": null,\n",
        "            \"grid_template_areas\": null,\n",
        "            \"grid_template_columns\": null,\n",
        "            \"grid_template_rows\": null,\n",
        "            \"height\": null,\n",
        "            \"justify_content\": null,\n",
        "            \"justify_items\": null,\n",
        "            \"left\": null,\n",
        "            \"margin\": null,\n",
        "            \"max_height\": null,\n",
        "            \"max_width\": null,\n",
        "            \"min_height\": null,\n",
        "            \"min_width\": null,\n",
        "            \"object_fit\": null,\n",
        "            \"object_position\": null,\n",
        "            \"order\": null,\n",
        "            \"overflow\": null,\n",
        "            \"overflow_x\": null,\n",
        "            \"overflow_y\": null,\n",
        "            \"padding\": null,\n",
        "            \"right\": null,\n",
        "            \"top\": null,\n",
        "            \"visibility\": null,\n",
        "            \"width\": null\n",
        "          }\n",
        "        },\n",
        "        \"7c44d8cf2834456cbbb5137230299947\": {\n",
        "          \"model_module\": \"@jupyter-widgets/base\",\n",
        "          \"model_name\": \"LayoutModel\",\n",
        "          \"model_module_version\": \"1.2.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/base\",\n",
        "            \"_model_module_version\": \"1.2.0\",\n",
        "            \"_model_name\": \"LayoutModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"LayoutView\",\n",
        "            \"align_content\": null,\n",
        "            \"align_items\": null,\n",
        "            \"align_self\": null,\n",
        "            \"border\": null,\n",
        "            \"bottom\": null,\n",
        "            \"display\": null,\n",
        "            \"flex\": null,\n",
        "            \"flex_flow\": null,\n",
        "            \"grid_area\": null,\n",
        "            \"grid_auto_columns\": null,\n",
        "            \"grid_auto_flow\": null,\n",
        "            \"grid_auto_rows\": null,\n",
        "            \"grid_column\": null,\n",
        "            \"grid_gap\": null,\n",
        "            \"grid_row\": null,\n",
        "            \"grid_template_areas\": null,\n",
        "            \"grid_template_columns\": null,\n",
        "            \"grid_template_rows\": null,\n",
        "            \"height\": null,\n",
        "            \"justify_content\": null,\n",
        "            \"justify_items\": null,\n",
        "            \"left\": null,\n",
        "            \"margin\": null,\n",
        "            \"max_height\": null,\n",
        "            \"max_width\": null,\n",
        "            \"min_height\": null,\n",
        "            \"min_width\": null,\n",
        "            \"object_fit\": null,\n",
        "            \"object_position\": null,\n",
        "            \"order\": null,\n",
        "            \"overflow\": null,\n",
        "            \"overflow_x\": null,\n",
        "            \"overflow_y\": null,\n",
        "            \"padding\": null,\n",
        "            \"right\": null,\n",
        "            \"top\": null,\n",
        "            \"visibility\": null,\n",
        "            \"width\": null\n",
        "          }\n",
        "        },\n",
        "        \"d1776d7800ea41138f1e4f77de0c77e6\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"DescriptionStyleModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"DescriptionStyleModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"StyleView\",\n",
        "            \"description_width\": \"\"\n",
        "          }\n",
        "        },\n",
        "        \"2f99e211638a4410b35923895ff24251\": {\n",
        "          \"model_module\": \"@jupyter-widgets/base\",\n",
        "          \"model_name\": \"LayoutModel\",\n",
        "          \"model_module_version\": \"1.2.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/base\",\n",
        "            \"_model_module_version\": \"1.2.0\",\n",
        "            \"_model_name\": \"LayoutModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"LayoutView\",\n",
        "            \"align_content\": null,\n",
        "            \"align_items\": null,\n",
        "            \"align_self\": null,\n",
        "            \"border\": null,\n",
        "            \"bottom\": null,\n",
        "            \"display\": null,\n",
        "            \"flex\": null,\n",
        "            \"flex_flow\": null,\n",
        "            \"grid_area\": null,\n",
        "            \"grid_auto_columns\": null,\n",
        "            \"grid_auto_flow\": null,\n",
        "            \"grid_auto_rows\": null,\n",
        "            \"grid_column\": null,\n",
        "            \"grid_gap\": null,\n",
        "            \"grid_row\": null,\n",
        "            \"grid_template_areas\": null,\n",
        "            \"grid_template_columns\": null,\n",
        "            \"grid_template_rows\": null,\n",
        "            \"height\": null,\n",
        "            \"justify_content\": null,\n",
        "            \"justify_items\": null,\n",
        "            \"left\": null,\n",
        "            \"margin\": null,\n",
        "            \"max_height\": null,\n",
        "            \"max_width\": null,\n",
        "            \"min_height\": null,\n",
        "            \"min_width\": null,\n",
        "            \"object_fit\": null,\n",
        "            \"object_position\": null,\n",
        "            \"order\": null,\n",
        "            \"overflow\": null,\n",
        "            \"overflow_x\": null,\n",
        "            \"overflow_y\": null,\n",
        "            \"padding\": null,\n",
        "            \"right\": null,\n",
        "            \"top\": null,\n",
        "            \"visibility\": null,\n",
        "            \"width\": null\n",
        "          }\n",
        "        },\n",
        "        \"2f1c1f6c313649059af9b2af09115720\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"ProgressStyleModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"ProgressStyleModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"StyleView\",\n",
        "            \"bar_color\": null,\n",
        "            \"description_width\": \"\"\n",
        "          }\n",
        "        },\n",
        "        \"cbf5ffe9bc664a6488b4a6288c237bea\": {\n",
        "          \"model_module\": \"@jupyter-widgets/base\",\n",
        "          \"model_name\": \"LayoutModel\",\n",
        "          \"model_module_version\": \"1.2.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/base\",\n",
        "            \"_model_module_version\": \"1.2.0\",\n",
        "            \"_model_name\": \"LayoutModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"LayoutView\",\n",
        "            \"align_content\": null,\n",
        "            \"align_items\": null,\n",
        "            \"align_self\": null,\n",
        "            \"border\": null,\n",
        "            \"bottom\": null,\n",
        "            \"display\": null,\n",
        "            \"flex\": null,\n",
        "            \"flex_flow\": null,\n",
        "            \"grid_area\": null,\n",
        "            \"grid_auto_columns\": null,\n",
        "            \"grid_auto_flow\": null,\n",
        "            \"grid_auto_rows\": null,\n",
        "            \"grid_column\": null,\n",
        "            \"grid_gap\": null,\n",
        "            \"grid_row\": null,\n",
        "            \"grid_template_areas\": null,\n",
        "            \"grid_template_columns\": null,\n",
        "            \"grid_template_rows\": null,\n",
        "            \"height\": null,\n",
        "            \"justify_content\": null,\n",
        "            \"justify_items\": null,\n",
        "            \"left\": null,\n",
        "            \"margin\": null,\n",
        "            \"max_height\": null,\n",
        "            \"max_width\": null,\n",
        "            \"min_height\": null,\n",
        "            \"min_width\": null,\n",
        "            \"object_fit\": null,\n",
        "            \"object_position\": null,\n",
        "            \"order\": null,\n",
        "            \"overflow\": null,\n",
        "            \"overflow_x\": null,\n",
        "            \"overflow_y\": null,\n",
        "            \"padding\": null,\n",
        "            \"right\": null,\n",
        "            \"top\": null,\n",
        "            \"visibility\": null,\n",
        "            \"width\": null\n",
        "          }\n",
        "        },\n",
        "        \"0a976d5ffda84f57bc7c77f495e71d5e\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"DescriptionStyleModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"DescriptionStyleModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"StyleView\",\n",
        "            \"description_width\": \"\"\n",
        "          }\n",
        "        },\n",
        "        \"30d3f72ec53f48938da84da121f58200\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"HBoxModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_dom_classes\": [],\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"HBoxModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_view_module_version\": \"1.5.0\",\n",
        "            \"_view_name\": \"HBoxView\",\n",
        "            \"box_style\": \"\",\n",
        "            \"children\": [\n",
        "              \"IPY_MODEL_f65c1cbd834c4e5d9893536bd6f346dd\",\n",
        "              \"IPY_MODEL_2001c04948f2494c8f39e52f3bf7f311\",\n",
        "              \"IPY_MODEL_29a80705829342e7a9b0996419edc23b\"\n",
        "            ],\n",
        "            \"layout\": \"IPY_MODEL_dbab24ca67ec42aba171a79f7b0fe471\"\n",
        "          }\n",
        "        },\n",
        "        \"f65c1cbd834c4e5d9893536bd6f346dd\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"HTMLModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_dom_classes\": [],\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"HTMLModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_view_module_version\": \"1.5.0\",\n",
        "            \"_view_name\": \"HTMLView\",\n",
        "            \"description\": \"\",\n",
        "            \"description_tooltip\": null,\n",
        "            \"layout\": \"IPY_MODEL_6d14d713d2e24df8a1ad0e3b6b61b20f\",\n",
        "            \"placeholder\": \"​\",\n",
        "            \"style\": \"IPY_MODEL_df01bca70ea94b8e8102412b758b26fb\",\n",
        "            \"value\": \"Processing Questions:   0%\"\n",
        "          }\n",
        "        },\n",
        "        \"2001c04948f2494c8f39e52f3bf7f311\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"FloatProgressModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_dom_classes\": [],\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"FloatProgressModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_view_module_version\": \"1.5.0\",\n",
        "            \"_view_name\": \"ProgressView\",\n",
        "            \"bar_style\": \"danger\",\n",
        "            \"description\": \"\",\n",
        "            \"description_tooltip\": null,\n",
        "            \"layout\": \"IPY_MODEL_ea6ffdbdb3fd4d34a3644d5d5b8223e6\",\n",
        "            \"max\": 3,\n",
        "            \"min\": 0,\n",
        "            \"orientation\": \"horizontal\",\n",
        "            \"style\": \"IPY_MODEL_bb700022a2054ca8a5a3143f658aa0b0\",\n",
        "            \"value\": 0\n",
        "          }\n",
        "        },\n",
        "        \"29a80705829342e7a9b0996419edc23b\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"HTMLModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_dom_classes\": [],\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"HTMLModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_view_module_version\": \"1.5.0\",\n",
        "            \"_view_name\": \"HTMLView\",\n",
        "            \"description\": \"\",\n",
        "            \"description_tooltip\": null,\n",
        "            \"layout\": \"IPY_MODEL_88b2e8a3572d4827bb0d7364930cdfec\",\n",
        "            \"placeholder\": \"​\",\n",
        "            \"style\": \"IPY_MODEL_c820f0c30f4b417fae603c1579855544\",\n",
        "            \"value\": \" 0/3 [00:00&lt;?, ?it/s]\"\n",
        "          }\n",
        "        },\n",
        "        \"dbab24ca67ec42aba171a79f7b0fe471\": {\n",
        "          \"model_module\": \"@jupyter-widgets/base\",\n",
        "          \"model_name\": \"LayoutModel\",\n",
        "          \"model_module_version\": \"1.2.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/base\",\n",
        "            \"_model_module_version\": \"1.2.0\",\n",
        "            \"_model_name\": \"LayoutModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"LayoutView\",\n",
        "            \"align_content\": null,\n",
        "            \"align_items\": null,\n",
        "            \"align_self\": null,\n",
        "            \"border\": null,\n",
        "            \"bottom\": null,\n",
        "            \"display\": null,\n",
        "            \"flex\": null,\n",
        "            \"flex_flow\": null,\n",
        "            \"grid_area\": null,\n",
        "            \"grid_auto_columns\": null,\n",
        "            \"grid_auto_flow\": null,\n",
        "            \"grid_auto_rows\": null,\n",
        "            \"grid_column\": null,\n",
        "            \"grid_gap\": null,\n",
        "            \"grid_row\": null,\n",
        "            \"grid_template_areas\": null,\n",
        "            \"grid_template_columns\": null,\n",
        "            \"grid_template_rows\": null,\n",
        "            \"height\": null,\n",
        "            \"justify_content\": null,\n",
        "            \"justify_items\": null,\n",
        "            \"left\": null,\n",
        "            \"margin\": null,\n",
        "            \"max_height\": null,\n",
        "            \"max_width\": null,\n",
        "            \"min_height\": null,\n",
        "            \"min_width\": null,\n",
        "            \"object_fit\": null,\n",
        "            \"object_position\": null,\n",
        "            \"order\": null,\n",
        "            \"overflow\": null,\n",
        "            \"overflow_x\": null,\n",
        "            \"overflow_y\": null,\n",
        "            \"padding\": null,\n",
        "            \"right\": null,\n",
        "            \"top\": null,\n",
        "            \"visibility\": null,\n",
        "            \"width\": null\n",
        "          }\n",
        "        },\n",
        "        \"6d14d713d2e24df8a1ad0e3b6b61b20f\": {\n",
        "          \"model_module\": \"@jupyter-widgets/base\",\n",
        "          \"model_name\": \"LayoutModel\",\n",
        "          \"model_module_version\": \"1.2.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/base\",\n",
        "            \"_model_module_version\": \"1.2.0\",\n",
        "            \"_model_name\": \"LayoutModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"LayoutView\",\n",
        "            \"align_content\": null,\n",
        "            \"align_items\": null,\n",
        "            \"align_self\": null,\n",
        "            \"border\": null,\n",
        "            \"bottom\": null,\n",
        "            \"display\": null,\n",
        "            \"flex\": null,\n",
        "            \"flex_flow\": null,\n",
        "            \"grid_area\": null,\n",
        "            \"grid_auto_columns\": null,\n",
        "            \"grid_auto_flow\": null,\n",
        "            \"grid_auto_rows\": null,\n",
        "            \"grid_column\": null,\n",
        "            \"grid_gap\": null,\n",
        "            \"grid_row\": null,\n",
        "            \"grid_template_areas\": null,\n",
        "            \"grid_template_columns\": null,\n",
        "            \"grid_template_rows\": null,\n",
        "            \"height\": null,\n",
        "            \"justify_content\": null,\n",
        "            \"justify_items\": null,\n",
        "            \"left\": null,\n",
        "            \"margin\": null,\n",
        "            \"max_height\": null,\n",
        "            \"max_width\": null,\n",
        "            \"min_height\": null,\n",
        "            \"min_width\": null,\n",
        "            \"object_fit\": null,\n",
        "            \"object_position\": null,\n",
        "            \"order\": null,\n",
        "            \"overflow\": null,\n",
        "            \"overflow_x\": null,\n",
        "            \"overflow_y\": null,\n",
        "            \"padding\": null,\n",
        "            \"right\": null,\n",
        "            \"top\": null,\n",
        "            \"visibility\": null,\n",
        "            \"width\": null\n",
        "          }\n",
        "        },\n",
        "        \"df01bca70ea94b8e8102412b758b26fb\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"DescriptionStyleModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"DescriptionStyleModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"StyleView\",\n",
        "            \"description_width\": \"\"\n",
        "          }\n",
        "        },\n",
        "        \"ea6ffdbdb3fd4d34a3644d5d5b8223e6\": {\n",
        "          \"model_module\": \"@jupyter-widgets/base\",\n",
        "          \"model_name\": \"LayoutModel\",\n",
        "          \"model_module_version\": \"1.2.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/base\",\n",
        "            \"_model_module_version\": \"1.2.0\",\n",
        "            \"_model_name\": \"LayoutModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"LayoutView\",\n",
        "            \"align_content\": null,\n",
        "            \"align_items\": null,\n",
        "            \"align_self\": null,\n",
        "            \"border\": null,\n",
        "            \"bottom\": null,\n",
        "            \"display\": null,\n",
        "            \"flex\": null,\n",
        "            \"flex_flow\": null,\n",
        "            \"grid_area\": null,\n",
        "            \"grid_auto_columns\": null,\n",
        "            \"grid_auto_flow\": null,\n",
        "            \"grid_auto_rows\": null,\n",
        "            \"grid_column\": null,\n",
        "            \"grid_gap\": null,\n",
        "            \"grid_row\": null,\n",
        "            \"grid_template_areas\": null,\n",
        "            \"grid_template_columns\": null,\n",
        "            \"grid_template_rows\": null,\n",
        "            \"height\": null,\n",
        "            \"justify_content\": null,\n",
        "            \"justify_items\": null,\n",
        "            \"left\": null,\n",
        "            \"margin\": null,\n",
        "            \"max_height\": null,\n",
        "            \"max_width\": null,\n",
        "            \"min_height\": null,\n",
        "            \"min_width\": null,\n",
        "            \"object_fit\": null,\n",
        "            \"object_position\": null,\n",
        "            \"order\": null,\n",
        "            \"overflow\": null,\n",
        "            \"overflow_x\": null,\n",
        "            \"overflow_y\": null,\n",
        "            \"padding\": null,\n",
        "            \"right\": null,\n",
        "            \"top\": null,\n",
        "            \"visibility\": null,\n",
        "            \"width\": null\n",
        "          }\n",
        "        },\n",
        "        \"bb700022a2054ca8a5a3143f658aa0b0\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"ProgressStyleModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"ProgressStyleModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"StyleView\",\n",
        "            \"bar_color\": null,\n",
        "            \"description_width\": \"\"\n",
        "          }\n",
        "        },\n",
        "        \"88b2e8a3572d4827bb0d7364930cdfec\": {\n",
        "          \"model_module\": \"@jupyter-widgets/base\",\n",
        "          \"model_name\": \"LayoutModel\",\n",
        "          \"model_module_version\": \"1.2.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/base\",\n",
        "            \"_model_module_version\": \"1.2.0\",\n",
        "            \"_model_name\": \"LayoutModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"LayoutView\",\n",
        "            \"align_content\": null,\n",
        "            \"align_items\": null,\n",
        "            \"align_self\": null,\n",
        "            \"border\": null,\n",
        "            \"bottom\": null,\n",
        "            \"display\": null,\n",
        "            \"flex\": null,\n",
        "            \"flex_flow\": null,\n",
        "            \"grid_area\": null,\n",
        "            \"grid_auto_columns\": null,\n",
        "            \"grid_auto_flow\": null,\n",
        "            \"grid_auto_rows\": null,\n",
        "            \"grid_column\": null,\n",
        "            \"grid_gap\": null,\n",
        "            \"grid_row\": null,\n",
        "            \"grid_template_areas\": null,\n",
        "            \"grid_template_columns\": null,\n",
        "            \"grid_template_rows\": null,\n",
        "            \"height\": null,\n",
        "            \"justify_content\": null,\n",
        "            \"justify_items\": null,\n",
        "            \"left\": null,\n",
        "            \"margin\": null,\n",
        "            \"max_height\": null,\n",
        "            \"max_width\": null,\n",
        "            \"min_height\": null,\n",
        "            \"min_width\": null,\n",
        "            \"object_fit\": null,\n",
        "            \"object_position\": null,\n",
        "            \"order\": null,\n",
        "            \"overflow\": null,\n",
        "            \"overflow_x\": null,\n",
        "            \"overflow_y\": null,\n",
        "            \"padding\": null,\n",
        "            \"right\": null,\n",
        "            \"top\": null,\n",
        "            \"visibility\": null,\n",
        "            \"width\": null\n",
        "          }\n",
        "        },\n",
        "        \"c820f0c30f4b417fae603c1579855544\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"DescriptionStyleModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"DescriptionStyleModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"StyleView\",\n",
        "            \"description_width\": \"\"\n",
        "          }\n",
        "        },\n",
        "        \"bcd81506a60544248d6209f2e88f0d56\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"HBoxModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_dom_classes\": [],\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"HBoxModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_view_module_version\": \"1.5.0\",\n",
        "            \"_view_name\": \"HBoxView\",\n",
        "            \"box_style\": \"\",\n",
        "            \"children\": [\n",
        "              \"IPY_MODEL_37c9f6b6bbcf462a9758581e68a80438\",\n",
        "              \"IPY_MODEL_4cb25320b003454b9dc694503a5f7965\",\n",
        "              \"IPY_MODEL_6b8f3cd154294f94bd12d3c7403c612c\"\n",
        "            ],\n",
        "            \"layout\": \"IPY_MODEL_78945499c68c4a6ba0907ede0ee96ed4\"\n",
        "          }\n",
        "        },\n",
        "        \"37c9f6b6bbcf462a9758581e68a80438\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"HTMLModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_dom_classes\": [],\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"HTMLModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_view_module_version\": \"1.5.0\",\n",
        "            \"_view_name\": \"HTMLView\",\n",
        "            \"description\": \"\",\n",
        "            \"description_tooltip\": null,\n",
        "            \"layout\": \"IPY_MODEL_a8ea273c994e42cf858b8f850bbbea08\",\n",
        "            \"placeholder\": \"​\",\n",
        "            \"style\": \"IPY_MODEL_aeaef1b15c2a428092e858bdb337c72f\",\n",
        "            \"value\": \"Processing Questions:  24%\"\n",
        "          }\n",
        "        },\n",
        "        \"4cb25320b003454b9dc694503a5f7965\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"FloatProgressModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_dom_classes\": [],\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"FloatProgressModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_view_module_version\": \"1.5.0\",\n",
        "            \"_view_name\": \"ProgressView\",\n",
        "            \"bar_style\": \"\",\n",
        "            \"description\": \"\",\n",
        "            \"description_tooltip\": null,\n",
        "            \"layout\": \"IPY_MODEL_93da93837b564f5db67f2aa677d14d62\",\n",
        "            \"max\": 1000,\n",
        "            \"min\": 0,\n",
        "            \"orientation\": \"horizontal\",\n",
        "            \"style\": \"IPY_MODEL_6acab8ff9cff4075b940dfaa01cd5cba\",\n",
        "            \"value\": 240\n",
        "          }\n",
        "        },\n",
        "        \"6b8f3cd154294f94bd12d3c7403c612c\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"HTMLModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_dom_classes\": [],\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"HTMLModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_view_module_version\": \"1.5.0\",\n",
        "            \"_view_name\": \"HTMLView\",\n",
        "            \"description\": \"\",\n",
        "            \"description_tooltip\": null,\n",
        "            \"layout\": \"IPY_MODEL_6701e7f9060e49e8bdac1d61272948ac\",\n",
        "            \"placeholder\": \"​\",\n",
        "            \"style\": \"IPY_MODEL_5a61dd3d8feb4a03a2c3a9fe6ceeb7a3\",\n",
        "            \"value\": \" 240/1000 [45:56&lt;2:25:47, 11.51s/it]\"\n",
        "          }\n",
        "        },\n",
        "        \"78945499c68c4a6ba0907ede0ee96ed4\": {\n",
        "          \"model_module\": \"@jupyter-widgets/base\",\n",
        "          \"model_name\": \"LayoutModel\",\n",
        "          \"model_module_version\": \"1.2.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/base\",\n",
        "            \"_model_module_version\": \"1.2.0\",\n",
        "            \"_model_name\": \"LayoutModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"LayoutView\",\n",
        "            \"align_content\": null,\n",
        "            \"align_items\": null,\n",
        "            \"align_self\": null,\n",
        "            \"border\": null,\n",
        "            \"bottom\": null,\n",
        "            \"display\": null,\n",
        "            \"flex\": null,\n",
        "            \"flex_flow\": null,\n",
        "            \"grid_area\": null,\n",
        "            \"grid_auto_columns\": null,\n",
        "            \"grid_auto_flow\": null,\n",
        "            \"grid_auto_rows\": null,\n",
        "            \"grid_column\": null,\n",
        "            \"grid_gap\": null,\n",
        "            \"grid_row\": null,\n",
        "            \"grid_template_areas\": null,\n",
        "            \"grid_template_columns\": null,\n",
        "            \"grid_template_rows\": null,\n",
        "            \"height\": null,\n",
        "            \"justify_content\": null,\n",
        "            \"justify_items\": null,\n",
        "            \"left\": null,\n",
        "            \"margin\": null,\n",
        "            \"max_height\": null,\n",
        "            \"max_width\": null,\n",
        "            \"min_height\": null,\n",
        "            \"min_width\": null,\n",
        "            \"object_fit\": null,\n",
        "            \"object_position\": null,\n",
        "            \"order\": null,\n",
        "            \"overflow\": null,\n",
        "            \"overflow_x\": null,\n",
        "            \"overflow_y\": null,\n",
        "            \"padding\": null,\n",
        "            \"right\": null,\n",
        "            \"top\": null,\n",
        "            \"visibility\": null,\n",
        "            \"width\": null\n",
        "          }\n",
        "        },\n",
        "        \"a8ea273c994e42cf858b8f850bbbea08\": {\n",
        "          \"model_module\": \"@jupyter-widgets/base\",\n",
        "          \"model_name\": \"LayoutModel\",\n",
        "          \"model_module_version\": \"1.2.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/base\",\n",
        "            \"_model_module_version\": \"1.2.0\",\n",
        "            \"_model_name\": \"LayoutModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"LayoutView\",\n",
        "            \"align_content\": null,\n",
        "            \"align_items\": null,\n",
        "            \"align_self\": null,\n",
        "            \"border\": null,\n",
        "            \"bottom\": null,\n",
        "            \"display\": null,\n",
        "            \"flex\": null,\n",
        "            \"flex_flow\": null,\n",
        "            \"grid_area\": null,\n",
        "            \"grid_auto_columns\": null,\n",
        "            \"grid_auto_flow\": null,\n",
        "            \"grid_auto_rows\": null,\n",
        "            \"grid_column\": null,\n",
        "            \"grid_gap\": null,\n",
        "            \"grid_row\": null,\n",
        "            \"grid_template_areas\": null,\n",
        "            \"grid_template_columns\": null,\n",
        "            \"grid_template_rows\": null,\n",
        "            \"height\": null,\n",
        "            \"justify_content\": null,\n",
        "            \"justify_items\": null,\n",
        "            \"left\": null,\n",
        "            \"margin\": null,\n",
        "            \"max_height\": null,\n",
        "            \"max_width\": null,\n",
        "            \"min_height\": null,\n",
        "            \"min_width\": null,\n",
        "            \"object_fit\": null,\n",
        "            \"object_position\": null,\n",
        "            \"order\": null,\n",
        "            \"overflow\": null,\n",
        "            \"overflow_x\": null,\n",
        "            \"overflow_y\": null,\n",
        "            \"padding\": null,\n",
        "            \"right\": null,\n",
        "            \"top\": null,\n",
        "            \"visibility\": null,\n",
        "            \"width\": null\n",
        "          }\n",
        "        },\n",
        "        \"aeaef1b15c2a428092e858bdb337c72f\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"DescriptionStyleModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"DescriptionStyleModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"StyleView\",\n",
        "            \"description_width\": \"\"\n",
        "          }\n",
        "        },\n",
        "        \"93da93837b564f5db67f2aa677d14d62\": {\n",
        "          \"model_module\": \"@jupyter-widgets/base\",\n",
        "          \"model_name\": \"LayoutModel\",\n",
        "          \"model_module_version\": \"1.2.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/base\",\n",
        "            \"_model_module_version\": \"1.2.0\",\n",
        "            \"_model_name\": \"LayoutModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"LayoutView\",\n",
        "            \"align_content\": null,\n",
        "            \"align_items\": null,\n",
        "            \"align_self\": null,\n",
        "            \"border\": null,\n",
        "            \"bottom\": null,\n",
        "            \"display\": null,\n",
        "            \"flex\": null,\n",
        "            \"flex_flow\": null,\n",
        "            \"grid_area\": null,\n",
        "            \"grid_auto_columns\": null,\n",
        "            \"grid_auto_flow\": null,\n",
        "            \"grid_auto_rows\": null,\n",
        "            \"grid_column\": null,\n",
        "            \"grid_gap\": null,\n",
        "            \"grid_row\": null,\n",
        "            \"grid_template_areas\": null,\n",
        "            \"grid_template_columns\": null,\n",
        "            \"grid_template_rows\": null,\n",
        "            \"height\": null,\n",
        "            \"justify_content\": null,\n",
        "            \"justify_items\": null,\n",
        "            \"left\": null,\n",
        "            \"margin\": null,\n",
        "            \"max_height\": null,\n",
        "            \"max_width\": null,\n",
        "            \"min_height\": null,\n",
        "            \"min_width\": null,\n",
        "            \"object_fit\": null,\n",
        "            \"object_position\": null,\n",
        "            \"order\": null,\n",
        "            \"overflow\": null,\n",
        "            \"overflow_x\": null,\n",
        "            \"overflow_y\": null,\n",
        "            \"padding\": null,\n",
        "            \"right\": null,\n",
        "            \"top\": null,\n",
        "            \"visibility\": null,\n",
        "            \"width\": null\n",
        "          }\n",
        "        },\n",
        "        \"6acab8ff9cff4075b940dfaa01cd5cba\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"ProgressStyleModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"ProgressStyleModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"StyleView\",\n",
        "            \"bar_color\": null,\n",
        "            \"description_width\": \"\"\n",
        "          }\n",
        "        },\n",
        "        \"6701e7f9060e49e8bdac1d61272948ac\": {\n",
        "          \"model_module\": \"@jupyter-widgets/base\",\n",
        "          \"model_name\": \"LayoutModel\",\n",
        "          \"model_module_version\": \"1.2.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/base\",\n",
        "            \"_model_module_version\": \"1.2.0\",\n",
        "            \"_model_name\": \"LayoutModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"LayoutView\",\n",
        "            \"align_content\": null,\n",
        "            \"align_items\": null,\n",
        "            \"align_self\": null,\n",
        "            \"border\": null,\n",
        "            \"bottom\": null,\n",
        "            \"display\": null,\n",
        "            \"flex\": null,\n",
        "            \"flex_flow\": null,\n",
        "            \"grid_area\": null,\n",
        "            \"grid_auto_columns\": null,\n",
        "            \"grid_auto_flow\": null,\n",
        "            \"grid_auto_rows\": null,\n",
        "            \"grid_column\": null,\n",
        "            \"grid_gap\": null,\n",
        "            \"grid_row\": null,\n",
        "            \"grid_template_areas\": null,\n",
        "            \"grid_template_columns\": null,\n",
        "            \"grid_template_rows\": null,\n",
        "            \"height\": null,\n",
        "            \"justify_content\": null,\n",
        "            \"justify_items\": null,\n",
        "            \"left\": null,\n",
        "            \"margin\": null,\n",
        "            \"max_height\": null,\n",
        "            \"max_width\": null,\n",
        "            \"min_height\": null,\n",
        "            \"min_width\": null,\n",
        "            \"object_fit\": null,\n",
        "            \"object_position\": null,\n",
        "            \"order\": null,\n",
        "            \"overflow\": null,\n",
        "            \"overflow_x\": null,\n",
        "            \"overflow_y\": null,\n",
        "            \"padding\": null,\n",
        "            \"right\": null,\n",
        "            \"top\": null,\n",
        "            \"visibility\": null,\n",
        "            \"width\": null\n",
        "          }\n",
        "        },\n",
        "        \"5a61dd3d8feb4a03a2c3a9fe6ceeb7a3\": {\n",
        "          \"model_module\": \"@jupyter-widgets/controls\",\n",
        "          \"model_name\": \"DescriptionStyleModel\",\n",
        "          \"model_module_version\": \"1.5.0\",\n",
        "          \"state\": {\n",
        "            \"_model_module\": \"@jupyter-widgets/controls\",\n",
        "            \"_model_module_version\": \"1.5.0\",\n",
        "            \"_model_name\": \"DescriptionStyleModel\",\n",
        "            \"_view_count\": null,\n",
        "            \"_view_module\": \"@jupyter-widgets/base\",\n",
        "            \"_view_module_version\": \"1.2.0\",\n",
        "            \"_view_name\": \"StyleView\",\n",
        "            \"description_width\": \"\"\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  },\n",
        "  \"nbformat\": 4,\n",
        "  \"nbformat_minor\": 0\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dQgBf4ANlHXS",
        "outputId": "e2faf779-0184-449a-92e2-7d70929574f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------------------\n",
            "Importing Dataset: /content/sciq_test_formatted.csv\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"display(new_dataset\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Question Number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"What term in biotechnology means a genetically exact copy of an organism?\",\n          \"Ice cores, varves and what else indicate the environmental conditions at the time of their creation?\",\n          \"Vertebrata are characterized by the presence of what?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Option A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"adult\",\n          \"mountain ranges\",\n          \"backbone\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Option B\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"male\",\n          \"fossils\",\n          \"Bones\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Option C\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"phenotype\",\n          \"tree rings\",\n          \"Muscles\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Option D\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"clone\",\n          \"magma\",\n          \"Thumbs\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Correct Answer Letter\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"C\",\n          \"D\",\n          \"A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-651f0d94-b8f4-4b94-8f3b-8c3bc961584c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question Number</th>\n",
              "      <th>Question</th>\n",
              "      <th>Option A</th>\n",
              "      <th>Option B</th>\n",
              "      <th>Option C</th>\n",
              "      <th>Option D</th>\n",
              "      <th>Correct Answer Letter</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Compounds that are capable of accepting electr...</td>\n",
              "      <td>antioxidants</td>\n",
              "      <td>Oxygen</td>\n",
              "      <td>oxidants</td>\n",
              "      <td>residues</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>What term in biotechnology means a genetically...</td>\n",
              "      <td>adult</td>\n",
              "      <td>male</td>\n",
              "      <td>phenotype</td>\n",
              "      <td>clone</td>\n",
              "      <td>D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Vertebrata are characterized by the presence o...</td>\n",
              "      <td>backbone</td>\n",
              "      <td>Bones</td>\n",
              "      <td>Muscles</td>\n",
              "      <td>Thumbs</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>What is the height above or below sea level ca...</td>\n",
              "      <td>depth</td>\n",
              "      <td>latitude</td>\n",
              "      <td>elevation</td>\n",
              "      <td>variation</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Ice cores, varves and what else indicate the e...</td>\n",
              "      <td>mountain ranges</td>\n",
              "      <td>fossils</td>\n",
              "      <td>tree rings</td>\n",
              "      <td>magma</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-651f0d94-b8f4-4b94-8f3b-8c3bc961584c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-651f0d94-b8f4-4b94-8f3b-8c3bc961584c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-651f0d94-b8f4-4b94-8f3b-8c3bc961584c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9ec807d8-1bed-4d13-ad02-8b0cc408d7e5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9ec807d8-1bed-4d13-ad02-8b0cc408d7e5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9ec807d8-1bed-4d13-ad02-8b0cc408d7e5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Question Number                                           Question  \\\n",
              "0                0  Compounds that are capable of accepting electr...   \n",
              "1                1  What term in biotechnology means a genetically...   \n",
              "2                2  Vertebrata are characterized by the presence o...   \n",
              "3                3  What is the height above or below sea level ca...   \n",
              "4                4  Ice cores, varves and what else indicate the e...   \n",
              "\n",
              "          Option A  Option B    Option C   Option D Correct Answer Letter  \n",
              "0     antioxidants    Oxygen    oxidants   residues                     C  \n",
              "1            adult      male   phenotype      clone                     D  \n",
              "2         backbone     Bones     Muscles     Thumbs                     A  \n",
              "3            depth  latitude   elevation  variation                     C  \n",
              "4  mountain ranges   fossils  tree rings      magma                     C  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------------------\n",
            "Editing System Prompts:\n",
            "System Prompts:\n",
            "  \n",
            "Given the following question, analyze the options, and provide a concise reasoning for your selected answer. Your reasoning should not exceed 100 words. After your explanation, clearly state your answer by choosing one of the options listed (A, B, C, or D).\n",
            "\n",
            "Question: ${Question}\n",
            "Options:\n",
            "A) ${Option A}\n",
            "B) ${Option B}\n",
            "C) ${Option C}\n",
            "D) ${Option D}\n",
            "\n",
            "\n",
            "Please provide your reasoning first, limited to 100 words, and consider how certain you should be of your answer.\n",
            "Reasoning: <Your concise reasoning here. Max 100 words>\n",
            "\n",
            "  \n",
            "Based on the reasoning above, Provide the best answer and the likelihood that each option is correct from 0.0 to 1.0 in a JSON format. The probabilities should sum to 1.0. For example:\n",
            "\n",
            "{\n",
            "'A': <Probability choice A is correct. As a float from 0.0 to 1.0>,\n",
            "'B': <Probability choice B is correct. As a float from 0.0 to 1.0>,\n",
            "'C': <Probability choice C is correct. As a float from 0.0 to 1.0>,\n",
            "'D': <Probability choice D is correct. As a float from 0.0 to 1.0>,\n",
            "'Answer': <Your answer choice here, as a single letter and nothing else.>\n",
            "}\n",
            "\n",
            "All options have a non-zero probability of being correct. No option should have a probability of 0 or 1.\n",
            "Be modest about your certainty.  Do not provide any additional reasoning.\n",
            "\n",
            "Response:\n",
            "\n",
            "------------------------------------------\n",
            "Formatting Dataset:\n",
            " Successfully Formatted Dataset\n",
            "New Dataset:\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"display(new_dataset\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Question Number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Full Prompt 1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\nGiven the following question, analyze the options, and provide a concise reasoning for your selected answer. Your reasoning should not exceed 100 words. After your explanation, clearly state your answer by choosing one of the options listed (A, B, C, or D).\\n\\nQuestion: What term in biotechnology means a genetically exact copy of an organism?\\nOptions:\\nA) adult\\nB) male\\nC) phenotype\\nD) clone\\n\\n\\nPlease provide your reasoning first, limited to 100 words, and consider how certain you should be of your answer.\\nReasoning: \",\n          \"\\nGiven the following question, analyze the options, and provide a concise reasoning for your selected answer. Your reasoning should not exceed 100 words. After your explanation, clearly state your answer by choosing one of the options listed (A, B, C, or D).\\n\\nQuestion: Ice cores, varves and what else indicate the environmental conditions at the time of their creation?\\nOptions:\\nA) mountain ranges\\nB) fossils\\nC) tree rings\\nD) magma\\n\\n\\nPlease provide your reasoning first, limited to 100 words, and consider how certain you should be of your answer.\\nReasoning: \",\n          \"\\nGiven the following question, analyze the options, and provide a concise reasoning for your selected answer. Your reasoning should not exceed 100 words. After your explanation, clearly state your answer by choosing one of the options listed (A, B, C, or D).\\n\\nQuestion: Vertebrata are characterized by the presence of what?\\nOptions:\\nA) backbone\\nB) Bones\\nC) Muscles\\nD) Thumbs\\n\\n\\nPlease provide your reasoning first, limited to 100 words, and consider how certain you should be of your answer.\\nReasoning: \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Full Prompt 2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\nBased on the reasoning above, Provide the best answer and the likelihood that each option is correct from 0.0 to 1.0 in a JSON format. The probabilities should sum to 1.0. For example:\\n\\n{\\n'A': <Probability choice A is correct. As a float from 0.0 to 1.0>,\\n'B': <Probability choice B is correct. As a float from 0.0 to 1.0>,\\n'C': <Probability choice C is correct. As a float from 0.0 to 1.0>,\\n'D': <Probability choice D is correct. As a float from 0.0 to 1.0>,\\n'Answer': <Your answer choice here, as a single letter and nothing else.>\\n}\\n\\nAll options have a non-zero probability of being correct. No option should have a probability of 0 or 1.\\nBe modest about your certainty.  Do not provide any additional reasoning.\\n\\nResponse:\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-1d8e6996-3ba6-496b-afa1-b05da2f4fff6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question Number</th>\n",
              "      <th>Full Prompt 1</th>\n",
              "      <th>Full Prompt 2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>\\nGiven the following question, analyze the op...</td>\n",
              "      <td>\\nBased on the reasoning above, Provide the be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>\\nGiven the following question, analyze the op...</td>\n",
              "      <td>\\nBased on the reasoning above, Provide the be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>\\nGiven the following question, analyze the op...</td>\n",
              "      <td>\\nBased on the reasoning above, Provide the be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>\\nGiven the following question, analyze the op...</td>\n",
              "      <td>\\nBased on the reasoning above, Provide the be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>\\nGiven the following question, analyze the op...</td>\n",
              "      <td>\\nBased on the reasoning above, Provide the be...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d8e6996-3ba6-496b-afa1-b05da2f4fff6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1d8e6996-3ba6-496b-afa1-b05da2f4fff6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1d8e6996-3ba6-496b-afa1-b05da2f4fff6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e6165cc9-99c3-430a-812c-398a6fe6a82c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e6165cc9-99c3-430a-812c-398a6fe6a82c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e6165cc9-99c3-430a-812c-398a6fe6a82c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Question Number                                      Full Prompt 1  \\\n",
              "0                0  \\nGiven the following question, analyze the op...   \n",
              "1                1  \\nGiven the following question, analyze the op...   \n",
              "2                2  \\nGiven the following question, analyze the op...   \n",
              "3                3  \\nGiven the following question, analyze the op...   \n",
              "4                4  \\nGiven the following question, analyze the op...   \n",
              "\n",
              "                                       Full Prompt 2  \n",
              "0  \\nBased on the reasoning above, Provide the be...  \n",
              "1  \\nBased on the reasoning above, Provide the be...  \n",
              "2  \\nBased on the reasoning above, Provide the be...  \n",
              "3  \\nBased on the reasoning above, Provide the be...  \n",
              "4  \\nBased on the reasoning above, Provide the be...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## Import Dataset\n",
        "print('-' *42)\n",
        "file_path = '/content/sciq_test_formatted.csv'\n",
        "print(f'Importing Dataset: {file_path}')\n",
        "dataset = pd.read_csv(file_path)\n",
        "display(dataset.head())\n",
        "\n",
        "## Edit System Prompts\n",
        "print('-' *42)\n",
        "print('Editing System Prompts:')\n",
        "\n",
        "sys_prompt1 = '''\n",
        "Given the following question, analyze the options, and provide a concise reasoning for your selected answer. Your reasoning should not exceed 100 words. After your explanation, clearly state your answer by choosing one of the options listed (A, B, C, or D).\n",
        "\n",
        "Question: ${Question}\n",
        "Options:\n",
        "A) ${Option A}\n",
        "B) ${Option B}\n",
        "C) ${Option C}\n",
        "D) ${Option D}\n",
        "\n",
        "\n",
        "Please provide your reasoning first, limited to 100 words, and consider how certain you should be of your answer.\n",
        "Reasoning: <Your concise reasoning here. Max 100 words>\n",
        "'''\n",
        "sys_prompt2 = '''\n",
        "Based on the reasoning above, Provide the best answer and the likelihood that each option is correct from 0.0 to 1.0 in a JSON format. The probabilities should sum to 1.0. For example:\n",
        "\n",
        "{\n",
        "'A': <Probability choice A is correct. As a float from 0.0 to 1.0>,\n",
        "'B': <Probability choice B is correct. As a float from 0.0 to 1.0>,\n",
        "'C': <Probability choice C is correct. As a float from 0.0 to 1.0>,\n",
        "'D': <Probability choice D is correct. As a float from 0.0 to 1.0>,\n",
        "'Answer': <Your answer choice here, as a single letter and nothing else.>\n",
        "}\n",
        "\n",
        "All options have a non-zero probability of being correct. No option should have a probability of 0 or 1.\n",
        "Be modest about your certainty.  Do not provide any additional reasoning.\n",
        "\n",
        "Response:\n",
        "'''\n",
        "\n",
        "print('System Prompts:')\n",
        "print(f'  {sys_prompt1}')\n",
        "print(f'  {sys_prompt2}')\n",
        "\n",
        "\n",
        "\n",
        "## Format DF\n",
        "print('-' *42)\n",
        "print('Formatting Dataset:')\n",
        "new_dataset = format_df(dataset)\n",
        "print(' Successfully Formatted Dataset')\n",
        "print('New Dataset:')\n",
        "display(new_dataset.head())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcQdnUyXn5ak",
        "outputId": "dfac45d5-fea3-4f73-b8c4-6e87ab804881"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Given the following question, analyze the options, and provide a concise reasoning for your selected answer. Your reasoning should not exceed 100 words. After your explanation, clearly state your answer by choosing one of the options listed (A, B, C, or D).\n",
            "\n",
            "Question: The temperature at which a substance melts is called its what point?\n",
            "Options:\n",
            "A) boiling\n",
            "B) change\n",
            "C) melting\n",
            "D) freezing\n",
            "\n",
            "\n",
            "Please provide your reasoning first, limited to 100 words, and consider how certain you should be of your answer.\n",
            "Reasoning: \n"
          ]
        }
      ],
      "source": [
        "print(new_dataset['Full Prompt 1'].iloc[64])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AR8o1Z88oI6P"
      },
      "outputs": [],
      "source": [
        "## Initialize Models\n",
        "print('-' *42)\n",
        "print('Initializing Models:')\n",
        "my_closed_models = {\n",
        "    'GPT': {\n",
        "        'api_key_name': 'gpt_api_key', # Name of the key to retrieve from userdata\n",
        "        'models': [\n",
        "            'gpt-4',\n",
        "            'gpt-3.5-turbo'\n",
        "        ]\n",
        "    },\n",
        "    'Claude': {\n",
        "        'api_key_name': 'claude_api_key', # Name of the key to retrieve from userdata\n",
        "        'models': [\n",
        "            'claude-3-7-sonnet-20250219',\n",
        "            'claude-3-haiku-20240307'\n",
        "        ]\n",
        "    },\n",
        "    'Gemini': {\n",
        "        'api_key_name': 'gemini_api_key', # Name of the key to retrieve from userdata\n",
        "        'models': [\n",
        "            'gemini-1.5-flash',\n",
        "            'gemini-2.5-pro-preview-06-05'\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "closed_models = init_models(my_closed_models)\n",
        "print(' Successfully Initialied Models')\n",
        "\n",
        "## Test Models on LSAT\n",
        "print('-' *42)\n",
        "print('Testing Models:')\n",
        "\n",
        "test_models_sequential_by_question(new_dataset, closed_models, debug=False, stop = 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827,
          "referenced_widgets": [
            "5fdda4e7efb644eaa0a0844b9177c1d4",
            "3a1f19eded9d485498d261123c240740",
            "42669ab4f7cf4f0398b757e50a4f3fb5",
            "7648713ced4c4644aeb6aeb4049a8f11",
            "4a7d7f66efe14f06a407241b8f199b03",
            "220e70fcadae4407ae6d87f015b6500f",
            "942684a56a00491f92cc8ce8edaa7fb9",
            "95fa09105d8640e6a391b33056ce018f",
            "e5dfa6933a17464e97aa0f14381aaf70",
            "6c3157c8ac4048629cd7be4755e7e07a",
            "4f480b7090364b5d95cb25b84f982149",
            "b7d00a1b65894b7ba7b8e00703c73e9d",
            "323c757d9dd04e818d33d780cc77d3fc",
            "6f67d43cc0b7422b898f27a8f6a3e33b",
            "56369256ccc8442db786aea1d7e274a6",
            "cac07e5f6f934cfb9bdebc556236112e",
            "7c44d8cf2834456cbbb5137230299947",
            "d1776d7800ea41138f1e4f77de0c77e6",
            "2f99e211638a4410b35923895ff24251",
            "2f1c1f6c313649059af9b2af09115720",
            "cbf5ffe9bc664a6488b4a6288c237bea",
            "0a976d5ffda84f57bc7c77f495e71d5e",
            "30d3f72ec53f48938da84da121f58200",
            "f65c1cbd834c4e5d9893536bd6f346dd",
            "2001c04948f2494c8f39e52f3bf7f311",
            "29a80705829342e7a9b0996419edc23b",
            "dbab24ca67ec42aba171a79f7b0fe471",
            "6d14d713d2e24df8a1ad0e3b6b61b20f",
            "df01bca70ea94b8e8102412b758b26fb",
            "ea6ffdbdb3fd4d34a3644d5d5b8223e6",
            "bb700022a2054ca8a5a3143f658aa0b0",
            "88b2e8a3572d4827bb0d7364930cdfec",
            "c820f0c30f4b417fae603c1579855544"
          ]
        },
        "id": "mq00cM-YG1lR",
        "outputId": "f03a633c-f701-446c-8c4e-6fa7984ad51a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading Tokenizer for meta-llama/Llama-3.1-8B-Instruct\n",
            "Downloading Model Weights for meta-llama/Llama-3.1-8B-Instruct\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5fdda4e7efb644eaa0a0844b9177c1d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7d00a1b65894b7ba7b8e00703c73e9d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30d3f72ec53f48938da84da121f58200",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Questions:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "UnboundLocalError",
          "evalue": "cannot access local variable 'question_num' where it is not associated with a value",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Question Number'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4-2780597552.py\u001b[0m in \u001b[0;36mtest_open_model_sciq\u001b[0;34m(model, df, debug)\u001b[0m\n\u001b[1;32m    304\u001b[0m       \u001b[0;31m## Question Information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m       \u001b[0mquestion_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Question Number'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m       \u001b[0mquestion_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Full Prompt 1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Question Number'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-7-1176528903.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m Response: '''\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mllama_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_open_model_sciq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_llama\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finished benchmarking on model:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllama_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4-2780597552.py\u001b[0m in \u001b[0;36mtest_open_model_sciq\u001b[0;34m(model, df, debug)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m       new_row = pd.DataFrame([{\n\u001b[0;32m--> 340\u001b[0;31m           \u001b[0;34m'Question ID'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquestion_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m           \u001b[0;34m'Question'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquestion_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m           \u001b[0;34m'Stated Confidence'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'ERROR'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'question_num' where it is not associated with a value"
          ]
        }
      ],
      "source": [
        "\n",
        "##------------------------------------------------------------------------------\n",
        "##                             OPEN MODELS\n",
        "##------------------------------------------------------------------------------\n",
        "\n",
        "## Get llama:\n",
        "\n",
        "HF_TOKEN = userdata.get('hf_llama_token')\n",
        "model_name = 'meta-llama/Llama-3.1-8B-Instruct'\n",
        "\n",
        "\n",
        "my_llama = LlamaModel(name = model_name, key = HF_TOKEN, MaxTokens = 250)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bcd81506a60544248d6209f2e88f0d56",
            "37c9f6b6bbcf462a9758581e68a80438",
            "4cb25320b003454b9dc694503a5f7965",
            "6b8f3cd154294f94bd12d3c7403c612c",
            "78945499c68c4a6ba0907ede0ee96ed4",
            "a8ea273c994e42cf858b8f850bbbea08",
            "aeaef1b15c2a428092e858bdb337c72f",
            "93da93837b564f5db67f2aa677d14d62",
            "6acab8ff9cff4075b940dfaa01cd5cba",
            "6701e7f9060e49e8bdac1d61272948ac",
            "5a61dd3d8feb4a03a2c3a9fe6ceeb7a3"
          ]
        },
        "id": "tX6dCf4iMXiU",
        "outputId": "29aba67e-f5a4-44da-80ff-d86c02793428"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcd81506a60544248d6209f2e88f0d56",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Questions:   0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "## Get Results\n",
        "\n",
        "sys_prompt2 = '''\n",
        "Based on the reasoning above, Provide the best answer and the likelihood that each option is correct from 0.0 to 1.0 in a JSON format. The probabilities should sum to 1.0. For example:\n",
        "\n",
        "{\n",
        "'Answer': <Your answer choice here, as a single letter and nothing else>,\n",
        "'A': <Probability choice A is correct. As a float from 0.0 to 1.0>,\n",
        "'B': <Probability choice B is correct. As a float from 0.0 to 1.0>,\n",
        "'C': <Probability choice C is correct. As a float from 0.0 to 1.0>,\n",
        "'D': <Probability choice D is correct. As a float from 0.0 to 1.0>,\n",
        "'E': <Probability choice E is correct. As a float from 0.0 to 1.0>\n",
        "}<|eot_id|>\n",
        "\n",
        "All options have a non-zero probability of being correct. No option should have a probability of 0 or 1.\n",
        "Be modest about your certainty.  Do not provide any additional reasoning.\n",
        "\n",
        "Response: '''\n",
        "\n",
        "\n",
        "llama_results = test_open_model_sciq(my_llama, new_dataset, debug = False)\n",
        "print('Finished benchmarking on model:')\n",
        "display(llama_results)\n",
        "\n",
        "\n",
        "## Save to drive\n",
        "\n",
        "sciq_folder_path = '/content/drive/MyDrive/SciQ'\n",
        "\n",
        "\n",
        "if not os.path.exists(sciq_folder_path):\n",
        "    os.makedirs(sciq_folder_path)\n",
        "    print(f\"Created folder: {sciq_folder_path}\")\n",
        "\n",
        "# Define the full path for the CSV file\n",
        "output_filename = f'SciQ_{model_name}'\n",
        "output_filename = output_filename.replace('/', '_').replace('-','_').replace('.','_') + '.csv'\n",
        "output_path = os.path.join(sciq_folder_path, output_filename)\n",
        "\n",
        "# 2. Save the DataFrame to the specified path\n",
        "llama_results.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Successfully saved llama_results to {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XrRgwB-NlfO",
        "outputId": "685d9e28-f0ad-4826-e114-621e7c57a5b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: \n",
            "Given the following question, analyze the options, and provide a concise reasoning for your selected answer. Your reasoning should not exceed 100 words. After your explanation, clearly state your answer by choosing one of the options listed (A, B, C, or D).\n",
            "\n",
            "Question: Compounds that are capable of accepting electrons, such as o 2 or f2, are called what?\n",
            "Options:\n",
            "A) antioxidants\n",
            "B) Oxygen\n",
            "C) oxidants\n",
            "D) residues\n",
            "\n",
            "\n",
            "Please provide your reasoning first, limited to 100 words, and consider how certain you should be of your answer.\n",
            "Reasoning: \n",
            "------------------------------------------\n",
            "Reasoning:  Compounds that accept electrons are known as oxidants. This is because they cause oxidation, which is the loss of electrons. Oxidants are often involved in chemical reactions that result in the transfer of electrons. In the context of the question, oxygen (o 2) and fluorine (f2) are both capable of accepting electrons, making them examples of oxidants. Therefore, the correct answer is C) oxidants. I am 90% certain of this answer.\n",
            "\n",
            "Answer: C) oxidants.  I am 90% certain of this answer.  I am not 100% certain because I am not an expert in chemistry, but based on my knowledge, I believe that the correct answer is C) oxidants.  I am 90% certain because I have a good understanding of the concept of oxidation and the role of oxidants in chemical reactions.  However, I may be missing some nuance or detail that would make me 100% certain.  Nevertheless, based on my analysis, I believe that C) oxidants is the correct answer.  I am willing to be corrected if I am wrong.  I am 90% certain because I have a good understanding of the concept of oxidation and\n",
            "------------------------------------------\n",
            "Confidence: {'Answer': 'C', 'A': 0.05, 'B': 0.1, 'C': 0.9, 'D': 0.05}\n"
          ]
        }
      ],
      "source": [
        "question = llama_results['Question'].iloc[0]\n",
        "sc = llama_results['Stated Confidence'].iloc[0]\n",
        "reasoning = llama_results['Reasoning'].iloc[0]\n",
        "print(f'Question: {question}')\n",
        "print('-' *42)\n",
        "print(f'Reasoning: {reasoning}')\n",
        "print('-' *42)\n",
        "print(f'Confidence: {sc}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOIoCVRIyLXjKLcRXdVYF37",
      "gpuType": "A100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "mount_file_id": "1e3gILiNk_1_2d5C-i-aVEWCacRR_cg1G",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a976d5ffda84f57bc7c77f495e71d5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2001c04948f2494c8f39e52f3bf7f311": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea6ffdbdb3fd4d34a3644d5d5b8223e6",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb700022a2054ca8a5a3143f658aa0b0",
            "value": 0
          }
        },
        "220e70fcadae4407ae6d87f015b6500f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29a80705829342e7a9b0996419edc23b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88b2e8a3572d4827bb0d7364930cdfec",
            "placeholder": "​",
            "style": "IPY_MODEL_c820f0c30f4b417fae603c1579855544",
            "value": " 0/3 [00:00&lt;?, ?it/s]"
          }
        },
        "2f1c1f6c313649059af9b2af09115720": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f99e211638a4410b35923895ff24251": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30d3f72ec53f48938da84da121f58200": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f65c1cbd834c4e5d9893536bd6f346dd",
              "IPY_MODEL_2001c04948f2494c8f39e52f3bf7f311",
              "IPY_MODEL_29a80705829342e7a9b0996419edc23b"
            ],
            "layout": "IPY_MODEL_dbab24ca67ec42aba171a79f7b0fe471"
          }
        },
        "323c757d9dd04e818d33d780cc77d3fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c44d8cf2834456cbbb5137230299947",
            "placeholder": "​",
            "style": "IPY_MODEL_d1776d7800ea41138f1e4f77de0c77e6",
            "value": "generation_config.json: 100%"
          }
        },
        "37c9f6b6bbcf462a9758581e68a80438": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8ea273c994e42cf858b8f850bbbea08",
            "placeholder": "​",
            "style": "IPY_MODEL_aeaef1b15c2a428092e858bdb337c72f",
            "value": "Processing Questions:  24%"
          }
        },
        "3a1f19eded9d485498d261123c240740": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_220e70fcadae4407ae6d87f015b6500f",
            "placeholder": "​",
            "style": "IPY_MODEL_942684a56a00491f92cc8ce8edaa7fb9",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "42669ab4f7cf4f0398b757e50a4f3fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95fa09105d8640e6a391b33056ce018f",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5dfa6933a17464e97aa0f14381aaf70",
            "value": 4
          }
        },
        "4a7d7f66efe14f06a407241b8f199b03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cb25320b003454b9dc694503a5f7965": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93da93837b564f5db67f2aa677d14d62",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6acab8ff9cff4075b940dfaa01cd5cba",
            "value": 240
          }
        },
        "4f480b7090364b5d95cb25b84f982149": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56369256ccc8442db786aea1d7e274a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbf5ffe9bc664a6488b4a6288c237bea",
            "placeholder": "​",
            "style": "IPY_MODEL_0a976d5ffda84f57bc7c77f495e71d5e",
            "value": " 184/184 [00:00&lt;00:00, 22.0kB/s]"
          }
        },
        "5a61dd3d8feb4a03a2c3a9fe6ceeb7a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fdda4e7efb644eaa0a0844b9177c1d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a1f19eded9d485498d261123c240740",
              "IPY_MODEL_42669ab4f7cf4f0398b757e50a4f3fb5",
              "IPY_MODEL_7648713ced4c4644aeb6aeb4049a8f11"
            ],
            "layout": "IPY_MODEL_4a7d7f66efe14f06a407241b8f199b03"
          }
        },
        "6701e7f9060e49e8bdac1d61272948ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6acab8ff9cff4075b940dfaa01cd5cba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b8f3cd154294f94bd12d3c7403c612c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6701e7f9060e49e8bdac1d61272948ac",
            "placeholder": "​",
            "style": "IPY_MODEL_5a61dd3d8feb4a03a2c3a9fe6ceeb7a3",
            "value": " 240/1000 [45:56&lt;2:25:47, 11.51s/it]"
          }
        },
        "6c3157c8ac4048629cd7be4755e7e07a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d14d713d2e24df8a1ad0e3b6b61b20f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f67d43cc0b7422b898f27a8f6a3e33b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f99e211638a4410b35923895ff24251",
            "max": 184,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f1c1f6c313649059af9b2af09115720",
            "value": 184
          }
        },
        "7648713ced4c4644aeb6aeb4049a8f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c3157c8ac4048629cd7be4755e7e07a",
            "placeholder": "​",
            "style": "IPY_MODEL_4f480b7090364b5d95cb25b84f982149",
            "value": " 4/4 [00:04&lt;00:00,  1.00s/it]"
          }
        },
        "78945499c68c4a6ba0907ede0ee96ed4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c44d8cf2834456cbbb5137230299947": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88b2e8a3572d4827bb0d7364930cdfec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93da93837b564f5db67f2aa677d14d62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "942684a56a00491f92cc8ce8edaa7fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95fa09105d8640e6a391b33056ce018f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8ea273c994e42cf858b8f850bbbea08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeaef1b15c2a428092e858bdb337c72f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7d00a1b65894b7ba7b8e00703c73e9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_323c757d9dd04e818d33d780cc77d3fc",
              "IPY_MODEL_6f67d43cc0b7422b898f27a8f6a3e33b",
              "IPY_MODEL_56369256ccc8442db786aea1d7e274a6"
            ],
            "layout": "IPY_MODEL_cac07e5f6f934cfb9bdebc556236112e"
          }
        },
        "bb700022a2054ca8a5a3143f658aa0b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bcd81506a60544248d6209f2e88f0d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37c9f6b6bbcf462a9758581e68a80438",
              "IPY_MODEL_4cb25320b003454b9dc694503a5f7965",
              "IPY_MODEL_6b8f3cd154294f94bd12d3c7403c612c"
            ],
            "layout": "IPY_MODEL_78945499c68c4a6ba0907ede0ee96ed4"
          }
        },
        "c820f0c30f4b417fae603c1579855544": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cac07e5f6f934cfb9bdebc556236112e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbf5ffe9bc664a6488b4a6288c237bea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1776d7800ea41138f1e4f77de0c77e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbab24ca67ec42aba171a79f7b0fe471": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df01bca70ea94b8e8102412b758b26fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5dfa6933a17464e97aa0f14381aaf70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea6ffdbdb3fd4d34a3644d5d5b8223e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f65c1cbd834c4e5d9893536bd6f346dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d14d713d2e24df8a1ad0e3b6b61b20f",
            "placeholder": "​",
            "style": "IPY_MODEL_df01bca70ea94b8e8102412b758b26fb",
            "value": "Processing Questions:   0%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
