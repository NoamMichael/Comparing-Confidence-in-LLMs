{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2436248",
   "metadata": {},
   "source": [
    "# Comparing Calibration Data Across All Models / Question Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8736a505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from -r requirements.txt (line 1)) (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from -r requirements.txt (line 2)) (2.3.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from -r requirements.txt (line 3)) (3.10.7)\n",
      "Requirement already satisfied: seaborn in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from -r requirements.txt (line 4)) (0.13.2)\n",
      "Requirement already satisfied: google in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from -r requirements.txt (line 5)) (3.0.0)\n",
      "Requirement already satisfied: openai in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from -r requirements.txt (line 6)) (2.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (3.2.5)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from google->-r requirements.txt (line 5)) (4.14.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 6)) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 6)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 6)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 6)) (0.11.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 6)) (2.12.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 6)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 6)) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 6)) (3.11)\n",
      "Requirement already satisfied: certifi in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 6)) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 6)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 6)) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 6)) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 6)) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from tqdm>4->openai->-r requirements.txt (line 6)) (0.4.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from beautifulsoup4->google->-r requirements.txt (line 5)) (2.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9704e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2f7b78",
   "metadata": {},
   "source": [
    "## Combine All Results Into Composite CSV\n",
    "\n",
    "First we will read from the Parsed Results folder and make a dictionary that abstracts the structure of the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "009288cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Claude', 'Deepseek', 'Gemini', 'GPT', 'Llama'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the folder and create a dictionary to model the structure of the files\n",
    "\n",
    "def folder_tree_dict(root, *, include_files=True, follow_symlinks=False, ignore_hidden=True):\n",
    "    root = Path(root)\n",
    "\n",
    "    def build(p: Path):\n",
    "        out = {}\n",
    "        for entry in sorted(p.iterdir(), key=lambda x: (x.is_file(), x.name.lower())):\n",
    "            if ignore_hidden and entry.name.startswith(\".\"):\n",
    "                continue\n",
    "            try:\n",
    "                if entry.is_dir() and (follow_symlinks or not entry.is_symlink()):\n",
    "                    out[entry.name] = build(entry)\n",
    "                else:\n",
    "                    if include_files:\n",
    "                        out[entry.name] = None  # or {\"size\": entry.stat().st_size}\n",
    "            except PermissionError:\n",
    "                out[entry.name] = \"<permission-denied>\"\n",
    "        return out\n",
    "\n",
    "    return {root.name: build(root)}\n",
    "\n",
    "\n",
    "folder_path = r\"Parsed Results\"\n",
    "\n",
    "folder_abstraction_dict = folder_tree_dict(folder_path)[folder_path]\n",
    "\n",
    "folder_abstraction_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081f850c",
   "metadata": {},
   "source": [
    "### Combined CSV\n",
    "We want to make a well-formed CSV for future analysis. This CSV will have the following fields for columns:\n",
    "\n",
    "```text\n",
    "Question Set (str) ---------------- Required: The display name of the question set\n",
    "Question ID (str) ----------------- Required: The Question ID\n",
    "Model (str) ----------------------- Required: The model that provided the response (e.g. Llama-3.1-8B-Instruct)\n",
    "Model Type (str) ------------------ Required: The family of models which  the model (e.g. Llama)\n",
    "Coerce (Bool) --------------------- Required: Whether the parser was able to understand the response\n",
    "\n",
    "Question (str) -------------------- Required: The question posed to the model\n",
    "Correct Answer (str) -------------- Optional: Depends on Question Set (LifeEval is different than others)\n",
    "Content (str) --------------------- Optional: Depends on Coerce value (NA if Coerce == False)\n",
    "Reasoning (str) ------------------- Optional: Depends on Coerce value (NA if Coerce == False)\n",
    "Answer (str) ---------------------- Optional: Depends on Coerce value (NA if Coerce == False)\n",
    "Score (float) --------------------- Optional: Depends on Coerce value (NA if Coerce == False)\n",
    "\n",
    "Stated Confidence Answer (float) -- Optional: Depends on Question Set (NA if not available)\n",
    "Stated Confidence A (float) ------- Optional: Depends on Question Set (NA if not available)\n",
    "Stated Confidence B (float) ------- Optional: Depends on Question Set (NA if not available)\n",
    "Stated Confidence C (float) ------- Optional: Depends on Question Set (NA if not available)\n",
    "Stated Confidence D (float) ------- Optional: Depends on Question Set (NA if not available)\n",
    "Stated Confidence E (float)-------- Optional: Depends on Question Set (NA if not available)\n",
    "\n",
    "Token Probability Answer (float) -- Optional: Depends on Model Type (NA if not available)\n",
    "Token Probability A (float) ------- Optional: Depends on Model Type (NA if not available)\n",
    "Token Probability B (float) ------- Optional: Depends on Model Type (NA if not available)\n",
    "Token Probability C (float) ------- Optional: Depends on Model Type (NA if not available)\n",
    "Token Probability D (float) ------- Optional: Depends on Model Type (NA if not available)\n",
    "Token Probability E (float) ------- Optional: Depends on Model Type (NA if not available)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ac22891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed Results/Claude\n",
      "    Parsed Results/Claude/claude-3-7-sonnet-20250219\n",
      "        boolq_valid    \n",
      "        halu_eval_qa    \n",
      "        life_eval    \n",
      "        lsat_ar_test    \n",
      "        sat_en    \n",
      "        sciq_test    \n",
      "    Parsed Results/Claude/claude-3-haiku-20240307\n",
      "        boolq_valid    \n",
      "        halu_eval_qa    \n",
      "        life_eval    \n",
      "        lsat_ar_test    \n",
      "        sat_en    \n",
      "        sciq_test    \n",
      "    Parsed Results/Claude/claude-sonnet-4-20250514\n",
      "        boolq_valid    \n",
      "        halu_eval_qa    \n",
      "        life_eval    \n",
      "        lsat_ar_test    \n",
      "        sat_en    \n",
      "        sciq_test    \n",
      "Parsed Results/Deepseek\n",
      "    Parsed Results/Deepseek/deepseek-r1\n",
      "        boolq_valid    \n",
      "        halu_eval_qa    \n",
      "        life_eval    \n",
      "        lsat_ar_test    \n",
      "        sat_en    \n",
      "        sciq_test    \n",
      "    Parsed Results/Deepseek/deepseek-v3\n",
      "        boolq_valid    \n",
      "        halu_eval_qa    \n",
      "        life_eval    \n",
      "        lsat_ar_test    \n",
      "        sat_en    \n",
      "        sciq_test    \n",
      "Parsed Results/Gemini\n",
      "    Parsed Results/Gemini/gemini-2.5-flash\n",
      "        boolq_valid    \n",
      "        halu_eval_qa    \n",
      "        life_eval    \n",
      "        lsat_ar_test    \n",
      "        sat_en    \n",
      "        sciq_test    \n",
      "    Parsed Results/Gemini/gemini-2.5-pro\n",
      "        boolq_valid    \n",
      "        halu_eval_qa    \n",
      "        life_eval    \n",
      "        lsat_ar_test    \n",
      "        sat_en    \n",
      "        sciq_test    \n",
      "Parsed Results/GPT\n",
      "    Parsed Results/GPT/gpt-4o\n",
      "        boolq_valid    \n",
      "        halu_eval_qa    \n",
      "        life_eval    \n",
      "        lsat_ar_test    \n",
      "        sat_en    \n",
      "        sciq_test    \n",
      "    Parsed Results/GPT/o3-2025-04-16\n",
      "        boolq_valid    \n",
      "        halu_eval_qa    \n",
      "        life_eval    \n",
      "        lsat_ar_test    \n",
      "        sat_en    \n",
      "        sciq_test    \n",
      "Parsed Results/Llama\n",
      "    Parsed Results/Llama/Meta-Llama-3.1-70B-Instruct\n",
      "        boolq_valid    \n",
      "        halu_eval_qa    \n",
      "        life_eval    \n",
      "        lsat_ar_test    \n",
      "        sat_en    \n",
      "        sciq_test    \n",
      "    Parsed Results/Llama/Meta-Llama-3.1-8B-Instruct\n",
      "        boolq_valid    \n",
      "        halu_eval_qa    \n",
      "        life_eval    \n",
      "        lsat_ar_test    \n",
      "        sat_en    \n",
      "        sciq_test    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reasoning</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Stated Confidence Answer</th>\n",
       "      <th>Coerce</th>\n",
       "      <th>Content</th>\n",
       "      <th>Question ID</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Question Set</th>\n",
       "      <th>Stated Confidence A</th>\n",
       "      <th>Stated Confidence B</th>\n",
       "      <th>Stated Confidence C</th>\n",
       "      <th>Stated Confidence D</th>\n",
       "      <th>Stated Confidence E</th>\n",
       "      <th>Token Probability True</th>\n",
       "      <th>Token Probability False</th>\n",
       "      <th>Token Probability Answer</th>\n",
       "      <th>Token Probability A</th>\n",
       "      <th>Token Probability B</th>\n",
       "      <th>Token Probability C</th>\n",
       "      <th>Token Probability D</th>\n",
       "      <th>Token Probability E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The question is asking whether the production ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n    \"Reasoning\": \"The question is asking wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>Claude</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>House tax and property tax are often used inte...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.85</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n    \"Reasoning\": \"House tax and property ta...</td>\n",
       "      <td>1</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>Claude</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This question is asking about phantom limb pai...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.95</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n    \"Reasoning\": \"This question is asking a...</td>\n",
       "      <td>2</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>Claude</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Escape from Gringotts is ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.98</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n    \"Reasoning\": \"Harry Potter and the Esca...</td>\n",
       "      <td>3</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>Claude</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hydroxyzine HCl (hydrochloride) and hydroxyzin...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.98</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n    \"Reasoning\": \"Hydroxyzine HCl (hydrochl...</td>\n",
       "      <td>4</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>Claude</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Reasoning Answer  \\\n",
       "0  The question is asking whether the production ...  False   \n",
       "1  House tax and property tax are often used inte...   True   \n",
       "2  This question is asking about phantom limb pai...   True   \n",
       "3  Harry Potter and the Escape from Gringotts is ...   True   \n",
       "4  Hydroxyzine HCl (hydrochloride) and hydroxyzin...   True   \n",
       "\n",
       "  Stated Confidence Answer  Coerce  \\\n",
       "0                      0.6    True   \n",
       "1                     0.85    True   \n",
       "2                     0.95    True   \n",
       "3                     0.98    True   \n",
       "4                     0.98    True   \n",
       "\n",
       "                                             Content Question ID  \\\n",
       "0  {\\n    \"Reasoning\": \"The question is asking wh...           0   \n",
       "1  {\\n    \"Reasoning\": \"House tax and property ta...           1   \n",
       "2  {\\n    \"Reasoning\": \"This question is asking a...           2   \n",
       "3  {\\n    \"Reasoning\": \"Harry Potter and the Esca...           3   \n",
       "4  {\\n    \"Reasoning\": \"Hydroxyzine HCl (hydrochl...           4   \n",
       "\n",
       "                        Model Model Type Question Set  Stated Confidence A  \\\n",
       "0  claude-3-7-sonnet-20250219     Claude        BoolQ                  NaN   \n",
       "1  claude-3-7-sonnet-20250219     Claude        BoolQ                  NaN   \n",
       "2  claude-3-7-sonnet-20250219     Claude        BoolQ                  NaN   \n",
       "3  claude-3-7-sonnet-20250219     Claude        BoolQ                  NaN   \n",
       "4  claude-3-7-sonnet-20250219     Claude        BoolQ                  NaN   \n",
       "\n",
       "   Stated Confidence B  Stated Confidence C  Stated Confidence D  \\\n",
       "0                  NaN                  NaN                  NaN   \n",
       "1                  NaN                  NaN                  NaN   \n",
       "2                  NaN                  NaN                  NaN   \n",
       "3                  NaN                  NaN                  NaN   \n",
       "4                  NaN                  NaN                  NaN   \n",
       "\n",
       "   Stated Confidence E  Token Probability True  Token Probability False  \\\n",
       "0                  NaN                     NaN                      NaN   \n",
       "1                  NaN                     NaN                      NaN   \n",
       "2                  NaN                     NaN                      NaN   \n",
       "3                  NaN                     NaN                      NaN   \n",
       "4                  NaN                     NaN                      NaN   \n",
       "\n",
       "   Token Probability Answer  Token Probability A  Token Probability B  \\\n",
       "0                       NaN                  NaN                  NaN   \n",
       "1                       NaN                  NaN                  NaN   \n",
       "2                       NaN                  NaN                  NaN   \n",
       "3                       NaN                  NaN                  NaN   \n",
       "4                       NaN                  NaN                  NaN   \n",
       "\n",
       "   Token Probability C  Token Probability D  Token Probability E  \n",
       "0                  NaN                  NaN                  NaN  \n",
       "1                  NaN                  NaN                  NaN  \n",
       "2                  NaN                  NaN                  NaN  \n",
       "3                  NaN                  NaN                  NaN  \n",
       "4                  NaN                  NaN                  NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined_df = pd.DataFrame()\n",
    "clean_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "mcq_qsets = ['LSAT-AR', 'SAT-EN', 'SciQ']\n",
    "\n",
    "\n",
    "\n",
    "for model_type, models in folder_abstraction_dict.items():\n",
    "    model_type_path = folder_path + f\"/{model_type}\"\n",
    "    print(model_type_path)\n",
    "    for model_name, qsets in models.items():\n",
    "        model_path = model_type_path + f\"/{model_name}\"\n",
    "        print(f\"    {model_path}\")\n",
    "        for qset_file_name in qsets:\n",
    "            splitter = f\"_{model_name}\"\n",
    "            qset_name = qset_file_name.split(splitter)[0]\n",
    "            qset_path = model_path + f\"/{qset_file_name}\"\n",
    "            \n",
    "            #--------- Write a function to spit out a dataframe w/ model_name, qset_name, true_answer and concat it\n",
    "\n",
    "            source_df = pd.read_csv(qset_path)\n",
    "            print(f\"        {qset_name}    \")\n",
    "            source_df[\"Model\"] = model_name\n",
    "            source_df[\"Model Type\"] = model_type\n",
    "            source_df[\"Question Set\"] = qset_name\n",
    "            source_df[\"Question ID\"] = source_df[\"Question ID\"].astype(str)\n",
    "            combined_df = pd.concat([combined_df, source_df], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "combined_df.drop([\"Unnamed: 0\", \"Question ID.1\"], axis = 1, inplace = True)\n",
    "\n",
    "## Still need to add correct answer and score\n",
    "\n",
    "col_rename_map ={\n",
    "# Metadata\n",
    "'Question Set': \"Question Set\",\n",
    "'Question ID': \"Question ID\",\n",
    "'Model': \"Model\",\n",
    "'Model Type': \"Model Type\",\n",
    "'coerce': \"Coerce\",\n",
    "\n",
    "# Model Response\n",
    "\n",
    "'content': \"Content\",\n",
    "'Reasoning': \"Reasoning\",\n",
    "'Answer': \"Answer\",\n",
    "\n",
    "# Stated Confidence\n",
    "'Confidence': \"Stated Confidence Answer\",\n",
    "\"A\": \"Stated Confidence A\",\n",
    "\"B\": \"Stated Confidence B\",\n",
    "'C': \"Stated Confidence C\",\n",
    "'D': \"Stated Confidence D\",\n",
    "'E': \"Stated Confidence E\",\n",
    "\n",
    "# Token Probability\n",
    "'True_prob': \"Token Probability True\",\n",
    "'False_prob': \"Token Probability False\",\n",
    "'Answer_prob': \"Token Probability Answer\",\n",
    "'A_prob': \"Token Probability A\",\n",
    "'B_prob': \"Token Probability B\",\n",
    "'C_prob': \"Token Probability C\",\n",
    "'D_prob': \"Token Probability D\",\n",
    "'E_prob': \"Token Probability E\"\n",
    "}\n",
    "\n",
    "combined_df = combined_df.rename(columns = col_rename_map)\n",
    "\n",
    "qset_rename = {\n",
    " 'boolq_valid': \"BoolQ\",\n",
    " 'halu_eval_qa': \"HaluEval\",\n",
    " 'life_eval': \"LifeEval\",\n",
    " 'lsat_ar_test': \"LSAT-AR\",\n",
    " 'sat_en': \"SAT-EN\",\n",
    " 'sciq_test':\"SciQ\"\n",
    "}\n",
    "\n",
    "combined_df[\"Question Set\"] = combined_df[\"Question Set\"].map(qset_rename)\n",
    "\n",
    "with pd.option_context('display.max_columns', None,\n",
    "                       #'display.width', None,\n",
    "                       #'display.max_colwidth', None\n",
    "                       ):\n",
    "    display(combined_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "666f9edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_clean = combined_df.copy()\n",
    "combined_clean['combined_name'] = combined_clean['Question ID'] + \"_\" + combined_clean[\"Question Set\"]\n",
    "\n",
    "s = combined_clean[\"combined_name\"].value_counts() % 11  #---------------- This seems to get rid of too much\n",
    "bad_qid = s.index[s.ne(0)].tolist()  \n",
    "\n",
    "combined_clean = combined_clean[~combined_clean[\"combined_name\"].isin(bad_qid)]\n",
    "\n",
    "\n",
    "# this gets the qid and qset where coerce is false\n",
    "bad_qid_qset = combined_df[combined_df[\"Coerce\"] == False][[\"Question ID\", \"Question Set\"]]\n",
    "\n",
    "#bad_qid_qset = bad_qid_qset[[\"Question ID\", \"Question Set\"]]\n",
    "\n",
    "bad = set(bad_qid_qset[\"Question ID\"] +  \"_\" + bad_qid_qset[\"Question Set\"])\n",
    "\n",
    "\n",
    "combined_clean['combined_name'] = combined_clean['Question ID'] + \"_\" + combined_clean[\"Question Set\"]\n",
    "\n",
    "\n",
    "\n",
    "mask = ~combined_clean[\"combined_name\"].isin(bad)   # True = keep\n",
    "\n",
    "combined_clean = combined_clean[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d71da9d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reasoning</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Stated Confidence Answer</th>\n",
       "      <th>Coerce</th>\n",
       "      <th>Content</th>\n",
       "      <th>Question ID</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Question Set</th>\n",
       "      <th>Stated Confidence A</th>\n",
       "      <th>...</th>\n",
       "      <th>Stated Confidence E</th>\n",
       "      <th>Token Probability True</th>\n",
       "      <th>Token Probability False</th>\n",
       "      <th>Token Probability Answer</th>\n",
       "      <th>Token Probability A</th>\n",
       "      <th>Token Probability B</th>\n",
       "      <th>Token Probability C</th>\n",
       "      <th>Token Probability D</th>\n",
       "      <th>Token Probability E</th>\n",
       "      <th>combined_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The question is asking whether the production ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n    \"Reasoning\": \"The question is asking wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>Claude</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0_BoolQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This question is asking about phantom limb pai...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.95</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n    \"Reasoning\": \"This question is asking a...</td>\n",
       "      <td>2</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>Claude</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2_BoolQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Escape from Gringotts is ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.98</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n    \"Reasoning\": \"Harry Potter and the Esca...</td>\n",
       "      <td>3</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>Claude</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3_BoolQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hydroxyzine HCl (hydrochloride) and hydroxyzin...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.98</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n    \"Reasoning\": \"Hydroxyzine HCl (hydrochl...</td>\n",
       "      <td>4</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>Claude</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4_BoolQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Barq's Root Beer is not a Pepsi product. It is...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.98</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n    \"Reasoning\": \"Barq's Root Beer is not a...</td>\n",
       "      <td>5</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>Claude</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5_BoolQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Reasoning Answer  \\\n",
       "0  The question is asking whether the production ...  False   \n",
       "2  This question is asking about phantom limb pai...   True   \n",
       "3  Harry Potter and the Escape from Gringotts is ...   True   \n",
       "4  Hydroxyzine HCl (hydrochloride) and hydroxyzin...   True   \n",
       "5  Barq's Root Beer is not a Pepsi product. It is...  False   \n",
       "\n",
       "  Stated Confidence Answer  Coerce  \\\n",
       "0                      0.6    True   \n",
       "2                     0.95    True   \n",
       "3                     0.98    True   \n",
       "4                     0.98    True   \n",
       "5                     0.98    True   \n",
       "\n",
       "                                             Content Question ID  \\\n",
       "0  {\\n    \"Reasoning\": \"The question is asking wh...           0   \n",
       "2  {\\n    \"Reasoning\": \"This question is asking a...           2   \n",
       "3  {\\n    \"Reasoning\": \"Harry Potter and the Esca...           3   \n",
       "4  {\\n    \"Reasoning\": \"Hydroxyzine HCl (hydrochl...           4   \n",
       "5  {\\n    \"Reasoning\": \"Barq's Root Beer is not a...           5   \n",
       "\n",
       "                        Model Model Type Question Set  Stated Confidence A  \\\n",
       "0  claude-3-7-sonnet-20250219     Claude        BoolQ                  NaN   \n",
       "2  claude-3-7-sonnet-20250219     Claude        BoolQ                  NaN   \n",
       "3  claude-3-7-sonnet-20250219     Claude        BoolQ                  NaN   \n",
       "4  claude-3-7-sonnet-20250219     Claude        BoolQ                  NaN   \n",
       "5  claude-3-7-sonnet-20250219     Claude        BoolQ                  NaN   \n",
       "\n",
       "   ...  Stated Confidence E  Token Probability True  Token Probability False  \\\n",
       "0  ...                  NaN                     NaN                      NaN   \n",
       "2  ...                  NaN                     NaN                      NaN   \n",
       "3  ...                  NaN                     NaN                      NaN   \n",
       "4  ...                  NaN                     NaN                      NaN   \n",
       "5  ...                  NaN                     NaN                      NaN   \n",
       "\n",
       "   Token Probability Answer  Token Probability A  Token Probability B  \\\n",
       "0                       NaN                  NaN                  NaN   \n",
       "2                       NaN                  NaN                  NaN   \n",
       "3                       NaN                  NaN                  NaN   \n",
       "4                       NaN                  NaN                  NaN   \n",
       "5                       NaN                  NaN                  NaN   \n",
       "\n",
       "   Token Probability C  Token Probability D  Token Probability E  \\\n",
       "0                  NaN                  NaN                  NaN   \n",
       "2                  NaN                  NaN                  NaN   \n",
       "3                  NaN                  NaN                  NaN   \n",
       "4                  NaN                  NaN                  NaN   \n",
       "5                  NaN                  NaN                  NaN   \n",
       "\n",
       "   combined_name  \n",
       "0        0_BoolQ  \n",
       "2        2_BoolQ  \n",
       "3        3_BoolQ  \n",
       "4        4_BoolQ  \n",
       "5        5_BoolQ  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(69278, 23)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Clean up MCQ Question Sets\n",
    "cc = combined_clean[combined_clean[\"Question Set\"].isin(mcq_qsets)]\n",
    "cc_letters = cc[[\"Stated Confidence A\", \"Stated Confidence B\", \"Stated Confidence C\",\"Stated Confidence D\",\"Stated Confidence E\",]].copy()\n",
    "sum_confidence = cc_letters.sum(axis = 1)\n",
    "\n",
    "con_mask = cc[sum_confidence == 0.0][\"combined_name\"]\n",
    "\n",
    "# Indixes that aren't in con_mask\n",
    "combined_clean = combined_clean.loc[~combined_clean[\"combined_name\"].isin(con_mask)]\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "## Make sure we also elimanate QID that are missing\n",
    "# he = combined_clean[combined_clean[\"Question Set\"] == \"HaluEval\"]\n",
    "\n",
    "# s = combined_clean[\"combined_name\"].value_counts() % 11  #---------------- This seems to get rid of too much\n",
    "# bad_qid = s.index[s.ne(0)].tolist()  \n",
    "\n",
    "\n",
    "\n",
    "combined_clean = combined_clean[~combined_clean[\"combined_name\"].isin(bad_qid)]\n",
    "\n",
    "\n",
    "## Special mask for LifeEval:\n",
    "\n",
    "le_df = combined_clean[combined_clean[\"Question Set\"] == \"LifeEval\"]\n",
    "\n",
    "con_isnum = pd.to_numeric( le_df['Stated Confidence Answer'], errors='coerce').notna()\n",
    "le_bad_qid= le_df[~con_isnum][\"combined_name\"]\n",
    "\n",
    "\n",
    "combined_clean = combined_clean[(~combined_clean[\"combined_name\"].isin(le_bad_qid)) ]\n",
    "\n",
    "\n",
    "display(combined_clean.head(5))\n",
    "combined_clean.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8879e949",
   "metadata": {},
   "source": [
    "## Summary Info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd746d8",
   "metadata": {},
   "source": [
    "Here we see the Raw versus Filtered counts for all the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9efcb31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw</th>\n",
       "      <th>Filtered</th>\n",
       "      <th>Prop. Kept</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Question Set</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BoolQ</th>\n",
       "      <td>3270.000000</td>\n",
       "      <td>2503.0</td>\n",
       "      <td>0.765443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HaluEval</th>\n",
       "      <td>1998.909091</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>0.895488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSAT-AR</th>\n",
       "      <td>229.909091</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.374061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LifeEval</th>\n",
       "      <td>808.000000</td>\n",
       "      <td>751.0</td>\n",
       "      <td>0.929455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAT-EN</th>\n",
       "      <td>206.000000</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.839806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SciQ</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>995.0</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Raw  Filtered  Prop. Kept\n",
       "Question Set                                   \n",
       "BoolQ         3270.000000    2503.0    0.765443\n",
       "HaluEval      1998.909091    1790.0    0.895488\n",
       "LSAT-AR        229.909091      86.0    0.374061\n",
       "LifeEval       808.000000     751.0    0.929455\n",
       "SAT-EN         206.000000     173.0    0.839806\n",
       "SciQ          1000.000000     995.0    0.995000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = pd.DataFrame({\n",
    "    \"Raw\": combined_df[\"Question Set\"].value_counts() / 11, # This is slightly below 2000 for Llama because we had to drop 3 duplicates\n",
    "    \"Filtered\": combined_clean[\"Question Set\"].value_counts() / 11\n",
    "})\n",
    "\n",
    "counts[~counts.index.isin(mcq_qsets)]\n",
    "\n",
    "counts[\"Prop. Kept\"] = counts[\"Filtered\"] / counts[\"Raw\"]\n",
    "counts\n",
    "# Need to look at: LSAT-AR (-1)???,  Sciq(-1) Im getting rid of too much?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bff4a25",
   "metadata": {},
   "source": [
    "Jacob's cleaned version of SciQ has 996 rows while mine has 995. When investigating each deleted Question ID in my version we find that they all have 1 instance where the answer could not be coerced. Does Jacob have an extra question that shouldn't be there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e58eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question ID</th>\n",
       "      <th>false_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>295</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Question ID  false_count\n",
       "0          13            1\n",
       "1         295            1\n",
       "2          40            1\n",
       "3         699            1\n",
       "4         705            1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "sciq_filtered = combined_clean[combined_clean[\"Question Set\"] == \"SciQ\"]\n",
    "sciq_raw = combined_df[combined_df[\"Question Set\"] == \"SciQ\"]\n",
    "\n",
    "\n",
    "sciq_filtered_ids = sciq_filtered.index\n",
    "\n",
    "deleted = sciq_raw[~sciq_raw.index.isin(sciq_filtered_ids)]\n",
    "deleted[\"Question ID\"].unique()\n",
    "\n",
    "# Deleted QID in SciQ are ['13', '40', '295', '699', '705'] after visual inspection they all seem to have False coerce values in one of 11 rows\n",
    "\n",
    "\n",
    "false_counts = (deleted['Coerce'].eq(False)\n",
    "                .groupby(deleted['Question ID'])\n",
    "                .sum()\n",
    "                .rename('false_count'))\n",
    "\n",
    "# as a DataFrame\n",
    "false_counts = false_counts.reset_index()\n",
    "false_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7316c437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reasoning</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Stated Confidence Answer</th>\n",
       "      <th>Coerce</th>\n",
       "      <th>Content</th>\n",
       "      <th>Question ID</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Question Set</th>\n",
       "      <th>Stated Confidence A</th>\n",
       "      <th>...</th>\n",
       "      <th>Stated Confidence D</th>\n",
       "      <th>Stated Confidence E</th>\n",
       "      <th>Token Probability True</th>\n",
       "      <th>Token Probability False</th>\n",
       "      <th>Token Probability Answer</th>\n",
       "      <th>Token Probability A</th>\n",
       "      <th>Token Probability B</th>\n",
       "      <th>Token Probability C</th>\n",
       "      <th>Token Probability D</th>\n",
       "      <th>Token Probability E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7219</th>\n",
       "      <td>B cells are a type of lymphocyte (white blood ...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>{\\n\"Reasoning\": \"B cells are a type of lymphoc...</td>\n",
       "      <td>705</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>Claude</td>\n",
       "      <td>SciQ</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14733</th>\n",
       "      <td>B cells are a type of lymphocyte, which are pr...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n\"Reasoning\": \"B cells are a type of lymphoc...</td>\n",
       "      <td>705</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>Claude</td>\n",
       "      <td>SciQ</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22247</th>\n",
       "      <td>B cells are a type of white blood cell that ar...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n\"Reasoning\": \"B cells are a type of white b...</td>\n",
       "      <td>705</td>\n",
       "      <td>claude-sonnet-4-20250514</td>\n",
       "      <td>Claude</td>\n",
       "      <td>SciQ</td>\n",
       "      <td>0.60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29786</th>\n",
       "      <td>B cells are lymphocytes produced in bone marro...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>**Reasoning:** B cells are a type of lymphocyt...</td>\n",
       "      <td>705</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>Deepseek</td>\n",
       "      <td>SciQ</td>\n",
       "      <td>0.60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37275</th>\n",
       "      <td>B cells are a type of lymphocyte, which are pr...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>```json\\n{\\n\"Reasoning\": \"B cells are a type o...</td>\n",
       "      <td>705</td>\n",
       "      <td>deepseek-v3</td>\n",
       "      <td>Deepseek</td>\n",
       "      <td>SciQ</td>\n",
       "      <td>0.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44789</th>\n",
       "      <td>B cells are primarily produced in the bone mar...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>```json\\n{\\n\"Reasoning\": \"B cells are primaril...</td>\n",
       "      <td>705</td>\n",
       "      <td>gemini-2.5-flash</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>SciQ</td>\n",
       "      <td>0.70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52303</th>\n",
       "      <td>The correct production site for B cells is the...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>```json\\n{\\n\"Reasoning\": \"The correct producti...</td>\n",
       "      <td>705</td>\n",
       "      <td>gemini-2.5-pro</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>SciQ</td>\n",
       "      <td>0.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59817</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n\"Reasoning\": \"B cells are a type of lymphoc...</td>\n",
       "      <td>705</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>GPT</td>\n",
       "      <td>SciQ</td>\n",
       "      <td>0.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.172440e-10</td>\n",
       "      <td>2.594609e-11</td>\n",
       "      <td>8.592167e-10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67321</th>\n",
       "      <td>B-cells develop in the bone marrow, but among ...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n\"Reasoning\": \"B-cells develop in the bone m...</td>\n",
       "      <td>705</td>\n",
       "      <td>o3-2025-04-16</td>\n",
       "      <td>GPT</td>\n",
       "      <td>SciQ</td>\n",
       "      <td>0.55</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74835</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n\"Reasoning\": \"B cells, also known as B lymp...</td>\n",
       "      <td>705</td>\n",
       "      <td>Meta-Llama-3.1-70B-Instruct</td>\n",
       "      <td>Llama</td>\n",
       "      <td>SciQ</td>\n",
       "      <td>0.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>2.932392e-05</td>\n",
       "      <td>7.390583e-06</td>\n",
       "      <td>1.621160e-05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82346</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n\"Reasoning\": \"B cells, also known as B lymp...</td>\n",
       "      <td>705</td>\n",
       "      <td>Meta-Llama-3.1-8B-Instruct</td>\n",
       "      <td>Llama</td>\n",
       "      <td>SciQ</td>\n",
       "      <td>0.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996632</td>\n",
       "      <td>3.212211e-03</td>\n",
       "      <td>1.057060e-04</td>\n",
       "      <td>4.982863e-05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Reasoning Answer  \\\n",
       "7219   B cells are a type of lymphocyte (white blood ...      A   \n",
       "14733  B cells are a type of lymphocyte, which are pr...      A   \n",
       "22247  B cells are a type of white blood cell that ar...      A   \n",
       "29786  B cells are lymphocytes produced in bone marro...      A   \n",
       "37275  B cells are a type of lymphocyte, which are pr...      A   \n",
       "44789  B cells are primarily produced in the bone mar...      A   \n",
       "52303  The correct production site for B cells is the...      A   \n",
       "59817                                                NaN      A   \n",
       "67321  B-cells develop in the bone marrow, but among ...      A   \n",
       "74835                                                NaN      A   \n",
       "82346                                                NaN      A   \n",
       "\n",
       "      Stated Confidence Answer  Coerce  \\\n",
       "7219                       NaN   False   \n",
       "14733                      NaN    True   \n",
       "22247                      NaN    True   \n",
       "29786                      NaN    True   \n",
       "37275                      NaN    True   \n",
       "44789                      NaN    True   \n",
       "52303                      NaN    True   \n",
       "59817                      NaN    True   \n",
       "67321                      NaN    True   \n",
       "74835                      NaN    True   \n",
       "82346                      NaN    True   \n",
       "\n",
       "                                                 Content Question ID  \\\n",
       "7219   {\\n\"Reasoning\": \"B cells are a type of lymphoc...         705   \n",
       "14733  {\\n\"Reasoning\": \"B cells are a type of lymphoc...         705   \n",
       "22247  {\\n\"Reasoning\": \"B cells are a type of white b...         705   \n",
       "29786  **Reasoning:** B cells are a type of lymphocyt...         705   \n",
       "37275  ```json\\n{\\n\"Reasoning\": \"B cells are a type o...         705   \n",
       "44789  ```json\\n{\\n\"Reasoning\": \"B cells are primaril...         705   \n",
       "52303  ```json\\n{\\n\"Reasoning\": \"The correct producti...         705   \n",
       "59817  {\\n\"Reasoning\": \"B cells are a type of lymphoc...         705   \n",
       "67321  {\\n\"Reasoning\": \"B-cells develop in the bone m...         705   \n",
       "74835  {\\n\"Reasoning\": \"B cells, also known as B lymp...         705   \n",
       "82346  {\\n\"Reasoning\": \"B cells, also known as B lymp...         705   \n",
       "\n",
       "                             Model Model Type Question Set  \\\n",
       "7219    claude-3-7-sonnet-20250219     Claude         SciQ   \n",
       "14733      claude-3-haiku-20240307     Claude         SciQ   \n",
       "22247     claude-sonnet-4-20250514     Claude         SciQ   \n",
       "29786                  deepseek-r1   Deepseek         SciQ   \n",
       "37275                  deepseek-v3   Deepseek         SciQ   \n",
       "44789             gemini-2.5-flash     Gemini         SciQ   \n",
       "52303               gemini-2.5-pro     Gemini         SciQ   \n",
       "59817                       gpt-4o        GPT         SciQ   \n",
       "67321                o3-2025-04-16        GPT         SciQ   \n",
       "74835  Meta-Llama-3.1-70B-Instruct      Llama         SciQ   \n",
       "82346   Meta-Llama-3.1-8B-Instruct      Llama         SciQ   \n",
       "\n",
       "       Stated Confidence A  ...  Stated Confidence D  Stated Confidence E  \\\n",
       "7219                  0.00  ...                 0.00                  NaN   \n",
       "14733                 1.00  ...                 0.00                  NaN   \n",
       "22247                 0.60  ...                 0.20                  NaN   \n",
       "29786                 0.60  ...                 0.20                  NaN   \n",
       "37275                 0.80  ...                 0.10                  NaN   \n",
       "44789                 0.70  ...                 0.10                  NaN   \n",
       "52303                 0.85  ...                 0.05                  NaN   \n",
       "59817                 0.80  ...                 0.10                  NaN   \n",
       "67321                 0.55  ...                 0.25                  NaN   \n",
       "74835                 0.80  ...                 0.05                  NaN   \n",
       "82346                 0.80  ...                 0.20                  NaN   \n",
       "\n",
       "       Token Probability True  Token Probability False  \\\n",
       "7219                      NaN                      NaN   \n",
       "14733                     NaN                      NaN   \n",
       "22247                     NaN                      NaN   \n",
       "29786                     NaN                      NaN   \n",
       "37275                     NaN                      NaN   \n",
       "44789                     NaN                      NaN   \n",
       "52303                     NaN                      NaN   \n",
       "59817                     NaN                      NaN   \n",
       "67321                     NaN                      NaN   \n",
       "74835                     NaN                      NaN   \n",
       "82346                     NaN                      NaN   \n",
       "\n",
       "       Token Probability Answer  Token Probability A  Token Probability B  \\\n",
       "7219                        NaN                  NaN                  NaN   \n",
       "14733                       NaN                  NaN                  NaN   \n",
       "22247                       NaN                  NaN                  NaN   \n",
       "29786                       NaN                  NaN                  NaN   \n",
       "37275                       NaN                  NaN                  NaN   \n",
       "44789                       NaN                  NaN                  NaN   \n",
       "52303                       NaN                  NaN                  NaN   \n",
       "59817                       NaN             1.000000         2.172440e-10   \n",
       "67321                       NaN                  NaN                  NaN   \n",
       "74835                       NaN             0.999947         2.932392e-05   \n",
       "82346                       NaN             0.996632         3.212211e-03   \n",
       "\n",
       "       Token Probability C  Token Probability D  Token Probability E  \n",
       "7219                   NaN                  NaN                  NaN  \n",
       "14733                  NaN                  NaN                  NaN  \n",
       "22247                  NaN                  NaN                  NaN  \n",
       "29786                  NaN                  NaN                  NaN  \n",
       "37275                  NaN                  NaN                  NaN  \n",
       "44789                  NaN                  NaN                  NaN  \n",
       "52303                  NaN                  NaN                  NaN  \n",
       "59817         2.594609e-11         8.592167e-10                  NaN  \n",
       "67321                  NaN                  NaN                  NaN  \n",
       "74835         7.390583e-06         1.621160e-05                  NaN  \n",
       "82346         1.057060e-04         4.982863e-05                  NaN  \n",
       "\n",
       "[11 rows x 22 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deleted[deleted['Question ID'] == '705']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b45d3d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\l'\n",
      "C:\\Users\\Noam Michael\\AppData\\Local\\Temp\\ipykernel_5888\\158929577.py:3: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  jb_df = pd.read_csv(\"Combined Results\\llm-confidence-correct.csv\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['13', '295', '40', '699', '705'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Jacob's file:\n",
    "\n",
    "jb_df = pd.read_csv(\"Combined Results\\llm-confidence-correct.csv\")\n",
    "jb_df.shape, combined_clean.shape\n",
    "\n",
    "jb_qid = jb_df[jb_df[\"qset\"] == \"sciq_test\"][\"question_id\"].unique()\n",
    "my_qid = combined_clean[combined_clean[\"Question Set\"] == \"SciQ\"][\"Question ID\"].unique()\n",
    "\n",
    "# elements not in the intersection (i.e., in exactly one array)\n",
    "not_in_intersection = np.setxor1d(jb_qid, my_qid)\n",
    "\n",
    "# if you also want side-specific lists:\n",
    "only_in_jb = np.setdiff1d(jb_qid, my_qid)\n",
    "only_in_me = np.setdiff1d(my_qid, jb_qid)\n",
    "\n",
    "only_in_jb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecd9798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Question Set</th>\n",
       "      <th>BoolQ</th>\n",
       "      <th>HaluEval</th>\n",
       "      <th>LSAT-AR</th>\n",
       "      <th>LifeEval</th>\n",
       "      <th>SAT-EN</th>\n",
       "      <th>SciQ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3.1-70B-Instruct</th>\n",
       "      <td>3241</td>\n",
       "      <td>1960</td>\n",
       "      <td>208</td>\n",
       "      <td>807</td>\n",
       "      <td>202</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3.1-8B-Instruct</th>\n",
       "      <td>3200</td>\n",
       "      <td>1997</td>\n",
       "      <td>190</td>\n",
       "      <td>800</td>\n",
       "      <td>202</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-7-sonnet-20250219</th>\n",
       "      <td>3267</td>\n",
       "      <td>2000</td>\n",
       "      <td>228</td>\n",
       "      <td>808</td>\n",
       "      <td>206</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-haiku-20240307</th>\n",
       "      <td>3036</td>\n",
       "      <td>1855</td>\n",
       "      <td>230</td>\n",
       "      <td>808</td>\n",
       "      <td>181</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-sonnet-4-20250514</th>\n",
       "      <td>3258</td>\n",
       "      <td>2000</td>\n",
       "      <td>188</td>\n",
       "      <td>808</td>\n",
       "      <td>205</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek-r1</th>\n",
       "      <td>3214</td>\n",
       "      <td>2000</td>\n",
       "      <td>228</td>\n",
       "      <td>808</td>\n",
       "      <td>206</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek-v3</th>\n",
       "      <td>2898</td>\n",
       "      <td>2000</td>\n",
       "      <td>228</td>\n",
       "      <td>808</td>\n",
       "      <td>204</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2.5-flash</th>\n",
       "      <td>3261</td>\n",
       "      <td>2000</td>\n",
       "      <td>177</td>\n",
       "      <td>808</td>\n",
       "      <td>206</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2.5-pro</th>\n",
       "      <td>3190</td>\n",
       "      <td>1984</td>\n",
       "      <td>188</td>\n",
       "      <td>808</td>\n",
       "      <td>204</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <td>3247</td>\n",
       "      <td>2000</td>\n",
       "      <td>230</td>\n",
       "      <td>808</td>\n",
       "      <td>206</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o3-2025-04-16</th>\n",
       "      <td>3070</td>\n",
       "      <td>1991</td>\n",
       "      <td>193</td>\n",
       "      <td>761</td>\n",
       "      <td>205</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Question Set                 BoolQ  HaluEval  LSAT-AR  LifeEval  SAT-EN  SciQ\n",
       "Model                                                                        \n",
       "Meta-Llama-3.1-70B-Instruct   3241      1960      208       807     202  1000\n",
       "Meta-Llama-3.1-8B-Instruct    3200      1997      190       800     202   997\n",
       "claude-3-7-sonnet-20250219    3267      2000      228       808     206   999\n",
       "claude-3-haiku-20240307       3036      1855      230       808     181   999\n",
       "claude-sonnet-4-20250514      3258      2000      188       808     205  1000\n",
       "deepseek-r1                   3214      2000      228       808     206  1000\n",
       "deepseek-v3                   2898      2000      228       808     204  1000\n",
       "gemini-2.5-flash              3261      2000      177       808     206  1000\n",
       "gemini-2.5-pro                3190      1984      188       808     204  1000\n",
       "gpt-4o                        3247      2000      230       808     206  1000\n",
       "o3-2025-04-16                 3070      1991      193       761     205  1000"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df[combined_df[\"Coerce\"] == True].pivot_table(index=\"Model\", columns=\"Question Set\",\n",
    "                        aggfunc=\"size\", fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dca270a",
   "metadata": {},
   "source": [
    "### Additional EDA:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112eca0e",
   "metadata": {},
   "source": [
    "Don was curious about some missing fields. For BoolQ we can see that all models have 2503 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4854d335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model\n",
       "claude-3-7-sonnet-20250219     2503\n",
       "claude-3-haiku-20240307        2503\n",
       "claude-sonnet-4-20250514       2503\n",
       "deepseek-r1                    2503\n",
       "deepseek-v3                    2503\n",
       "gemini-2.5-flash               2503\n",
       "gemini-2.5-pro                 2503\n",
       "gpt-4o                         2503\n",
       "o3-2025-04-16                  2503\n",
       "Meta-Llama-3.1-70B-Instruct    2503\n",
       "Meta-Llama-3.1-8B-Instruct     2503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_clean[(combined_clean[\"Question Set\"] == \"BoolQ\")][\"Model\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a241c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reasoning</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Stated Confidence Answer</th>\n",
       "      <th>Coerce</th>\n",
       "      <th>Content</th>\n",
       "      <th>Question ID</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Question Set</th>\n",
       "      <th>Stated Confidence A</th>\n",
       "      <th>...</th>\n",
       "      <th>Stated Confidence E</th>\n",
       "      <th>Token Probability True</th>\n",
       "      <th>Token Probability False</th>\n",
       "      <th>Token Probability Answer</th>\n",
       "      <th>Token Probability A</th>\n",
       "      <th>Token Probability B</th>\n",
       "      <th>Token Probability C</th>\n",
       "      <th>Token Probability D</th>\n",
       "      <th>Token Probability E</th>\n",
       "      <th>combined_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37570</th>\n",
       "      <td>The television series 'The Tudors' aired on Sh...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>```json\\n{\\n    \"Reasoning\": \"The television s...</td>\n",
       "      <td>3000</td>\n",
       "      <td>gemini-2.5-flash</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000_BoolQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37571</th>\n",
       "      <td>The question asks if the character Marley dies...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>```json\\n{\\n    \"Reasoning\": \"The question ask...</td>\n",
       "      <td>3001</td>\n",
       "      <td>gemini-2.5-flash</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3001_BoolQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37572</th>\n",
       "      <td>Canada is a prominent country with a well-deve...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>```json\\n{\\n    \"Reasoning\": \"Canada is a prom...</td>\n",
       "      <td>3002</td>\n",
       "      <td>gemini-2.5-flash</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3002_BoolQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37574</th>\n",
       "      <td>The term 'Pit Bull' commonly refers to a type ...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>```json\\n{\\n    \"Reasoning\": \"The term 'Pit Bu...</td>\n",
       "      <td>3004</td>\n",
       "      <td>gemini-2.5-flash</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3004_BoolQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37575</th>\n",
       "      <td>A 'postal code' is a general term used interna...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Response: {\\n    \"Reasoning\": \"A 'postal code'...</td>\n",
       "      <td>3005</td>\n",
       "      <td>gemini-2.5-flash</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3005_BoolQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Reasoning Answer  \\\n",
       "37570  The television series 'The Tudors' aired on Sh...  False   \n",
       "37571  The question asks if the character Marley dies...   True   \n",
       "37572  Canada is a prominent country with a well-deve...   True   \n",
       "37574  The term 'Pit Bull' commonly refers to a type ...  False   \n",
       "37575  A 'postal code' is a general term used interna...  False   \n",
       "\n",
       "      Stated Confidence Answer  Coerce  \\\n",
       "37570                      1.0    True   \n",
       "37571                      1.0    True   \n",
       "37572                      1.0    True   \n",
       "37574                      1.0    True   \n",
       "37575                      1.0    True   \n",
       "\n",
       "                                                 Content Question ID  \\\n",
       "37570  ```json\\n{\\n    \"Reasoning\": \"The television s...        3000   \n",
       "37571  ```json\\n{\\n    \"Reasoning\": \"The question ask...        3001   \n",
       "37572  ```json\\n{\\n    \"Reasoning\": \"Canada is a prom...        3002   \n",
       "37574  ```json\\n{\\n    \"Reasoning\": \"The term 'Pit Bu...        3004   \n",
       "37575  Response: {\\n    \"Reasoning\": \"A 'postal code'...        3005   \n",
       "\n",
       "                  Model Model Type Question Set  Stated Confidence A  ...  \\\n",
       "37570  gemini-2.5-flash     Gemini        BoolQ                  NaN  ...   \n",
       "37571  gemini-2.5-flash     Gemini        BoolQ                  NaN  ...   \n",
       "37572  gemini-2.5-flash     Gemini        BoolQ                  NaN  ...   \n",
       "37574  gemini-2.5-flash     Gemini        BoolQ                  NaN  ...   \n",
       "37575  gemini-2.5-flash     Gemini        BoolQ                  NaN  ...   \n",
       "\n",
       "       Stated Confidence E  Token Probability True  Token Probability False  \\\n",
       "37570                  NaN                     NaN                      NaN   \n",
       "37571                  NaN                     NaN                      NaN   \n",
       "37572                  NaN                     NaN                      NaN   \n",
       "37574                  NaN                     NaN                      NaN   \n",
       "37575                  NaN                     NaN                      NaN   \n",
       "\n",
       "       Token Probability Answer  Token Probability A  Token Probability B  \\\n",
       "37570                       NaN                  NaN                  NaN   \n",
       "37571                       NaN                  NaN                  NaN   \n",
       "37572                       NaN                  NaN                  NaN   \n",
       "37574                       NaN                  NaN                  NaN   \n",
       "37575                       NaN                  NaN                  NaN   \n",
       "\n",
       "       Token Probability C  Token Probability D  Token Probability E  \\\n",
       "37570                  NaN                  NaN                  NaN   \n",
       "37571                  NaN                  NaN                  NaN   \n",
       "37572                  NaN                  NaN                  NaN   \n",
       "37574                  NaN                  NaN                  NaN   \n",
       "37575                  NaN                  NaN                  NaN   \n",
       "\n",
       "       combined_name  \n",
       "37570     3000_BoolQ  \n",
       "37571     3001_BoolQ  \n",
       "37572     3002_BoolQ  \n",
       "37574     3004_BoolQ  \n",
       "37575     3005_BoolQ  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_clean[(combined_clean[\"Question Set\"] == \"BoolQ\") & (combined_clean[\"Model Type\"] == \"Gemini\")].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d86feb",
   "metadata": {},
   "source": [
    "## Save both CSVs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8469f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_path   = Path(\"Parsed Results/combined_raw.csv\")\n",
    "clean_path = Path(\"Parsed Results/combined_clean.csv\")\n",
    "\n",
    "\n",
    "# write\n",
    "combined_df.to_csv(raw_path, index=False, encoding=\"utf-8\")\n",
    "combined_clean.to_csv(clean_path, index=False, encoding=\"utf-8\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
