{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2436248",
   "metadata": {},
   "source": [
    "# Comparing Calibration Data Across All Models / Question Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8736a505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas (from -r requirements.txt (line 1))\n",
      "  Using cached pandas-2.3.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy (from -r requirements.txt (line 2))\n",
      "  Downloading numpy-2.3.4-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting matplotlib (from -r requirements.txt (line 3))\n",
      "  Using cached matplotlib-3.10.7-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting seaborn (from -r requirements.txt (line 4))\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting google (from -r requirements.txt (line 5))\n",
      "  Downloading google-3.0.0-py2.py3-none-any.whl.metadata (627 bytes)\n",
      "Collecting openai (from -r requirements.txt (line 6))\n",
      "  Downloading openai-2.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->-r requirements.txt (line 1))\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->-r requirements.txt (line 1))\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->-r requirements.txt (line 3))\n",
      "  Using cached contourpy-1.3.3-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->-r requirements.txt (line 3))\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->-r requirements.txt (line 3))\n",
      "  Using cached fonttools-4.60.1-cp312-cp312-win_amd64.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->-r requirements.txt (line 3))\n",
      "  Using cached kiwisolver-1.4.9-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib->-r requirements.txt (line 3))\n",
      "  Using cached pillow-12.0.0-cp312-cp312-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib->-r requirements.txt (line 3))\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting beautifulsoup4 (from google->-r requirements.txt (line 5))\n",
      "  Using cached beautifulsoup4-4.14.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai->-r requirements.txt (line 6))\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai->-r requirements.txt (line 6))\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai->-r requirements.txt (line 6))\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.10.0 (from openai->-r requirements.txt (line 6))\n",
      "  Downloading jiter-0.11.1-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai->-r requirements.txt (line 6))\n",
      "  Downloading pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)\n",
      "Collecting sniffio (from openai->-r requirements.txt (line 6))\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai->-r requirements.txt (line 6))\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions<5,>=4.11 (from openai->-r requirements.txt (line 6))\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 6))\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 6))\n",
      "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 6))\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 6))\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 6))\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.4 (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 6))\n",
      "  Downloading pydantic_core-2.41.4-cp312-cp312-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 6))\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\noam michael\\desktop\\comparing-confidence-in-llms\\.venv\\lib\\site-packages (from tqdm>4->openai->-r requirements.txt (line 6)) (0.4.6)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->google->-r requirements.txt (line 5))\n",
      "  Using cached soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Using cached pandas-2.3.3-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "Downloading numpy-2.3.4-cp312-cp312-win_amd64.whl (12.8 MB)\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 2.1/12.8 MB 10.7 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.2/12.8 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 5.2/12.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 6.0/12.8 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.1/12.8 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.9/12.8 MB 6.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.7/12.8 MB 5.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.4/12.8 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.0/12.8 MB 5.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.5/12.8 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.0/12.8 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.5/12.8 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.1/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.8/12.8 MB 4.1 MB/s eta 0:00:00\n",
      "Using cached matplotlib-3.10.7-cp312-cp312-win_amd64.whl (8.1 MB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading google-3.0.0-py2.py3-none-any.whl (45 kB)\n",
      "Downloading openai-2.5.0-py3-none-any.whl (999 kB)\n",
      "   ---------------------------------------- 0.0/999.9 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 524.3/999.9 kB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 999.9/999.9 kB 2.8 MB/s eta 0:00:00\n",
      "Using cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Using cached contourpy-1.3.3-cp312-cp312-win_amd64.whl (226 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached fonttools-4.60.1-cp312-cp312-win_amd64.whl (2.3 MB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.11.1-cp312-cp312-win_amd64.whl (204 kB)\n",
      "Using cached kiwisolver-1.4.9-cp312-cp312-win_amd64.whl (73 kB)\n",
      "Using cached pillow-12.0.0-cp312-cp312-win_amd64.whl (7.0 MB)\n",
      "Downloading pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
      "Downloading pydantic_core-2.41.4-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.0/2.0 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.6/2.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 2.8 MB/s eta 0:00:00\n",
      "Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached beautifulsoup4-4.14.2-py3-none-any.whl (106 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached soupsieve-2.8-py3-none-any.whl (36 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: pytz, tzdata, typing-extensions, tqdm, soupsieve, sniffio, pyparsing, pillow, numpy, kiwisolver, jiter, idna, h11, fonttools, distro, cycler, certifi, annotated-types, typing-inspection, pydantic-core, pandas, httpcore, contourpy, beautifulsoup4, anyio, pydantic, matplotlib, httpx, google, seaborn, openai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.11.0 beautifulsoup4-4.14.2 certifi-2025.10.5 contourpy-1.3.3 cycler-0.12.1 distro-1.9.0 fonttools-4.60.1 google-3.0.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.11 jiter-0.11.1 kiwisolver-1.4.9 matplotlib-3.10.7 numpy-2.3.4 openai-2.5.0 pandas-2.3.3 pillow-12.0.0 pydantic-2.12.3 pydantic-core-2.41.4 pyparsing-3.2.5 pytz-2025.2 seaborn-0.13.2 sniffio-1.3.1 soupsieve-2.8 tqdm-4.67.1 typing-extensions-4.15.0 typing-inspection-0.4.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9704e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2f7b78",
   "metadata": {},
   "source": [
    "## Combine All Results Into Composite CSV\n",
    "\n",
    "First we will read from the Parsed Results folder and make a dictionary that abstracts the structure of the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "009288cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Claude', 'Deepseek', 'Gemini', 'GPT', 'Llama'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the folder and create a dictionary to model the structure of the files\n",
    "\n",
    "def folder_tree_dict(root, *, include_files=True, follow_symlinks=False, ignore_hidden=True):\n",
    "    root = Path(root)\n",
    "\n",
    "    def build(p: Path):\n",
    "        out = {}\n",
    "        for entry in sorted(p.iterdir(), key=lambda x: (x.is_file(), x.name.lower())):\n",
    "            if ignore_hidden and entry.name.startswith(\".\"):\n",
    "                continue\n",
    "            try:\n",
    "                if entry.is_dir() and (follow_symlinks or not entry.is_symlink()):\n",
    "                    out[entry.name] = build(entry)\n",
    "                else:\n",
    "                    if include_files:\n",
    "                        out[entry.name] = None  # or {\"size\": entry.stat().st_size}\n",
    "            except PermissionError:\n",
    "                out[entry.name] = \"<permission-denied>\"\n",
    "        return out\n",
    "\n",
    "    return {root.name: build(root)}\n",
    "\n",
    "\n",
    "folder_path = r\"Parsed Results\"\n",
    "\n",
    "folder_abstraction_dict = folder_tree_dict(folder_path)[folder_path]\n",
    "\n",
    "folder_abstraction_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081f850c",
   "metadata": {},
   "source": [
    "### Combined CSV\n",
    "We want to make a well-formed CSV for future analysis. This CSV will have the following fields for columns:\n",
    "\n",
    "```text\n",
    "Question Set (str) ---------------- Required: The display name of the question set\n",
    "Question ID (str) ----------------- Required: The Question ID\n",
    "Model (str) ----------------------- Required: The model that provided the response (e.g. Llama-3.1-8B-Instruct)\n",
    "Model Type (str) ------------------ Required: The family of models which  the model (e.g. Llama)\n",
    "Coerce (Bool) --------------------- Required: Whether the parser was able to understand the response\n",
    "\n",
    "Question (str) -------------------- Required: The question posed to the model\n",
    "Correct Answer (str) -------------- Optional: Depends on Question Set (LifeEval is different than others)\n",
    "Content (str) --------------------- Optional: Depends on Coerce value (NA if Coerce == False)\n",
    "Reasoning (str) ------------------- Optional: Depends on Coerce value (NA if Coerce == False)\n",
    "Answer (str) ---------------------- Optional: Depends on Coerce value (NA if Coerce == False)\n",
    "Score (float) --------------------- Optional: Depends on Coerce value (NA if Coerce == False)\n",
    "\n",
    "Stated Confidence Answer (float) -- Optional: Depends on Question Set (NA if not available)\n",
    "Stated Confidence A (float) ------- Optional: Depends on Question Set (NA if not available)\n",
    "Stated Confidence B (float) ------- Optional: Depends on Question Set (NA if not available)\n",
    "Stated Confidence C (float) ------- Optional: Depends on Question Set (NA if not available)\n",
    "Stated Confidence D (float) ------- Optional: Depends on Question Set (NA if not available)\n",
    "Stated Confidence E (float)-------- Optional: Depends on Question Set (NA if not available)\n",
    "\n",
    "Token Probability Answer (float) -- Optional: Depends on Model Type (NA if not available)\n",
    "Token Probability A (float) ------- Optional: Depends on Model Type (NA if not available)\n",
    "Token Probability B (float) ------- Optional: Depends on Model Type (NA if not available)\n",
    "Token Probability C (float) ------- Optional: Depends on Model Type (NA if not available)\n",
    "Token Probability D (float) ------- Optional: Depends on Model Type (NA if not available)\n",
    "Token Probability E (float) ------- Optional: Depends on Model Type (NA if not available)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "1ac22891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed Results/Claude\n",
      "    Parsed Results/Claude/claude-3-7-sonnet-20250219\n",
      "        boolq_valid:    Parsed Results/Claude/claude-3-7-sonnet-20250219/boolq_valid_claude-3-7-sonnet-20250219.csv\n",
      "        halu_eval_qa:    Parsed Results/Claude/claude-3-7-sonnet-20250219/halu_eval_qa_claude-3-7-sonnet-20250219.csv\n",
      "        life_eval:    Parsed Results/Claude/claude-3-7-sonnet-20250219/life_eval_claude-3-7-sonnet-20250219.csv\n",
      "        lsat_ar_test:    Parsed Results/Claude/claude-3-7-sonnet-20250219/lsat_ar_test_claude-3-7-sonnet-20250219.csv\n",
      "        sat_en:    Parsed Results/Claude/claude-3-7-sonnet-20250219/sat_en_claude-3-7-sonnet-20250219.csv\n",
      "        sciq_test:    Parsed Results/Claude/claude-3-7-sonnet-20250219/sciq_test_claude-3-7-sonnet-20250219.csv\n",
      "    Parsed Results/Claude/claude-3-haiku-20240307\n",
      "        boolq_valid:    Parsed Results/Claude/claude-3-haiku-20240307/boolq_valid_claude-3-haiku-20240307.csv\n",
      "        halu_eval_qa:    Parsed Results/Claude/claude-3-haiku-20240307/halu_eval_qa_claude-3-haiku-20240307.csv\n",
      "        life_eval:    Parsed Results/Claude/claude-3-haiku-20240307/life_eval_claude-3-haiku-20240307.csv\n",
      "        lsat_ar_test:    Parsed Results/Claude/claude-3-haiku-20240307/lsat_ar_test_claude-3-haiku-20240307.csv\n",
      "        sat_en:    Parsed Results/Claude/claude-3-haiku-20240307/sat_en_claude-3-haiku-20240307.csv\n",
      "        sciq_test:    Parsed Results/Claude/claude-3-haiku-20240307/sciq_test_claude-3-haiku-20240307.csv\n",
      "    Parsed Results/Claude/claude-sonnet-4-20250514\n",
      "        boolq_valid:    Parsed Results/Claude/claude-sonnet-4-20250514/boolq_valid_claude-sonnet-4-20250514.csv\n",
      "        halu_eval_qa:    Parsed Results/Claude/claude-sonnet-4-20250514/halu_eval_qa_claude-sonnet-4-20250514.csv\n",
      "        life_eval:    Parsed Results/Claude/claude-sonnet-4-20250514/life_eval_claude-sonnet-4-20250514.csv\n",
      "        lsat_ar_test:    Parsed Results/Claude/claude-sonnet-4-20250514/lsat_ar_test_claude-sonnet-4-20250514.csv\n",
      "        sat_en:    Parsed Results/Claude/claude-sonnet-4-20250514/sat_en_claude-sonnet-4-20250514.csv\n",
      "        sciq_test:    Parsed Results/Claude/claude-sonnet-4-20250514/sciq_test_claude-sonnet-4-20250514.csv\n",
      "Parsed Results/Deepseek\n",
      "    Parsed Results/Deepseek/deepseek-r1\n",
      "        boolq_valid:    Parsed Results/Deepseek/deepseek-r1/boolq_valid_deepseek-r1.csv\n",
      "        halu_eval_qa:    Parsed Results/Deepseek/deepseek-r1/halu_eval_qa_deepseek-r1.csv\n",
      "        life_eval:    Parsed Results/Deepseek/deepseek-r1/life_eval_deepseek-r1.csv\n",
      "        lsat_ar_test:    Parsed Results/Deepseek/deepseek-r1/lsat_ar_test_deepseek-r1.csv\n",
      "        sat_en:    Parsed Results/Deepseek/deepseek-r1/sat_en_deepseek-r1.csv\n",
      "        sciq_test:    Parsed Results/Deepseek/deepseek-r1/sciq_test_deepseek-r1.csv\n",
      "    Parsed Results/Deepseek/deepseek-v3\n",
      "        boolq_valid:    Parsed Results/Deepseek/deepseek-v3/boolq_valid_deepseek-v3.csv\n",
      "        halu_eval_qa:    Parsed Results/Deepseek/deepseek-v3/halu_eval_qa_deepseek-v3.csv\n",
      "        life_eval:    Parsed Results/Deepseek/deepseek-v3/life_eval_deepseek-v3.csv\n",
      "        lsat_ar_test:    Parsed Results/Deepseek/deepseek-v3/lsat_ar_test_deepseek-v3.csv\n",
      "        sat_en:    Parsed Results/Deepseek/deepseek-v3/sat_en_deepseek-v3.csv\n",
      "        sciq_test:    Parsed Results/Deepseek/deepseek-v3/sciq_test_deepseek-v3.csv\n",
      "Parsed Results/Gemini\n",
      "    Parsed Results/Gemini/gemini-2.5-flash\n",
      "        boolq_valid:    Parsed Results/Gemini/gemini-2.5-flash/boolq_valid_gemini-2.5-flash.csv\n",
      "        halu_eval_qa:    Parsed Results/Gemini/gemini-2.5-flash/halu_eval_qa_gemini-2.5-flash.csv\n",
      "        life_eval:    Parsed Results/Gemini/gemini-2.5-flash/life_eval_gemini-2.5-flash.csv\n",
      "        lsat_ar_test:    Parsed Results/Gemini/gemini-2.5-flash/lsat_ar_test_gemini-2.5-flash.csv\n",
      "        sat_en:    Parsed Results/Gemini/gemini-2.5-flash/sat_en_gemini-2.5-flash.csv\n",
      "        sciq_test:    Parsed Results/Gemini/gemini-2.5-flash/sciq_test_gemini-2.5-flash.csv\n",
      "    Parsed Results/Gemini/gemini-2.5-pro\n",
      "        boolq_valid:    Parsed Results/Gemini/gemini-2.5-pro/boolq_valid_gemini-2.5-pro.csv\n",
      "        halu_eval_qa:    Parsed Results/Gemini/gemini-2.5-pro/halu_eval_qa_gemini-2.5-pro.csv\n",
      "        life_eval:    Parsed Results/Gemini/gemini-2.5-pro/life_eval_gemini-2.5-pro.csv\n",
      "        lsat_ar_test:    Parsed Results/Gemini/gemini-2.5-pro/lsat_ar_test_gemini-2.5-pro.csv\n",
      "        sat_en:    Parsed Results/Gemini/gemini-2.5-pro/sat_en_gemini-2.5-pro.csv\n",
      "        sciq_test:    Parsed Results/Gemini/gemini-2.5-pro/sciq_test_gemini-2.5-pro.csv\n",
      "Parsed Results/GPT\n",
      "    Parsed Results/GPT/gpt-4o\n",
      "        boolq_valid:    Parsed Results/GPT/gpt-4o/boolq_valid_gpt-4o.csv\n",
      "        halu_eval_qa:    Parsed Results/GPT/gpt-4o/halu_eval_qa_gpt-4o.csv\n",
      "        life_eval:    Parsed Results/GPT/gpt-4o/life_eval_gpt-4o.csv\n",
      "        lsat_ar_test:    Parsed Results/GPT/gpt-4o/lsat_ar_test_gpt-4o.csv\n",
      "        sat_en:    Parsed Results/GPT/gpt-4o/sat_en_gpt-4o.csv\n",
      "        sciq_test:    Parsed Results/GPT/gpt-4o/sciq_test_gpt-4o.csv\n",
      "    Parsed Results/GPT/o3-2025-04-16\n",
      "        boolq_valid:    Parsed Results/GPT/o3-2025-04-16/boolq_valid_o3-2025-04-16.csv\n",
      "        halu_eval_qa:    Parsed Results/GPT/o3-2025-04-16/halu_eval_qa_o3-2025-04-16.csv\n",
      "        life_eval:    Parsed Results/GPT/o3-2025-04-16/life_eval_o3-2025-04-16.csv\n",
      "        lsat_ar_test:    Parsed Results/GPT/o3-2025-04-16/lsat_ar_test_o3-2025-04-16.csv\n",
      "        sat_en:    Parsed Results/GPT/o3-2025-04-16/sat_en_o3-2025-04-16.csv\n",
      "        sciq_test:    Parsed Results/GPT/o3-2025-04-16/sciq_test_o3-2025-04-16.csv\n",
      "Parsed Results/Llama\n",
      "    Parsed Results/Llama/Meta-Llama-3.1-70B-Instruct\n",
      "        boolq_valid:    Parsed Results/Llama/Meta-Llama-3.1-70B-Instruct/boolq_valid_Meta-Llama-3.1-70B-Instruct.csv\n",
      "        halu_eval_qa:    Parsed Results/Llama/Meta-Llama-3.1-70B-Instruct/halu_eval_qa_Meta-Llama-3.1-70B-Instruct.csv\n",
      "        life_eval:    Parsed Results/Llama/Meta-Llama-3.1-70B-Instruct/life_eval_Meta-Llama-3.1-70B-Instruct.csv\n",
      "        lsat_ar_test:    Parsed Results/Llama/Meta-Llama-3.1-70B-Instruct/lsat_ar_test_Meta-Llama-3.1-70B-Instruct.csv\n",
      "        sat_en:    Parsed Results/Llama/Meta-Llama-3.1-70B-Instruct/sat_en_Meta-Llama-3.1-70B-Instruct.csv\n",
      "        sciq_test:    Parsed Results/Llama/Meta-Llama-3.1-70B-Instruct/sciq_test_Meta-Llama-3.1-70B-Instruct.csv\n",
      "    Parsed Results/Llama/Meta-Llama-3.1-8B-Instruct\n",
      "        boolq_valid:    Parsed Results/Llama/Meta-Llama-3.1-8B-Instruct/boolq_valid_Meta-Llama-3.1-8B-Instruct.csv\n",
      "        halu_eval_qa:    Parsed Results/Llama/Meta-Llama-3.1-8B-Instruct/halu_eval_qa_Meta-Llama-3.1-8B-Instruct.csv\n",
      "        life_eval:    Parsed Results/Llama/Meta-Llama-3.1-8B-Instruct/life_eval_Meta-Llama-3.1-8B-Instruct.csv\n",
      "        lsat_ar_test:    Parsed Results/Llama/Meta-Llama-3.1-8B-Instruct/lsat_ar_test_Meta-Llama-3.1-8B-Instruct.csv\n",
      "        sat_en:    Parsed Results/Llama/Meta-Llama-3.1-8B-Instruct/sat_en_Meta-Llama-3.1-8B-Instruct.csv\n",
      "        sciq_test:    Parsed Results/Llama/Meta-Llama-3.1-8B-Instruct/sciq_test_Meta-Llama-3.1-8B-Instruct.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reasoning</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Stated Confidence Answer</th>\n",
       "      <th>Coerce</th>\n",
       "      <th>Content</th>\n",
       "      <th>Question ID</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Question Set</th>\n",
       "      <th>Stated Confidence A</th>\n",
       "      <th>Stated Confidence B</th>\n",
       "      <th>Stated Confidence C</th>\n",
       "      <th>Stated Confidence D</th>\n",
       "      <th>Stated Confidence E</th>\n",
       "      <th>Token Probability True</th>\n",
       "      <th>Token Probability False</th>\n",
       "      <th>Token Probability Answer</th>\n",
       "      <th>Token Probability A</th>\n",
       "      <th>Token Probability B</th>\n",
       "      <th>Token Probability C</th>\n",
       "      <th>Token Probability D</th>\n",
       "      <th>Token Probability E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The question is asking whether the production ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n    \"Reasoning\": \"The question is asking wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>Claude</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>House tax and property tax are often used inte...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.85</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n    \"Reasoning\": \"House tax and property ta...</td>\n",
       "      <td>1</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>Claude</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This question is asking about phantom limb pai...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.95</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n    \"Reasoning\": \"This question is asking a...</td>\n",
       "      <td>2</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>Claude</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Escape from Gringotts is ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.98</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n    \"Reasoning\": \"Harry Potter and the Esca...</td>\n",
       "      <td>3</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>Claude</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hydroxyzine HCl (hydrochloride) and hydroxyzin...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.98</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n    \"Reasoning\": \"Hydroxyzine HCl (hydrochl...</td>\n",
       "      <td>4</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>Claude</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82636</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n\"Reasoning\": \"Predation is a biological pro...</td>\n",
       "      <td>995</td>\n",
       "      <td>Meta-Llama-3.1-8B-Instruct</td>\n",
       "      <td>Llama</td>\n",
       "      <td>SciQ</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>9.645942e-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82637</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n\"Reasoning\": \"Short period comets are thoug...</td>\n",
       "      <td>996</td>\n",
       "      <td>Meta-Llama-3.1-8B-Instruct</td>\n",
       "      <td>Llama</td>\n",
       "      <td>SciQ</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>2.966547e-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82638</th>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n\"Reasoning\": \"The question is asking about ...</td>\n",
       "      <td>997</td>\n",
       "      <td>Meta-Llama-3.1-8B-Instruct</td>\n",
       "      <td>Llama</td>\n",
       "      <td>SciQ</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>9.997405e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82639</th>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n\"Reasoning\": \"Atoms with unstable nuclei ar...</td>\n",
       "      <td>998</td>\n",
       "      <td>Meta-Llama-3.1-8B-Instruct</td>\n",
       "      <td>Llama</td>\n",
       "      <td>SciQ</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>9.999572e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82640</th>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n\"Reasoning\": \"Atmospheric sulfur is primari...</td>\n",
       "      <td>999</td>\n",
       "      <td>Meta-Llama-3.1-8B-Instruct</td>\n",
       "      <td>Llama</td>\n",
       "      <td>SciQ</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>8.449691e-07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82641 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Reasoning Answer  \\\n",
       "0      The question is asking whether the production ...  False   \n",
       "1      House tax and property tax are often used inte...   True   \n",
       "2      This question is asking about phantom limb pai...   True   \n",
       "3      Harry Potter and the Escape from Gringotts is ...   True   \n",
       "4      Hydroxyzine HCl (hydrochloride) and hydroxyzin...   True   \n",
       "...                                                  ...    ...   \n",
       "82636                                                NaN      A   \n",
       "82637                                                NaN      A   \n",
       "82638                                                NaN      D   \n",
       "82639                                                NaN      D   \n",
       "82640                                                NaN      C   \n",
       "\n",
       "      Stated Confidence Answer  Coerce  \\\n",
       "0                          0.6    True   \n",
       "1                         0.85    True   \n",
       "2                         0.95    True   \n",
       "3                         0.98    True   \n",
       "4                         0.98    True   \n",
       "...                        ...     ...   \n",
       "82636                      NaN    True   \n",
       "82637                      NaN    True   \n",
       "82638                      NaN    True   \n",
       "82639                      NaN    True   \n",
       "82640                      NaN    True   \n",
       "\n",
       "                                                 Content Question ID  \\\n",
       "0      {\\n    \"Reasoning\": \"The question is asking wh...           0   \n",
       "1      {\\n    \"Reasoning\": \"House tax and property ta...           1   \n",
       "2      {\\n    \"Reasoning\": \"This question is asking a...           2   \n",
       "3      {\\n    \"Reasoning\": \"Harry Potter and the Esca...           3   \n",
       "4      {\\n    \"Reasoning\": \"Hydroxyzine HCl (hydrochl...           4   \n",
       "...                                                  ...         ...   \n",
       "82636  {\\n\"Reasoning\": \"Predation is a biological pro...         995   \n",
       "82637  {\\n\"Reasoning\": \"Short period comets are thoug...         996   \n",
       "82638  {\\n\"Reasoning\": \"The question is asking about ...         997   \n",
       "82639  {\\n\"Reasoning\": \"Atoms with unstable nuclei ar...         998   \n",
       "82640  {\\n\"Reasoning\": \"Atmospheric sulfur is primari...         999   \n",
       "\n",
       "                            Model Model Type Question Set  \\\n",
       "0      claude-3-7-sonnet-20250219     Claude        BoolQ   \n",
       "1      claude-3-7-sonnet-20250219     Claude        BoolQ   \n",
       "2      claude-3-7-sonnet-20250219     Claude        BoolQ   \n",
       "3      claude-3-7-sonnet-20250219     Claude        BoolQ   \n",
       "4      claude-3-7-sonnet-20250219     Claude        BoolQ   \n",
       "...                           ...        ...          ...   \n",
       "82636  Meta-Llama-3.1-8B-Instruct      Llama         SciQ   \n",
       "82637  Meta-Llama-3.1-8B-Instruct      Llama         SciQ   \n",
       "82638  Meta-Llama-3.1-8B-Instruct      Llama         SciQ   \n",
       "82639  Meta-Llama-3.1-8B-Instruct      Llama         SciQ   \n",
       "82640  Meta-Llama-3.1-8B-Instruct      Llama         SciQ   \n",
       "\n",
       "       Stated Confidence A  Stated Confidence B  Stated Confidence C  \\\n",
       "0                      NaN                  NaN                  NaN   \n",
       "1                      NaN                  NaN                  NaN   \n",
       "2                      NaN                  NaN                  NaN   \n",
       "3                      NaN                  NaN                  NaN   \n",
       "4                      NaN                  NaN                  NaN   \n",
       "...                    ...                  ...                  ...   \n",
       "82636                 0.95                  0.0                  0.0   \n",
       "82637                 0.95                  0.0                  0.0   \n",
       "82638                 0.00                  0.0                  0.0   \n",
       "82639                 0.00                  0.0                  0.0   \n",
       "82640                 0.00                  0.2                  0.8   \n",
       "\n",
       "       Stated Confidence D  Stated Confidence E  Token Probability True  \\\n",
       "0                      NaN                  NaN                     NaN   \n",
       "1                      NaN                  NaN                     NaN   \n",
       "2                      NaN                  NaN                     NaN   \n",
       "3                      NaN                  NaN                     NaN   \n",
       "4                      NaN                  NaN                     NaN   \n",
       "...                    ...                  ...                     ...   \n",
       "82636                 0.05                  NaN                     NaN   \n",
       "82637                 0.05                  NaN                     NaN   \n",
       "82638                 1.00                  NaN                     NaN   \n",
       "82639                 1.00                  NaN                     NaN   \n",
       "82640                 0.00                  NaN                     NaN   \n",
       "\n",
       "       Token Probability False  Token Probability Answer  Token Probability A  \\\n",
       "0                          NaN                       NaN                  NaN   \n",
       "1                          NaN                       NaN                  NaN   \n",
       "2                          NaN                       NaN                  NaN   \n",
       "3                          NaN                       NaN                  NaN   \n",
       "4                          NaN                       NaN                  NaN   \n",
       "...                        ...                       ...                  ...   \n",
       "82636                      NaN                       NaN             0.999986   \n",
       "82637                      NaN                       NaN             0.999989   \n",
       "82638                      NaN                       NaN             0.000175   \n",
       "82639                      NaN                       NaN             0.000015   \n",
       "82640                      NaN                       NaN             0.000011   \n",
       "\n",
       "       Token Probability B  Token Probability C  Token Probability D  \\\n",
       "0                      NaN                  NaN                  NaN   \n",
       "1                      NaN                  NaN                  NaN   \n",
       "2                      NaN                  NaN                  NaN   \n",
       "3                      NaN                  NaN                  NaN   \n",
       "4                      NaN                  NaN                  NaN   \n",
       "...                    ...                  ...                  ...   \n",
       "82636             0.000003             0.000001         9.645942e-06   \n",
       "82637             0.000004             0.000004         2.966547e-06   \n",
       "82638             0.000042             0.000043         9.997405e-01   \n",
       "82639             0.000018             0.000010         9.999572e-01   \n",
       "82640             0.000008             0.999980         8.449691e-07   \n",
       "\n",
       "       Token Probability E  \n",
       "0                      NaN  \n",
       "1                      NaN  \n",
       "2                      NaN  \n",
       "3                      NaN  \n",
       "4                      NaN  \n",
       "...                    ...  \n",
       "82636                  NaN  \n",
       "82637                  NaN  \n",
       "82638                  NaN  \n",
       "82639                  NaN  \n",
       "82640                  NaN  \n",
       "\n",
       "[82641 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined_df = pd.DataFrame()\n",
    "clean_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "mcq_qsets = ['LSAT-AR', 'SAT-EN', 'SciQ']\n",
    "\n",
    "\n",
    "\n",
    "for model_type, models in folder_abstraction_dict.items():\n",
    "    model_type_path = folder_path + f\"/{model_type}\"\n",
    "    print(model_type_path)\n",
    "    for model_name, qsets in models.items():\n",
    "        model_path = model_type_path + f\"/{model_name}\"\n",
    "        print(f\"    {model_path}\")\n",
    "        for qset_file_name in qsets:\n",
    "            splitter = f\"_{model_name}\"\n",
    "            qset_name = qset_file_name.split(splitter)[0]\n",
    "            qset_path = model_path + f\"/{qset_file_name}\"\n",
    "            print(f\"        {qset_name}:    {qset_path}\")\n",
    "            #--------- Write a function to spit out a dataframe w/ model_name, qset_name, true_answer and concat it\n",
    "\n",
    "            source_df = pd.read_csv(qset_path)\n",
    "            source_df[\"Model\"] = model_name\n",
    "            source_df[\"Model Type\"] = model_type\n",
    "            source_df[\"Question Set\"] = qset_name\n",
    "            source_df[\"Question ID\"] = source_df[\"Question ID\"].astype(str)\n",
    "            combined_df = pd.concat([combined_df, source_df], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "combined_df.drop([\"Unnamed: 0\", \"Question ID.1\"], axis = 1, inplace = True)\n",
    "\n",
    "## Still need to add correct answer and score\n",
    "\n",
    "col_rename_map ={\n",
    "# Metadata\n",
    "'Question Set': \"Question Set\",\n",
    "'Question ID': \"Question ID\",\n",
    "'Model': \"Model\",\n",
    "'Model Type': \"Model Type\",\n",
    "'coerce': \"Coerce\",\n",
    "\n",
    "# Model Response\n",
    "\n",
    "'content': \"Content\",\n",
    "'Reasoning': \"Reasoning\",\n",
    "'Answer': \"Answer\",\n",
    "\n",
    "# Stated Confidence\n",
    "'Confidence': \"Stated Confidence Answer\",\n",
    "\"A\": \"Stated Confidence A\",\n",
    "\"B\": \"Stated Confidence B\",\n",
    "'C': \"Stated Confidence C\",\n",
    "'D': \"Stated Confidence D\",\n",
    "'E': \"Stated Confidence E\",\n",
    "\n",
    "# Token Probability\n",
    "'True_prob': \"Token Probability True\",\n",
    "'False_prob': \"Token Probability False\",\n",
    "'Answer_prob': \"Token Probability Answer\",\n",
    "'A_prob': \"Token Probability A\",\n",
    "'B_prob': \"Token Probability B\",\n",
    "'C_prob': \"Token Probability C\",\n",
    "'D_prob': \"Token Probability D\",\n",
    "'E_prob': \"Token Probability E\"\n",
    "}\n",
    "\n",
    "combined_df = combined_df.rename(columns = col_rename_map)\n",
    "\n",
    "qset_rename = {\n",
    " 'boolq_valid': \"BoolQ\",\n",
    " 'halu_eval_qa': \"HaluEval\",\n",
    " 'life_eval': \"LifeEval\",\n",
    " 'lsat_ar_test': \"LSAT-AR\",\n",
    " 'sat_en': \"SAT-EN\",\n",
    " 'sciq_test':\"SciQ\"\n",
    "}\n",
    "\n",
    "combined_df[\"Question Set\"] = combined_df[\"Question Set\"].map(qset_rename)\n",
    "\n",
    "with pd.option_context('display.max_columns', None,\n",
    "                       #'display.width', None,\n",
    "                       #'display.max_colwidth', None\n",
    "                       ):\n",
    "    display(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "666f9edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_clean = combined_df.copy()\n",
    "\n",
    "# this gets the qid and qset where coerce is false\n",
    "bad_qid_qset = combined_df[combined_df[\"Coerce\"] == False][[\"Question ID\", \"Question Set\"]]\n",
    "\n",
    "#bad_qid_qset = bad_qid_qset[[\"Question ID\", \"Question Set\"]]\n",
    "\n",
    "bad = set(bad_qid_qset[\"Question ID\"] +  \"_\" + bad_qid_qset[\"Question Set\"])\n",
    "\n",
    "\n",
    "combined_clean['combined_name'] = combined_clean['Question ID'] + \"_\" + combined_clean[\"Question Set\"]\n",
    "\n",
    "\n",
    "\n",
    "mask = ~combined_clean[\"combined_name\"].isin(bad)   # True = keep\n",
    "\n",
    "combined_clean = combined_clean[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "d71da9d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reasoning</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Stated Confidence Answer</th>\n",
       "      <th>Coerce</th>\n",
       "      <th>Content</th>\n",
       "      <th>Question ID</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Question Set</th>\n",
       "      <th>Stated Confidence A</th>\n",
       "      <th>...</th>\n",
       "      <th>Stated Confidence E</th>\n",
       "      <th>Token Probability True</th>\n",
       "      <th>Token Probability False</th>\n",
       "      <th>Token Probability Answer</th>\n",
       "      <th>Token Probability A</th>\n",
       "      <th>Token Probability B</th>\n",
       "      <th>Token Probability C</th>\n",
       "      <th>Token Probability D</th>\n",
       "      <th>Token Probability E</th>\n",
       "      <th>combined_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The question is asking whether the production ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n    \"Reasoning\": \"The question is asking wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>Claude</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0_BoolQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This question is asking about phantom limb pai...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.95</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n    \"Reasoning\": \"This question is asking a...</td>\n",
       "      <td>2</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>Claude</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2_BoolQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Escape from Gringotts is ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.98</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n    \"Reasoning\": \"Harry Potter and the Esca...</td>\n",
       "      <td>3</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>Claude</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3_BoolQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hydroxyzine HCl (hydrochloride) and hydroxyzin...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.98</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n    \"Reasoning\": \"Hydroxyzine HCl (hydrochl...</td>\n",
       "      <td>4</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>Claude</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4_BoolQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Barq's Root Beer is not a Pepsi product. It is...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.98</td>\n",
       "      <td>True</td>\n",
       "      <td>{\\n    \"Reasoning\": \"Barq's Root Beer is not a...</td>\n",
       "      <td>5</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>Claude</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5_BoolQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Reasoning Answer  \\\n",
       "0  The question is asking whether the production ...  False   \n",
       "2  This question is asking about phantom limb pai...   True   \n",
       "3  Harry Potter and the Escape from Gringotts is ...   True   \n",
       "4  Hydroxyzine HCl (hydrochloride) and hydroxyzin...   True   \n",
       "5  Barq's Root Beer is not a Pepsi product. It is...  False   \n",
       "\n",
       "  Stated Confidence Answer  Coerce  \\\n",
       "0                      0.6    True   \n",
       "2                     0.95    True   \n",
       "3                     0.98    True   \n",
       "4                     0.98    True   \n",
       "5                     0.98    True   \n",
       "\n",
       "                                             Content Question ID  \\\n",
       "0  {\\n    \"Reasoning\": \"The question is asking wh...           0   \n",
       "2  {\\n    \"Reasoning\": \"This question is asking a...           2   \n",
       "3  {\\n    \"Reasoning\": \"Harry Potter and the Esca...           3   \n",
       "4  {\\n    \"Reasoning\": \"Hydroxyzine HCl (hydrochl...           4   \n",
       "5  {\\n    \"Reasoning\": \"Barq's Root Beer is not a...           5   \n",
       "\n",
       "                        Model Model Type Question Set  Stated Confidence A  \\\n",
       "0  claude-3-7-sonnet-20250219     Claude        BoolQ                  NaN   \n",
       "2  claude-3-7-sonnet-20250219     Claude        BoolQ                  NaN   \n",
       "3  claude-3-7-sonnet-20250219     Claude        BoolQ                  NaN   \n",
       "4  claude-3-7-sonnet-20250219     Claude        BoolQ                  NaN   \n",
       "5  claude-3-7-sonnet-20250219     Claude        BoolQ                  NaN   \n",
       "\n",
       "   ...  Stated Confidence E  Token Probability True  Token Probability False  \\\n",
       "0  ...                  NaN                     NaN                      NaN   \n",
       "2  ...                  NaN                     NaN                      NaN   \n",
       "3  ...                  NaN                     NaN                      NaN   \n",
       "4  ...                  NaN                     NaN                      NaN   \n",
       "5  ...                  NaN                     NaN                      NaN   \n",
       "\n",
       "   Token Probability Answer  Token Probability A  Token Probability B  \\\n",
       "0                       NaN                  NaN                  NaN   \n",
       "2                       NaN                  NaN                  NaN   \n",
       "3                       NaN                  NaN                  NaN   \n",
       "4                       NaN                  NaN                  NaN   \n",
       "5                       NaN                  NaN                  NaN   \n",
       "\n",
       "   Token Probability C  Token Probability D  Token Probability E  \\\n",
       "0                  NaN                  NaN                  NaN   \n",
       "2                  NaN                  NaN                  NaN   \n",
       "3                  NaN                  NaN                  NaN   \n",
       "4                  NaN                  NaN                  NaN   \n",
       "5                  NaN                  NaN                  NaN   \n",
       "\n",
       "   combined_name  \n",
       "0        0_BoolQ  \n",
       "2        2_BoolQ  \n",
       "3        3_BoolQ  \n",
       "4        4_BoolQ  \n",
       "5        5_BoolQ  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(69278, 23)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Clean up MCQ Question Sets\n",
    "cc = combined_clean[combined_clean[\"Question Set\"].isin(mcq_qsets)]\n",
    "cc_letters = cc[[\"Stated Confidence A\", \"Stated Confidence B\", \"Stated Confidence C\",\"Stated Confidence D\",\"Stated Confidence E\",]].copy()\n",
    "sum_confidence = cc_letters.sum(axis = 1)\n",
    "\n",
    "con_mask = cc[sum_confidence == 0.0][\"combined_name\"]\n",
    "\n",
    "# Indixes that aren't in con_mask\n",
    "combined_clean = combined_clean.loc[~combined_clean[\"combined_name\"].isin(con_mask)]\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "## Make sure we also elimanate QID that are missing\n",
    "he = combined_clean[combined_clean[\"Question Set\"] == \"HaluEval\"]\n",
    "\n",
    "s = combined_clean[\"combined_name\"].value_counts() % 11  #---------------- This seems to get rid of too much\n",
    "bad_qid = s.index[s.ne(0)].tolist()  \n",
    "\n",
    "\n",
    "\n",
    "combined_clean = combined_clean[~combined_clean[\"combined_name\"].isin(bad_qid)]\n",
    "\n",
    "\n",
    "## Special mask for LifeEval:\n",
    "\n",
    "le_df = combined_clean[combined_clean[\"Question Set\"] == \"LifeEval\"]\n",
    "\n",
    "con_isnum = pd.to_numeric( le_df['Stated Confidence Answer'], errors='coerce').notna()\n",
    "le_bad_qid= le_df[~con_isnum][\"combined_name\"]\n",
    "\n",
    "\n",
    "combined_clean = combined_clean[(~combined_clean[\"combined_name\"].isin(le_bad_qid)) ]\n",
    "\n",
    "\n",
    "display(combined_clean.head())\n",
    "combined_clean.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8879e949",
   "metadata": {},
   "source": [
    "## Summary Info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd746d8",
   "metadata": {},
   "source": [
    "Here we see the Raw versus Filtered counts for all the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9efcb31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw</th>\n",
       "      <th>Filtered</th>\n",
       "      <th>Prop. Kept</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Question Set</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BoolQ</th>\n",
       "      <td>3270.0</td>\n",
       "      <td>2503.0</td>\n",
       "      <td>0.765443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HaluEval</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>0.895448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSAT-AR</th>\n",
       "      <td>230.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.373913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LifeEval</th>\n",
       "      <td>808.0</td>\n",
       "      <td>751.0</td>\n",
       "      <td>0.929455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAT-EN</th>\n",
       "      <td>206.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.839806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SciQ</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>995.0</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Raw  Filtered  Prop. Kept\n",
       "Question Set                              \n",
       "BoolQ         3270.0    2503.0    0.765443\n",
       "HaluEval      1999.0    1790.0    0.895448\n",
       "LSAT-AR        230.0      86.0    0.373913\n",
       "LifeEval       808.0     751.0    0.929455\n",
       "SAT-EN         206.0     173.0    0.839806\n",
       "SciQ          1000.0     995.0    0.995000"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = pd.DataFrame({\n",
    "    \"Raw\": round(combined_df[\"Question Set\"].value_counts() / 11), # This is slightly below 2000 for Llama because we had to drop 3 duplicates\n",
    "    \"Filtered\": combined_clean[\"Question Set\"].value_counts() / 11\n",
    "})\n",
    "\n",
    "counts[~counts.index.isin(mcq_qsets)]\n",
    "\n",
    "counts[\"Prop. Kept\"] = counts[\"Filtered\"] / counts[\"Raw\"]\n",
    "counts\n",
    "# Need to look at: LSAT-AR (-1)???,  Sciq(-1) Im getting rid of too much?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bff4a25",
   "metadata": {},
   "source": [
    "Jacob's cleaned version of SciQ has 996 rows while mine has 995. When investigating each deleted Question ID in my version we find that they all have 1 instance where the answer could not be coerced. Does Jacob have an extra question that shouldn't be there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "26e58eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question ID</th>\n",
       "      <th>false_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>295</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Question ID  false_count\n",
       "0          13            1\n",
       "1         295            1\n",
       "2          40            1\n",
       "3         699            1\n",
       "4         705            1"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "sciq_filtered = combined_clean[combined_clean[\"Question Set\"] == \"SciQ\"]\n",
    "sciq_raw = combined_df[combined_df[\"Question Set\"] == \"SciQ\"]\n",
    "\n",
    "\n",
    "sciq_filtered_ids = sciq_filtered.index\n",
    "\n",
    "deleted = sciq_raw[~sciq_raw.index.isin(sciq_filtered_ids)]\n",
    "deleted[\"Question ID\"].unique()\n",
    "\n",
    "# Deleted QID in SciQ are ['13', '40', '295', '699', '705'] after visual inspection they all seem to have False\n",
    "\n",
    "\n",
    "false_counts = (deleted['Coerce'].eq(False)\n",
    "                .groupby(deleted['Question ID'])\n",
    "                .sum()\n",
    "                .rename('false_count'))\n",
    "\n",
    "# as a DataFrame\n",
    "false_counts = false_counts.reset_index()\n",
    "false_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1ecd9798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Question Set</th>\n",
       "      <th>BoolQ</th>\n",
       "      <th>HaluEval</th>\n",
       "      <th>LSAT-AR</th>\n",
       "      <th>LifeEval</th>\n",
       "      <th>SAT-EN</th>\n",
       "      <th>SciQ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3.1-70B-Instruct</th>\n",
       "      <td>3241</td>\n",
       "      <td>1960</td>\n",
       "      <td>208</td>\n",
       "      <td>807</td>\n",
       "      <td>202</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3.1-8B-Instruct</th>\n",
       "      <td>3200</td>\n",
       "      <td>1997</td>\n",
       "      <td>190</td>\n",
       "      <td>800</td>\n",
       "      <td>202</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-7-sonnet-20250219</th>\n",
       "      <td>3267</td>\n",
       "      <td>2000</td>\n",
       "      <td>228</td>\n",
       "      <td>808</td>\n",
       "      <td>206</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-haiku-20240307</th>\n",
       "      <td>3036</td>\n",
       "      <td>1855</td>\n",
       "      <td>230</td>\n",
       "      <td>808</td>\n",
       "      <td>181</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-sonnet-4-20250514</th>\n",
       "      <td>3258</td>\n",
       "      <td>2000</td>\n",
       "      <td>188</td>\n",
       "      <td>808</td>\n",
       "      <td>205</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek-r1</th>\n",
       "      <td>3214</td>\n",
       "      <td>2000</td>\n",
       "      <td>228</td>\n",
       "      <td>808</td>\n",
       "      <td>206</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek-v3</th>\n",
       "      <td>2898</td>\n",
       "      <td>2000</td>\n",
       "      <td>228</td>\n",
       "      <td>808</td>\n",
       "      <td>204</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2.5-flash</th>\n",
       "      <td>3261</td>\n",
       "      <td>2000</td>\n",
       "      <td>177</td>\n",
       "      <td>808</td>\n",
       "      <td>206</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2.5-pro</th>\n",
       "      <td>3190</td>\n",
       "      <td>1984</td>\n",
       "      <td>188</td>\n",
       "      <td>808</td>\n",
       "      <td>204</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <td>3247</td>\n",
       "      <td>2000</td>\n",
       "      <td>230</td>\n",
       "      <td>808</td>\n",
       "      <td>206</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o3-2025-04-16</th>\n",
       "      <td>3070</td>\n",
       "      <td>1991</td>\n",
       "      <td>193</td>\n",
       "      <td>761</td>\n",
       "      <td>205</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Question Set                 BoolQ  HaluEval  LSAT-AR  LifeEval  SAT-EN  SciQ\n",
       "Model                                                                        \n",
       "Meta-Llama-3.1-70B-Instruct   3241      1960      208       807     202  1000\n",
       "Meta-Llama-3.1-8B-Instruct    3200      1997      190       800     202   997\n",
       "claude-3-7-sonnet-20250219    3267      2000      228       808     206   999\n",
       "claude-3-haiku-20240307       3036      1855      230       808     181   999\n",
       "claude-sonnet-4-20250514      3258      2000      188       808     205  1000\n",
       "deepseek-r1                   3214      2000      228       808     206  1000\n",
       "deepseek-v3                   2898      2000      228       808     204  1000\n",
       "gemini-2.5-flash              3261      2000      177       808     206  1000\n",
       "gemini-2.5-pro                3190      1984      188       808     204  1000\n",
       "gpt-4o                        3247      2000      230       808     206  1000\n",
       "o3-2025-04-16                 3070      1991      193       761     205  1000"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df[combined_df[\"Coerce\"] == True].pivot_table(index=\"Model\", columns=\"Question Set\",\n",
    "                        aggfunc=\"size\", fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dca270a",
   "metadata": {},
   "source": [
    "### Additional EDA:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112eca0e",
   "metadata": {},
   "source": [
    "Don was curious about some missing fields. For BoolQ we can see that all models have 2503 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "4854d335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model\n",
       "claude-3-7-sonnet-20250219     2503\n",
       "claude-3-haiku-20240307        2503\n",
       "claude-sonnet-4-20250514       2503\n",
       "deepseek-r1                    2503\n",
       "deepseek-v3                    2503\n",
       "gemini-2.5-flash               2503\n",
       "gemini-2.5-pro                 2503\n",
       "gpt-4o                         2503\n",
       "o3-2025-04-16                  2503\n",
       "Meta-Llama-3.1-70B-Instruct    2503\n",
       "Meta-Llama-3.1-8B-Instruct     2503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_clean[(combined_clean[\"Question Set\"] == \"BoolQ\")][\"Model\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "e79a241c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reasoning</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Stated Confidence Answer</th>\n",
       "      <th>Coerce</th>\n",
       "      <th>Content</th>\n",
       "      <th>Question ID</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Question Set</th>\n",
       "      <th>Stated Confidence A</th>\n",
       "      <th>...</th>\n",
       "      <th>Stated Confidence E</th>\n",
       "      <th>Token Probability True</th>\n",
       "      <th>Token Probability False</th>\n",
       "      <th>Token Probability Answer</th>\n",
       "      <th>Token Probability A</th>\n",
       "      <th>Token Probability B</th>\n",
       "      <th>Token Probability C</th>\n",
       "      <th>Token Probability D</th>\n",
       "      <th>Token Probability E</th>\n",
       "      <th>combined_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37570</th>\n",
       "      <td>The television series 'The Tudors' aired on Sh...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>```json\\n{\\n    \"Reasoning\": \"The television s...</td>\n",
       "      <td>3000</td>\n",
       "      <td>gemini-2.5-flash</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000_BoolQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37571</th>\n",
       "      <td>The question asks if the character Marley dies...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>```json\\n{\\n    \"Reasoning\": \"The question ask...</td>\n",
       "      <td>3001</td>\n",
       "      <td>gemini-2.5-flash</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3001_BoolQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37572</th>\n",
       "      <td>Canada is a prominent country with a well-deve...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>```json\\n{\\n    \"Reasoning\": \"Canada is a prom...</td>\n",
       "      <td>3002</td>\n",
       "      <td>gemini-2.5-flash</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3002_BoolQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37574</th>\n",
       "      <td>The term 'Pit Bull' commonly refers to a type ...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>```json\\n{\\n    \"Reasoning\": \"The term 'Pit Bu...</td>\n",
       "      <td>3004</td>\n",
       "      <td>gemini-2.5-flash</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3004_BoolQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37575</th>\n",
       "      <td>A 'postal code' is a general term used interna...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Response: {\\n    \"Reasoning\": \"A 'postal code'...</td>\n",
       "      <td>3005</td>\n",
       "      <td>gemini-2.5-flash</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3005_BoolQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Reasoning Answer  \\\n",
       "37570  The television series 'The Tudors' aired on Sh...  False   \n",
       "37571  The question asks if the character Marley dies...   True   \n",
       "37572  Canada is a prominent country with a well-deve...   True   \n",
       "37574  The term 'Pit Bull' commonly refers to a type ...  False   \n",
       "37575  A 'postal code' is a general term used interna...  False   \n",
       "\n",
       "      Stated Confidence Answer  Coerce  \\\n",
       "37570                      1.0    True   \n",
       "37571                      1.0    True   \n",
       "37572                      1.0    True   \n",
       "37574                      1.0    True   \n",
       "37575                      1.0    True   \n",
       "\n",
       "                                                 Content Question ID  \\\n",
       "37570  ```json\\n{\\n    \"Reasoning\": \"The television s...        3000   \n",
       "37571  ```json\\n{\\n    \"Reasoning\": \"The question ask...        3001   \n",
       "37572  ```json\\n{\\n    \"Reasoning\": \"Canada is a prom...        3002   \n",
       "37574  ```json\\n{\\n    \"Reasoning\": \"The term 'Pit Bu...        3004   \n",
       "37575  Response: {\\n    \"Reasoning\": \"A 'postal code'...        3005   \n",
       "\n",
       "                  Model Model Type Question Set  Stated Confidence A  ...  \\\n",
       "37570  gemini-2.5-flash     Gemini        BoolQ                  NaN  ...   \n",
       "37571  gemini-2.5-flash     Gemini        BoolQ                  NaN  ...   \n",
       "37572  gemini-2.5-flash     Gemini        BoolQ                  NaN  ...   \n",
       "37574  gemini-2.5-flash     Gemini        BoolQ                  NaN  ...   \n",
       "37575  gemini-2.5-flash     Gemini        BoolQ                  NaN  ...   \n",
       "\n",
       "       Stated Confidence E  Token Probability True  Token Probability False  \\\n",
       "37570                  NaN                     NaN                      NaN   \n",
       "37571                  NaN                     NaN                      NaN   \n",
       "37572                  NaN                     NaN                      NaN   \n",
       "37574                  NaN                     NaN                      NaN   \n",
       "37575                  NaN                     NaN                      NaN   \n",
       "\n",
       "       Token Probability Answer  Token Probability A  Token Probability B  \\\n",
       "37570                       NaN                  NaN                  NaN   \n",
       "37571                       NaN                  NaN                  NaN   \n",
       "37572                       NaN                  NaN                  NaN   \n",
       "37574                       NaN                  NaN                  NaN   \n",
       "37575                       NaN                  NaN                  NaN   \n",
       "\n",
       "       Token Probability C  Token Probability D  Token Probability E  \\\n",
       "37570                  NaN                  NaN                  NaN   \n",
       "37571                  NaN                  NaN                  NaN   \n",
       "37572                  NaN                  NaN                  NaN   \n",
       "37574                  NaN                  NaN                  NaN   \n",
       "37575                  NaN                  NaN                  NaN   \n",
       "\n",
       "       combined_name  \n",
       "37570     3000_BoolQ  \n",
       "37571     3001_BoolQ  \n",
       "37572     3002_BoolQ  \n",
       "37574     3004_BoolQ  \n",
       "37575     3005_BoolQ  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_clean[(combined_clean[\"Question Set\"] == \"BoolQ\") & (combined_clean[\"Model Type\"] == \"Gemini\")].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d86feb",
   "metadata": {},
   "source": [
    "## Save both CSVs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "8469f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_path   = Path(\"Parsed Results/combined_raw.csv\")\n",
    "clean_path = Path(\"Parsed Results/combined_clean.csv\")\n",
    "\n",
    "\n",
    "# write\n",
    "combined_df.to_csv(raw_path, index=False, encoding=\"utf-8\")\n",
    "combined_clean.to_csv(clean_path, index=False, encoding=\"utf-8\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
