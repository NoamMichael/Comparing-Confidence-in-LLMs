{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNDy/WYvfyVQp7Yf4xGVR0O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoamMichael/Comparing-Confidence-in-LLMs/blob/main/LSAT_Benchmarking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WuTZXLzGAGkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe43523e-3a60-4826-b8e2-c1cacae65ca8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anthropic\n",
            "  Downloading anthropic-0.52.2-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (2.11.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.14.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.1)\n",
            "Downloading anthropic-0.52.2-py3-none-any.whl (286 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.3/286.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic\n",
            "Successfully installed anthropic-0.52.2\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.84.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "# This Notebook will test all models on the formatted LSAT-AR dataset\n",
        "# I have no issue running multiple API clients simultaneously. However, running\n",
        "# local models is pretty memory intensive so I can only run one at a time.\n",
        "%pip install anthropic\n",
        "%pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import (AutoTokenizer,\n",
        "                        AutoModelForCausalLM,\n",
        "                        BitsAndBytesConfig,\n",
        "                        pipeline)\n",
        "import warnings\n",
        "import openai\n",
        "import anthropic\n",
        "import google.generativeai as genai\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "class OpenModel: ## This class is built around Hugging Face methods\n",
        "  def __init__(self, name, key, MaxTokens = 150):\n",
        "    self.name = name\n",
        "    self.key = key\n",
        "    self.MaxTokens = MaxTokens\n",
        "    print(f\"Downloading Tokenizer for {self.name}\")\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(self.name,token = self.key) ## Import Tokenizer\n",
        "    print(f\"Downloading Model Weights for {self.name}\")\n",
        "    self.model = AutoModelForCausalLM.from_pretrained(self.name, token = self.key, device_map=\"auto\") ## Import Model\n",
        "\n",
        "    ## Make text generation pipeline\n",
        "    self.pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model = self.model,\n",
        "    tokenizer = self.tokenizer,\n",
        "    do_sample = False,\n",
        "    max_new_tokens = self.MaxTokens,\n",
        "    eos_token_id = self.tokenizer.eos_token_id,\n",
        "    pad_token_id = self.tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "  def generate(self, prompt):\n",
        "    return self.pipeline(prompt)[0]['generated_text']\n",
        "\n",
        "  def GetTokens(self, prompt: str):\n",
        "    ## Get Answer:\n",
        "    batch = self.tokenizer(prompt, return_tensors= \"pt\").to('cuda')\n",
        "    with torch.no_grad():\n",
        "        outputs = self.model(**batch)\n",
        "    ## Get Token Probabilites\n",
        "    logits = outputs.logits\n",
        "\n",
        "    ## Apply softmax to the logits to get probabilities\n",
        "    probs = torch.softmax(logits[0, -1], dim=0)\n",
        "\n",
        "    ##Get the top k token indices and their probabilities\n",
        "    top_k_probs, top_k_indices = torch.topk(probs, 100, sorted =True)\n",
        "\n",
        "    ## Convert token indices to tokens\n",
        "    top_k_tokens = [self.tokenizer.decode([token_id]) for token_id in top_k_indices]\n",
        "\n",
        "    ## Convert probabilities to list of floats\n",
        "    top_k_probs = top_k_probs.tolist()                  #list of probabilities\n",
        "\n",
        "    ## Create a Pandas Series with tokens as index and probabilities as values\n",
        "    logit_series = pd.Series(top_k_probs, index=top_k_tokens)\n",
        "\n",
        "    ## Sort the series by values in descending order\n",
        "    logit_series = logit_series.sort_values(ascending=False)\n",
        "    logit_series.index.name = \"Token\"\n",
        "    logit_series.name = \"Probability\"\n",
        "    return logit_series\n",
        "\n",
        "class ClosedModel(ABC):\n",
        "  @abstractmethod\n",
        "  def generate(self, prompt: str, system:str = \"\")-> str:\n",
        "        \"\"\"\n",
        "        Abstract method to generate a response from the language model.\n",
        "        \"\"\"\n",
        "        pass\n",
        "  @abstractmethod\n",
        "  def __init__(self, name, api_key):\n",
        "    self.name = name\n",
        "    self.key = api_key\n",
        "    self.results = pd.DataFrame(columns = ['Question ID','Question', 'Answer', 'Reasoning'])\n",
        "    pass\n",
        "\n",
        "  @abstractmethod\n",
        "  def client(self):\n",
        "    pass\n",
        "\n",
        "  @abstractmethod\n",
        "  def GetRAC(self, prompt: str, system1:str = \"\", system2: str = \"\")-> tuple[str, str]: ## Get Reasoning Answer Confidence\n",
        "    pass\n",
        "\n",
        "class GPTmodel(ClosedModel):\n",
        "  def __init__(self, name, api_key):\n",
        "    self.name = name\n",
        "    self.key = api_key\n",
        "    self.results = pd.DataFrame(columns = ['Question ID','Question', 'Answer', 'Reasoning'])\n",
        "  def client(self):\n",
        "    # Initialize the OpenAI client with the API key\n",
        "    self.client = openai.OpenAI(api_key=self.key)\n",
        "\n",
        "\n",
        "  def generate(self, prompt: str, system: str = \"\") -> str:\n",
        "    # Use the new client-based API call\n",
        "    response = self.client.chat.completions.create(\n",
        "        model=self.name,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0,\n",
        "        max_tokens=100\n",
        "    )\n",
        "    # Access the content from the new response object structure\n",
        "    return response.choices[0].message.content\n",
        "  def GetRAC(self, prompt: str)-> tuple[str, str]: ## Get Reasoning Answer Confidence\n",
        "    ## For context here's the two system prompts:\n",
        "    ## System prompt 1:\n",
        "    '''\n",
        "    Given the following question, analyze the options, and provide a concise reasoning for your selected answer. Your reasoning should not exceed 100 words. After your explanation, clearly state your answer by choosing one of the options listed (A, B, C, D, or E).\n",
        "\n",
        "    Question: ${Question}\n",
        "    Options:\n",
        "    A) ${Option A}\n",
        "    B) ${Option B}\n",
        "    C) ${Option C}\n",
        "    D) ${Option D}\n",
        "    E) ${Option E}\n",
        "\n",
        "    Please provide your reasoning first, limited to 100 words, and then conclusively state only your selected answer using the corresponding letter (A, B, C, D, or E).\n",
        "    Reasoning: <Your concise reasoning here. Max 100 words>\n",
        "    '''\n",
        "\n",
        "    ## System prompt 2:\n",
        "    '''\n",
        "    Based on the reasoning above, Provide the correct answer and the likelihood that each option is correct from 0.0 to 1.0 in a JSON format. The four probabilities should sum to 1.0. For example:\n",
        "\n",
        "    {\n",
        "    'Answer': <Your answer choice here, as a single letter and nothing else.>\n",
        "    'A': <Probability choice A is correct. As a float from 0.0 to 1.0>,\n",
        "    'B': <Probability choice B is correct. As a float from 0.0 to 1.0>,\n",
        "    'C': <Probability choice C is correct. As a float from 0.0 to 1.0>,\n",
        "    'D': <Probability choice D is correct. As a float from 0.0 to 1.0>,\n",
        "    'E': <Probability choice E is correct. As a float from 0.0 to 1.0>\n",
        "    }\n",
        "    '''\n",
        "    # Access global system prompts\n",
        "    global sys_prompt1, sys_prompt2\n",
        "    ## Get the reasoning\n",
        "    reasoning = self.generate(prompt, sys_prompt1)\n",
        "    ## Get the answer and confidence\n",
        "    answer_confidence = self.generate(prompt + reasoning, sys_prompt2)\n",
        "\n",
        "    return reasoning, answer_confidence\n",
        "\n",
        "class AnthropicModel(ClosedModel):\n",
        "  def __init__(self, name, api_key):\n",
        "    self.name = name\n",
        "    self.key = api_key\n",
        "    self.results = pd.DataFrame(columns = ['Question ID','Question', 'Answer', 'Reasoning'])\n",
        "  def client(self):\n",
        "    # Initialize the Anthropic client with the API key\n",
        "    self.client = anthropic.Anthropic(api_key=self.key)\n",
        "\n",
        "  def generate(self, prompt: str, system: str = \"\") -> str:\n",
        "    # The messages list should only contain user and assistant roles\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "    # Use the Anthropic client to create a message\n",
        "    # Pass the system message as a top-level 'system' parameter\n",
        "    message = self.client.messages.create(\n",
        "        model=self.name,\n",
        "        max_tokens=100, # You can adjust this or make it an instance variable\n",
        "        messages=messages,\n",
        "        system=system if system else None # Pass system as a separate parameter, or None if empty\n",
        "    )\n",
        "    # Access the content from the response object\n",
        "    return message.content[0].text\n",
        "\n",
        "  def GetRAC(self, prompt: str)-> tuple[str, str]: ## Get Reasoning Answer Confidence\n",
        "    \"\"\"\n",
        "    NEED TO DO\n",
        "    \"\"\"\n",
        "    pass\n",
        "class GeminiModel(ClosedModel):\n",
        "  def __init__(self, name, api_key):\n",
        "    self.name = name\n",
        "    self.key = api_key\n",
        "    self.results = pd.DataFrame(columns = ['Question ID','Question', 'Answer', 'Reasoning'])\n",
        "\n",
        "  def client(self):\n",
        "    # Initialize the google.generativeai client with the API key\n",
        "\n",
        "    genai.configure(api_key=self.key)\n",
        "    self.model = genai.GenerativeModel(model_name=self.name)\n",
        "\n",
        "  def generate(self, prompt: str, system: str = \"\") -> str:\n",
        "    # Build the content list, including the system message if provided\n",
        "    contents = [{\"role\": \"user\", \"parts\": [prompt]}]\n",
        "    if system:\n",
        "        contents = [{\"role\": \"user\", \"parts\": [system]}] + contents\n",
        "\n",
        "    # Use the Gemini model to generate content\n",
        "    response = self.model.generate_content(contents)\n",
        "\n",
        "    # Access the content from the response object\n",
        "    return response.text\n",
        "\n",
        "  def GetRAC(self, prompt: str)-> tuple[str, str]: ## Get Reasoning Answer Confidence\n",
        "    \"\"\"\n",
        "    NEED TO DO\n",
        "    \"\"\"\n",
        "    pass"
      ],
      "metadata": {
        "id": "ZqNsBM1oBHmp"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Playground for Llama\n",
        "hf_llama_token = userdata.get('hf_llama_token')\n",
        "test_name = 'meta-llama/Llama-3.1-8B-Instruct'\n",
        "test_key = hf_llama_token\n",
        "test_prompt = \"Zdzisław Beksiński was\"\n",
        "\n",
        "test_model = OpenModel(name = test_name, key = test_key)"
      ],
      "metadata": {
        "id": "sA1Rq7e6HlTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_model.generate(test_prompt))\n",
        "test_model.GetTokens(test_prompt)"
      ],
      "metadata": {
        "id": "H-bj6Bn9HsSF",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Playground for GPT\n",
        "\n",
        "gpt_4_key = userdata.get('gpt_api_key')\n",
        "test_name = 'gpt-4'\n",
        "test_key = gpt_4_key\n",
        "test_prompt = \"Zdzisław Beksiński was\"\n",
        "test_system = \"You are a helpful assistant.\"\n",
        "\n",
        "my_gpt = GPTmodel(name = test_name, api_key = test_key)\n",
        "my_gpt.client()\n",
        "my_gpt.generate(test_prompt, test_system)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "1r9p6BsQO5_Q",
        "outputId": "3d8a8a9b-0909-4014-d5cd-448219575f44"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"a renowned Polish painter, photographer, and sculptor. He is best known for his large, detailed images of a surreal, post-apocalyptic environment. Beksiński's works are characterized by their haunting, dreamlike nature, often featuring desolate landscapes and grotesque, distorted figures. Despite the grim themes, he insisted his work was not to be interpreted in a literal sense, and that he was more interested in the emotions and reactions they provoked. He was born on February 24, \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Playground for Claude\n",
        "\n",
        "claude_key = userdata.get('claude_api_key')\n",
        "test_name = 'claude-3-haiku-20240307'\n",
        "test_key = claude_key\n",
        "test_prompt = \"Zdzisław Beksiński was\"\n",
        "test_system = \"You are a helpful assistant.\"\n",
        "\n",
        "my_claude = AnthropicModel(name = test_name, api_key = test_key)\n",
        "my_claude.client()\n",
        "my_claude.generate(test_prompt, test_system)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "WrdIcyVUff4I",
        "outputId": "6e42ad11-8abf-441a-a6dc-76777cff72c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Zdzisław Beksiński was a Polish painter, photographer, and sculptor who was known for his distinctive surrealist and dystopian style. Here are some key facts about him:\\n\\n- Born in 1929 in Sanok, Poland, Beksiński initially studied to be an architect before turning to art.\\n\\n- His paintings often depicted post-apocalyptic, nightmarish landscapes and figures. His style was highly detailed and technical, with a'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Playground for Gemini\n",
        "\n",
        "gemini_api_key = userdata.get('gemini_api_key') # Assuming you stored your key in Userdata\n",
        "test_name = \"gemini-2.0-flash\" # Or another Gemini model name like 'gemini-1.5-flash'\n",
        "test_key = gemini_api_key\n",
        "test_prompt = \"Zdzisław Beksiński was\"\n",
        "test_system = \"You are a helpful assistant.\" # Optional system message\n",
        "\n",
        "my_gemini = GeminiModel(name = test_name, api_key = test_key)\n",
        "my_gemini.client()\n",
        "my_gemini.generate(test_prompt, test_system)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "dG59Di8PtRH4",
        "outputId": "023d6b33-7d38-47b7-9768-ba4b044efed2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Zdzisław Beksiński was a Polish painter, photographer, and sculptor specializing in dystopian surrealism. He is known for his distinctive and hauntingly beautiful, yet often disturbing, imagery. His art explores themes of death, decay, anxiety, and the human condition.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Pseudo Code\n",
        "## Import dataset\n",
        "\n",
        "## Initialize all closed models\n",
        "\n",
        "##--Initialize all GPT models\n",
        "##----GPT-4o\n",
        "##----GPT-o3\n",
        "##--Initialize all Claude models\n",
        "##----Claude-3.7 Sonnet\n",
        "##----Claude-4 Sonnet\n",
        "##--Initialize Gemini\n",
        "##----Gemini-2.0 Flash\n",
        "##----Gemini-1.5 Flash\n",
        "##----Gemini-2.5 Pro\n",
        "\n",
        "'''\n",
        "for question in dataset:\n",
        "  for model in ClosedModels:\n",
        "    model.generate(question) #Since we are iterating over ClosedModels we can call the abstract method .generate()\n",
        "\n",
        "'''\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZkvW0SL0xkY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Initializing my closed models\n",
        "\n",
        "my_closed_models = {\n",
        "    'GPT': {\n",
        "        'api_key_name': 'gpt_api_key', # Name of the key to retrieve from userdata\n",
        "        'models': [\n",
        "            'gpt-4',\n",
        "            'gpt-3.5-turbo'\n",
        "        ]\n",
        "    },\n",
        "    'Claude': {\n",
        "        'api_key_name': 'claude_api_key', # Name of the key to retrieve from userdata\n",
        "        'models': [\n",
        "            #'claude-3-sonnet-20240229',\n",
        "            'claude-3-haiku-20240307'\n",
        "        ]\n",
        "    },\n",
        "    'Gemini': {\n",
        "        'api_key_name': 'gemini_api_key', # Name of the key to retrieve from userdata\n",
        "        'models': [\n",
        "            'gemini-1.5-flash',\n",
        "            #'gemini-1.5-pro'\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "print('Initializing Closed Models:')\n",
        "closed_models = []\n",
        "for model_type in my_closed_models:\n",
        "    print(f'{model_type}:')\n",
        "    api_key_name = my_closed_models[model_type]['api_key_name']\n",
        "    api_key = userdata.get(api_key_name)\n",
        "    print(f'  API Key Name: {my_closed_models[model_type][\"api_key_name\"]}')\n",
        "    for model_name in my_closed_models[model_type]['models']:\n",
        "      # Instantiate the correct subclass based on model_type\n",
        "      if model_type == 'GPT':\n",
        "          my_model = GPTmodel(name = model_name, api_key = api_key)\n",
        "      elif model_type == 'Claude':\n",
        "          my_model = AnthropicModel(name = model_name, api_key = api_key)\n",
        "      elif model_type == 'Gemini':\n",
        "          my_model = GeminiModel(name = model_name, api_key = api_key)\n",
        "      else:\n",
        "          # Handle unexpected model types if necessary\n",
        "          print(f\"Warning: Unknown model type {model_type}. Skipping.\")\n",
        "          continue # Skip to the next model name if type is unknow\n",
        "      my_model.client()\n",
        "      closed_models.append(my_model)\n",
        "      print(f'    {model_name}')\n",
        "\n",
        "\n",
        "print(f'Models Initialized: {len(closed_models)}')\n",
        "print(f'Model locations:\\n{closed_models}')\n",
        "\n",
        "print('-'*42)\n",
        "print('Testing all closed models:')\n",
        "print(f'Test prompt: {test_prompt}')\n",
        "print(f'Test system: {test_system}')\n",
        "\n",
        "for model in closed_models:\n",
        "  print(f'\\nTesting model: {model.name}')\n",
        "  print(model.generate(test_prompt, test_system))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "Xl01iH3a1Vl4",
        "outputId": "a3b048c8-aa9f-4fba-f59c-46768867ea81"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Closed Models:\n",
            "GPT:\n",
            "  API Key Name: gpt_api_key\n",
            "    gpt-4\n",
            "    gpt-3.5-turbo\n",
            "Claude:\n",
            "  API Key Name: claude_api_key\n",
            "    claude-3-haiku-20240307\n",
            "Gemini:\n",
            "  API Key Name: gemini_api_key\n",
            "    gemini-1.5-flash\n",
            "Models Initialized: 4\n",
            "Model locations:\n",
            "[<__main__.GPTmodel object at 0x7f37b4ceedd0>, <__main__.GPTmodel object at 0x7f37b4d0c890>, <__main__.AnthropicModel object at 0x7f37b34f0550>, <__main__.GeminiModel object at 0x7f37b58a1810>]\n",
            "------------------------------------------\n",
            "Testing all closed models:\n",
            "Test prompt: Zdzisław Beksiński was\n",
            "Test system: You are a helpful assistant.\n",
            "\n",
            "Testing model: gpt-4\n",
            "a renowned Polish painter, photographer, and sculptor. He is best known for his large, detailed images of a surreal, post-apocalyptic environment. Beksiński's works are characterized by their haunting beauty, often depicting twisted figures, desolate landscapes, and eerie symbolism. Despite the often grim subject matter, he insisted his work was not to be read literally, and that he was not a pessimist. Beksiński was born on February 24, 1929, and trag\n",
            "\n",
            "Testing model: gpt-3.5-turbo\n",
            "Zdzisław Beksiński was a renowned Polish artist known for his surreal and dystopian paintings. He was primarily known for his dark and haunting artworks that often depicted nightmarish and otherworldly scenes. Beksiński's work has gained international recognition and has left a lasting impact on the art world.\n",
            "\n",
            "Testing model: claude-3-haiku-20240307\n",
            "Zdzisław Beksiński was a Polish painter, photographer, and sculptor who was known for his distinctive surreal and dystopian style. Some key facts about Zdzisław Beksiński:\n",
            "\n",
            "- He was born in 1929 in Sanok, Poland and died in 2005 in Warsaw, Poland.\n",
            "\n",
            "- His paintings often depicted post-apocalyptic, surreal landscapes and figures in distorted, disturbing ways. His\n",
            "\n",
            "Testing model: gemini-1.5-flash\n",
            "Zdzisław Beksiński was a Polish painter, sculptor, and photographer.  He is best known for his dystopian and surrealist paintings, characterized by their bleak, apocalyptic imagery, often featuring skeletal figures, decaying landscapes, and unsettling atmospheres.  His work is highly distinctive and emotionally evocative, and continues to be influential in the art world.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Import LSAT dataset\n",
        "\n",
        "file_path = '/content/LSAT_formatted.csv'\n",
        "\n",
        "dataset = pd.read_csv(file_path)\n",
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "1DpX0W9yIitP",
        "outputId": "2a23a5c4-b1fc-4e50-b796-d39dfc2eb9ab"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Question Correct Answer  \\\n",
              "0  Exactly six trade representatives negotiate a ...              B   \n",
              "1  Exactly six trade representatives negotiate a ...              A   \n",
              "2  Exactly six trade representatives negotiate a ...              B   \n",
              "3  Exactly six trade representatives negotiate a ...              E   \n",
              "4  Exactly six trade representatives negotiate a ...              E   \n",
              "\n",
              "  Question Number                                      Option A  \\\n",
              "0  199106_2-G_1_1  Klosnik, Poirier, Neri, Manley, Osata, Londi   \n",
              "1  199106_2-G_1_2                             Klosnik and Osata   \n",
              "2  199106_2-G_1_3                                Londi and Neri   \n",
              "3  199106_2-G_1_4                              Londi and Manley   \n",
              "4  199106_2-G_1_5                                       Klosnik   \n",
              "\n",
              "                                       Option B  \\\n",
              "0  Klosnik, Londi, Manley, Poirier, Neri, Osata   \n",
              "1                                Londi and Neri   \n",
              "2                               Londi and Osata   \n",
              "3                             Londi and Poirier   \n",
              "4                                 Klosnik, Neri   \n",
              "\n",
              "                                       Option C  \\\n",
              "0  Klosnik, Londi, Manley, Osata, Poirier, Neri   \n",
              "1                               Londi and Osata   \n",
              "2                                Neri and Osata   \n",
              "3                                Neri and Osata   \n",
              "4                                 Neri, Poirier   \n",
              "\n",
              "                                       Option D  \\\n",
              "0  Klosnik, Osata, Poirier, Neri, Londi, Manley   \n",
              "1                               Manley and Neri   \n",
              "2                              Neri and Poirier   \n",
              "3                              Neri and Poirier   \n",
              "4                       Klosnik, Osata, Poirier   \n",
              "\n",
              "                                       Option E  \n",
              "0  Klosnik, Neri, Londi, Osata, Manley, Poirier  \n",
              "1                            Manley and Poirier  \n",
              "2                             Osata and Poirier  \n",
              "3                             Poirier and Osata  \n",
              "4                 Klosnik, Neri, Osata, Poirier  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-35974fb5-3255-41ac-8351-a0bb7de2e3b2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Correct Answer</th>\n",
              "      <th>Question Number</th>\n",
              "      <th>Option A</th>\n",
              "      <th>Option B</th>\n",
              "      <th>Option C</th>\n",
              "      <th>Option D</th>\n",
              "      <th>Option E</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Exactly six trade representatives negotiate a ...</td>\n",
              "      <td>B</td>\n",
              "      <td>199106_2-G_1_1</td>\n",
              "      <td>Klosnik, Poirier, Neri, Manley, Osata, Londi</td>\n",
              "      <td>Klosnik, Londi, Manley, Poirier, Neri, Osata</td>\n",
              "      <td>Klosnik, Londi, Manley, Osata, Poirier, Neri</td>\n",
              "      <td>Klosnik, Osata, Poirier, Neri, Londi, Manley</td>\n",
              "      <td>Klosnik, Neri, Londi, Osata, Manley, Poirier</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Exactly six trade representatives negotiate a ...</td>\n",
              "      <td>A</td>\n",
              "      <td>199106_2-G_1_2</td>\n",
              "      <td>Klosnik and Osata</td>\n",
              "      <td>Londi and Neri</td>\n",
              "      <td>Londi and Osata</td>\n",
              "      <td>Manley and Neri</td>\n",
              "      <td>Manley and Poirier</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Exactly six trade representatives negotiate a ...</td>\n",
              "      <td>B</td>\n",
              "      <td>199106_2-G_1_3</td>\n",
              "      <td>Londi and Neri</td>\n",
              "      <td>Londi and Osata</td>\n",
              "      <td>Neri and Osata</td>\n",
              "      <td>Neri and Poirier</td>\n",
              "      <td>Osata and Poirier</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Exactly six trade representatives negotiate a ...</td>\n",
              "      <td>E</td>\n",
              "      <td>199106_2-G_1_4</td>\n",
              "      <td>Londi and Manley</td>\n",
              "      <td>Londi and Poirier</td>\n",
              "      <td>Neri and Osata</td>\n",
              "      <td>Neri and Poirier</td>\n",
              "      <td>Poirier and Osata</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Exactly six trade representatives negotiate a ...</td>\n",
              "      <td>E</td>\n",
              "      <td>199106_2-G_1_5</td>\n",
              "      <td>Klosnik</td>\n",
              "      <td>Klosnik, Neri</td>\n",
              "      <td>Neri, Poirier</td>\n",
              "      <td>Klosnik, Osata, Poirier</td>\n",
              "      <td>Klosnik, Neri, Osata, Poirier</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35974fb5-3255-41ac-8351-a0bb7de2e3b2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-35974fb5-3255-41ac-8351-a0bb7de2e3b2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-35974fb5-3255-41ac-8351-a0bb7de2e3b2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-10f767fb-2507-4dd4-a4b9-ab2efa08f9f7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-10f767fb-2507-4dd4-a4b9-ab2efa08f9f7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-10f767fb-2507-4dd4-a4b9-ab2efa08f9f7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 1630,\n  \"fields\": [\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1580,\n        \"samples\": [\n          \"Detectives investigating a citywide increase in burglaries questioned exactly seven suspects\\u2014S, T, V, W, X, Y, and Z\\u2014each on a different one of seven consecutive days. Each suspect was questioned exactly once. Any suspect who confessed did so while being questioned. The investigation conformed to the following: T was questioned on day three. The suspect questioned on day four did not confess. S was questioned after W was questioned. Both X and V were questioned after Z was questioned. No suspects confessed after W was questioned. Exactly two suspects confessed after T was questioned. Which one of the following suspects must have been questioned before T was questioned?\",\n          \"Bird-watchers explore a forest to see which of the following six kinds of birds\\u2014grosbeak, harrier, jay, martin, shrike, wren\\u2014it contains. The findings are consistent with the following conditions: If harriers are in the forest, then grosbeaks are not. If jays, martins, or both are in the forest, then so are harriers. If wrens are in the forest, then so are grosbeaks. If jays are not in the forest, then shrikes are. Suppose the condition is added that if shrikes are in the forest, then harriers are not. If all other conditions remain in effect, then which one of the following could be true?\",\n          \"A courier delivers exactly eight parcels\\u2014G, H, J, K, L, M, N, and O. No two parcels are delivered at the same time, nor is any parcel delivered more than once. The following conditions must apply: L is delivered later than H. K is delivered earlier than O. H is delivered earlier than M. O is delivered later than G. M is delivered earlier than G. Both N and J are delivered earlier than M. Which one of the following must be true?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Correct Answer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"A\",\n          \"D\",\n          \"E\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question Number\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1630,\n        \"samples\": [\n          \"199809_1-G_4_24\",\n          \"199402_2-G_2_12\",\n          \"200709_2-G_1_5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Option A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1347,\n        \"samples\": [\n          \"Nation X: oranges, rice; Nation Y: oranges, tea; Nation Z: soybeans, wheat\",\n          \"There is exactly one yellow toy included in the display.\",\n          \"1 is a split-level house\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Option B\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1386,\n        \"samples\": [\n          \"1, 3, 5, and 6\",\n          \"2, 4\",\n          \"Every subcommittee has either Hsia or Irving as a member.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Option C\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1387,\n        \"samples\": [\n          \"Lido is inspected on Tuesday morning.\",\n          \"4, 5\",\n          \"Irving serves on a subcommittee with Pinsky.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Option D\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1402,\n        \"samples\": [\n          \"Zinser is the only performer who signs with Star Agency.\",\n          \"Nordique, Lofton, Plattesville, Jackson, Oceana\",\n          \"One of the men orders swordfish.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Option E\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1357,\n        \"samples\": [\n          \"Two of the people order tilefish.\",\n          \"Sethna is on the second-place team.\",\n          \"If the house in Townsend is not shown fifth, then it must be shown immediately before the house in Riverton.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## System Prompts\n",
        "\n",
        "debug = True ## Test condition for print statements / less runs\n",
        "set_seed = 42 ## Random Seed\n",
        "\n",
        "sys_prompt1 = '''\n",
        "Given the following question, analyze the options, and provide a concise reasoning for your selected answer. Your reasoning should not exceed 100 words. After your explanation, clearly state your answer by choosing one of the options listed (A, B, C, D, or E).\n",
        "\n",
        "Question: ${Question}\n",
        "Options:\n",
        "A) ${Option A}\n",
        "B) ${Option B}\n",
        "C) ${Option C}\n",
        "D) ${Option D}\n",
        "E) ${Option E}\n",
        "\n",
        "Please provide your reasoning first, limited to 100 words, and then conclusively state only your selected answer using the corresponding letter (A, B, C, D, or E).\n",
        "Reasoning: <Your concise reasoning here. Max 100 words>\n",
        "'''\n",
        "sys_prompt2 = '''\n",
        "Based on the reasoning above, Provide the correct answer and the likelihood that each option is correct from 0.0 to 1.0 in a JSON format. The four probabilities should sum to 1.0. For example:\n",
        "\n",
        "{\n",
        "'Answer': <Your answer choice here, as a single letter and nothing else.>\n",
        "'A': <Probability choice A is correct. As a float from 0.0 to 1.0>,\n",
        "'B': <Probability choice B is correct. As a float from 0.0 to 1.0>,\n",
        "'C': <Probability choice C is correct. As a float from 0.0 to 1.0>,\n",
        "'D': <Probability choice D is correct. As a float from 0.0 to 1.0>,\n",
        "'E': <Probability choice E is correct. As a float from 0.0 to 1.0>\n",
        "}\n",
        "'''\n",
        "\n",
        "## Edit system Prompts in order to match size of dataset\n",
        "columns = dataset.columns\n",
        "num_options = columns.str.contains('Option').astype(int).sum()\n",
        "\n",
        "sys_prompt_temp1 = sys_prompt1\n",
        "sys_prompt_temp2 = sys_prompt2\n",
        "## Reformat system prompt in order to fit number of options in benchmark\n",
        "if num_options < 5: ## ABCD\n",
        "  sys_prompt_temp1 = (sys_prompt1\n",
        "                .replace('(A, B, C, D, or E)', '(A, B, C, or D)') ## Change the available options\n",
        "                .replace('E) ${Option E}', '') ## Drop option E\n",
        "      )\n",
        "  sys_prompt_temp2 = (sys_prompt2\n",
        "                .replace('(A, B, C, D, or E)', '(A, B, C, or D)') ## Change the available options\n",
        "                .replace('E) ${Option E}', '') ## Drop option E\n",
        "      )\n",
        "  if num_options < 4: ## ABC\n",
        "    sys_prompt_temp1 = (sys_prompt_temp1\n",
        "                  .replace('(A, B, C, or D)', '(A, B, or C)') ## Change the available options\n",
        "                  .replace('D) ${Option D}', '') ## Drop option D\n",
        "        )\n",
        "    sys_prompt_temp2 = (sys_prompt_temp2\n",
        "                .replace('(A, B, C, or D)', '(A, B, or C)') ## Change the available options\n",
        "                .replace('D) ${Option D}', '') ## Drop option D\n",
        "      )\n",
        "\n",
        "    if num_options < 3: ## AB\n",
        "      sys_prompt_temp1 = (sys_prompt_temp1\n",
        "                    .replace('(A, B, or C)', '(A or B)') ## Change the available options\n",
        "                    .replace('C) ${Option C}', '') ## Drop option C\n",
        "          )\n",
        "      sys_prompt_temp2 = (sys_prompt_temp2\n",
        "                  .replace('(A, B, or C)', '(A or B)') ## Change the available options\n",
        "                  .replace('C) ${Option C}', '') ## Drop option C\n",
        "        )\n",
        "\n",
        "sys_prompt1 = sys_prompt_temp1\n",
        "sys_prompt2 = sys_prompt_temp2"
      ],
      "metadata": {
        "id": "9EVsC1FaKS0q"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_dataset = format_df(dataset)\n",
        "new_dataset.head()\n",
        "\n",
        "new_test_prompt = new_dataset['Full Prompt 1'][0]\n",
        "print(new_test_prompt)\n",
        "display(new_dataset.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "6nwOId3dtK1H",
        "outputId": "e80d6465-f3c5-4edc-f0b5-db209076e6b5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Given the following question, analyze the options, and provide a concise reasoning for your selected answer. Your reasoning should not exceed 100 words. After your explanation, clearly state your answer by choosing one of the options listed (A, B, C, D, or E).\n",
            "\n",
            "Question: Exactly six trade representatives negotiate a treaty: Klosnik, Londi, Manley, Neri, Osata, Poirier. There are exactly six chairs evenly spaced around a circular table. The chairs are numbered 1 through 6, with successively numbered chairs next to each other and chair number 1 next to chair number 6. Each chair is occupied by exactly one of the representatives. The following conditions apply: Poirier sits immediately next to Neri. Londi sits immediately next to Manley, Neri, or both. Klosnik does not sit immediately next to Manley. If Osata sits immediately next to Poirier, Osata does not sit immediately next to Manley. Which one of the following seating arrangements of the six representatives in chairs 1 through 6 would NOT violate the stated conditions?\n",
            "Options:\n",
            "A) Klosnik, Poirier, Neri, Manley, Osata, Londi\n",
            "B) Klosnik, Londi, Manley, Poirier, Neri, Osata\n",
            "C) Klosnik, Londi, Manley, Osata, Poirier, Neri\n",
            "D) Klosnik, Osata, Poirier, Neri, Londi, Manley\n",
            "E) Klosnik, Neri, Londi, Osata, Manley, Poirier\n",
            "\n",
            "Please provide your reasoning first, limited to 100 words, and then conclusively state only your selected answer using the corresponding letter (A, B, C, D, or E).\n",
            "Reasoning: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     Question Num                                      Full Prompt 1  \\\n",
              "0  199106_2-G_1_1  \\nGiven the following question, analyze the op...   \n",
              "1  199106_2-G_1_2  \\nGiven the following question, analyze the op...   \n",
              "2  199106_2-G_1_3  \\nGiven the following question, analyze the op...   \n",
              "3  199106_2-G_1_4  \\nGiven the following question, analyze the op...   \n",
              "4  199106_2-G_1_5  \\nGiven the following question, analyze the op...   \n",
              "\n",
              "                                       Full Prompt 2  \n",
              "0  \\nBased on the reasoning above, Provide the co...  \n",
              "1  \\nBased on the reasoning above, Provide the co...  \n",
              "2  \\nBased on the reasoning above, Provide the co...  \n",
              "3  \\nBased on the reasoning above, Provide the co...  \n",
              "4  \\nBased on the reasoning above, Provide the co...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c6199c2-5584-436c-826c-c1d1ad7ea0fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question Num</th>\n",
              "      <th>Full Prompt 1</th>\n",
              "      <th>Full Prompt 2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>199106_2-G_1_1</td>\n",
              "      <td>\\nGiven the following question, analyze the op...</td>\n",
              "      <td>\\nBased on the reasoning above, Provide the co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>199106_2-G_1_2</td>\n",
              "      <td>\\nGiven the following question, analyze the op...</td>\n",
              "      <td>\\nBased on the reasoning above, Provide the co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>199106_2-G_1_3</td>\n",
              "      <td>\\nGiven the following question, analyze the op...</td>\n",
              "      <td>\\nBased on the reasoning above, Provide the co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>199106_2-G_1_4</td>\n",
              "      <td>\\nGiven the following question, analyze the op...</td>\n",
              "      <td>\\nBased on the reasoning above, Provide the co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>199106_2-G_1_5</td>\n",
              "      <td>\\nGiven the following question, analyze the op...</td>\n",
              "      <td>\\nBased on the reasoning above, Provide the co...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c6199c2-5584-436c-826c-c1d1ad7ea0fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8c6199c2-5584-436c-826c-c1d1ad7ea0fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8c6199c2-5584-436c-826c-c1d1ad7ea0fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2a434ab2-a23d-4e67-9ec3-76fdc3031953\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2a434ab2-a23d-4e67-9ec3-76fdc3031953')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2a434ab2-a23d-4e67-9ec3-76fdc3031953 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(new_dataset\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Question Num\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"199106_2-G_1_2\",\n          \"199106_2-G_1_5\",\n          \"199106_2-G_1_3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Full Prompt 1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\nGiven the following question, analyze the options, and provide a concise reasoning for your selected answer. Your reasoning should not exceed 100 words. After your explanation, clearly state your answer by choosing one of the options listed (A, B, C, D, or E).\\n\\nQuestion: Exactly six trade representatives negotiate a treaty: Klosnik, Londi, Manley, Neri, Osata, Poirier. There are exactly six chairs evenly spaced around a circular table. The chairs are numbered 1 through 6, with successively numbered chairs next to each other and chair number 1 next to chair number 6. Each chair is occupied by exactly one of the representatives. The following conditions apply: Poirier sits immediately next to Neri. Londi sits immediately next to Manley, Neri, or both. Klosnik does not sit immediately next to Manley. If Osata sits immediately next to Poirier, Osata does not sit immediately next to Manley. If Londi sits immediately next to Poirier, which one of the following is a pair of representatives who must sit immediately next to each other?\\nOptions:\\nA) Klosnik and Osata\\nB) Londi and Neri\\nC) Londi and Osata\\nD) Manley and Neri\\nE) Manley and Poirier\\n\\nPlease provide your reasoning first, limited to 100 words, and then conclusively state only your selected answer using the corresponding letter (A, B, C, D, or E).\\nReasoning: \",\n          \"\\nGiven the following question, analyze the options, and provide a concise reasoning for your selected answer. Your reasoning should not exceed 100 words. After your explanation, clearly state your answer by choosing one of the options listed (A, B, C, D, or E).\\n\\nQuestion: Exactly six trade representatives negotiate a treaty: Klosnik, Londi, Manley, Neri, Osata, Poirier. There are exactly six chairs evenly spaced around a circular table. The chairs are numbered 1 through 6, with successively numbered chairs next to each other and chair number 1 next to chair number 6. Each chair is occupied by exactly one of the representatives. The following conditions apply: Poirier sits immediately next to Neri. Londi sits immediately next to Manley, Neri, or both. Klosnik does not sit immediately next to Manley. If Osata sits immediately next to Poirier, Osata does not sit immediately next to Manley. If Londi sits immediately next to Manley, then which one of the following is a complete and accurate list of representatives any one of whom could also sit immediately next to Londi?\\nOptions:\\nA) Klosnik\\nB) Klosnik, Neri\\nC) Neri, Poirier\\nD) Klosnik, Osata, Poirier\\nE) Klosnik, Neri, Osata, Poirier\\n\\nPlease provide your reasoning first, limited to 100 words, and then conclusively state only your selected answer using the corresponding letter (A, B, C, D, or E).\\nReasoning: \",\n          \"\\nGiven the following question, analyze the options, and provide a concise reasoning for your selected answer. Your reasoning should not exceed 100 words. After your explanation, clearly state your answer by choosing one of the options listed (A, B, C, D, or E).\\n\\nQuestion: Exactly six trade representatives negotiate a treaty: Klosnik, Londi, Manley, Neri, Osata, Poirier. There are exactly six chairs evenly spaced around a circular table. The chairs are numbered 1 through 6, with successively numbered chairs next to each other and chair number 1 next to chair number 6. Each chair is occupied by exactly one of the representatives. The following conditions apply: Poirier sits immediately next to Neri. Londi sits immediately next to Manley, Neri, or both. Klosnik does not sit immediately next to Manley. If Osata sits immediately next to Poirier, Osata does not sit immediately next to Manley. If Klosnik sits directly between Londi and Poirier, then Manley must sit directly between\\nOptions:\\nA) Londi and Neri\\nB) Londi and Osata\\nC) Neri and Osata\\nD) Neri and Poirier\\nE) Osata and Poirier\\n\\nPlease provide your reasoning first, limited to 100 words, and then conclusively state only your selected answer using the corresponding letter (A, B, C, D, or E).\\nReasoning: \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Full Prompt 2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\nBased on the reasoning above, Provide the correct answer and the likelihood that each option is correct from 0.0 to 1.0 in a JSON format. The four probabilities should sum to 1.0. For example:\\n\\n{\\n'Answer': <Your answer choice here, as a single letter and nothing else.>\\n'A': <Probability choice A is correct. As a float from 0.0 to 1.0>,\\n'B': <Probability choice B is correct. As a float from 0.0 to 1.0>,\\n'C': <Probability choice C is correct. As a float from 0.0 to 1.0>,\\n'D': <Probability choice D is correct. As a float from 0.0 to 1.0>,\\n'E': <Probability choice E is correct. As a float from 0.0 to 1.0>\\n}\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## %%%%\n",
        "## Minor edits needed to generalize to other datasets\n",
        "## %%%%\n",
        "\n",
        "def format_df(df):\n",
        "  ## Takes in a dataframe in the form:\n",
        "  ## | Question Number | Question | Option A | Option B | ... | Correct Answer Letter |\n",
        "  ## |     (Int)       |     (Str)     |  (Str)   |  (Str)   |     |       (Char)          |\n",
        "  ##\n",
        "  ## Returns a dataframe in the form:\n",
        "  ## | Question Number | Full Prompt 1 | Full Prompt 2 |\n",
        "  ## |     (Int)       |    (Str)      |    (Str)      |\n",
        "\n",
        "  columns = df.columns\n",
        "  num_options = columns.str.contains('Option').astype(int).sum()\n",
        "\n",
        "  #----------------------------------------------------------------------------#\n",
        "  ## Check if DF is formatted properly\n",
        "  error_text = f'''Make sure dataframe is in following format:\n",
        "  | Question Number | Question | Option A | Option B | ... | Correct Answer Letter |\n",
        "  |     (Int)       |     (Str)     |  (Str)   |  (Str)   |     |       (Char)          |\n",
        "\n",
        "  The current format of Dataframe is: {columns}\n",
        "  '''\n",
        "  ['Question Number', 'Question', 'Correct Answer Letter']\n",
        "  if num_options < 2:\n",
        "    raise Exception(error_text)\n",
        "\n",
        "  #----------------------------------------------------------------------------#\n",
        "  ## Initialize Output dataframe:\n",
        "  header = ['Question Num', 'Full Prompt 1', 'Full Prompt 2']\n",
        "  output_df = pd.DataFrame(columns = header)\n",
        "\n",
        "  #----------------------------------------------------------------------------#\n",
        "\n",
        "  ## Format questions for benchmark\n",
        "  letters = ['A', 'B', 'C', 'D', 'E']\n",
        "  options = ['Option A', 'Option B', 'Option C', 'Option D', 'Option E']\n",
        "\n",
        "  for i in range(len(df)):\n",
        "    question = df['Question'][i]\n",
        "    option_text = df[options[:num_options]].iloc[i].to_list()\n",
        "\n",
        "    ## Prompt for specific question\n",
        "    new_prompt = sys_prompt_temp1.replace('${Question}', question)\n",
        "    for j in range(num_options): ## This for loop allows for dynamic question amounts\n",
        "        new_prompt = new_prompt.replace(f'${{Option {letters[j]}}}', str(option_text[j]))\n",
        "\n",
        "\n",
        "    ## Add formatted prompts.\n",
        "    ## Note that this is formatted to llama so changes may be needed down the line.\n",
        "    prompts1 = (new_prompt.split('<Your concise reasoning here. Max 100 words>')[0]) ## Specific prompt for question\n",
        "\n",
        "    prompts2 = (sys_prompt_temp2) ## Generic prompt for question confidence\n",
        "    output_df.loc[i] = [df['Question Number'].iloc[i], prompts1, prompts2]\n",
        "\n",
        "  return output_df\n"
      ],
      "metadata": {
        "id": "pPVxES4WVeru"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Try it on GPT\n",
        "\n",
        "test_reasoning, test_answer = my_gpt.GetRAC(prompt = new_test_prompt)\n",
        "print(f'Reasoning: {test_reasoning}\\nAnswer: {test_answer}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7P_QrxiLvWPx",
        "outputId": "71529f1a-e3bd-42ef-9c1d-3f92c0746577"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reasoning: Looking at the conditions, we can see that option A violates the condition that Klosnik does not sit immediately next to Manley. Option B violates the condition that Londi sits immediately next to Manley, Neri, or both. Option C violates the condition that Osata does not sit immediately next to Manley if Osata sits immediately next to Poirier. Option D does not violate any of the conditions. Option E violates the condition that Poirier sits immediately next to Neri\n",
            "Answer: {\n",
            "'Answer': 'D',\n",
            "'A': 0.0,\n",
            "'B': 0.0,\n",
            "'C': 0.0,\n",
            "'D': 1.0,\n",
            "'E': 0.0\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_row = pd.DataFrame([{\n",
        "            'Question ID': 42,\n",
        "            'Question': \"This is a question\", # You might want to store the original question here\n",
        "            'Answer': \"This is a JSON\", # Or just the extracted answer part\n",
        "            'Reasoning': \"Some reasoning\"\n",
        "        }])\n",
        "\n",
        "my_gpt.results = my_gpt.results._append(new_row, ignore_index=True)\n",
        "my_gpt.results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "ViJShKbW6dg9",
        "outputId": "27f64694-8e46-4cdb-e14d-f3c0da193f13"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Question ID            Question          Answer       Reasoning\n",
              "0          42  This is a question  This is a JSON  Some reasoning"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dbd22189-e2fe-4d25-89e5-dddbe9637b0c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question ID</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>Reasoning</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>42</td>\n",
              "      <td>This is a question</td>\n",
              "      <td>This is a JSON</td>\n",
              "      <td>Some reasoning</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dbd22189-e2fe-4d25-89e5-dddbe9637b0c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dbd22189-e2fe-4d25-89e5-dddbe9637b0c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dbd22189-e2fe-4d25-89e5-dddbe9637b0c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"my_gpt\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Question ID\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 42,\n        \"max\": 42,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          42\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"This is a question\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"This is a JSON\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Reasoning\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Some reasoning\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def test_models_sequential_by_question(df, models, debug=False):\n",
        "    \"\"\"\n",
        "    Tests a list of models on a given dataset sequentially,\n",
        "    iterating through questions and then models for each question.\n",
        "    Includes a debug mode to process only the first 10 questions.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The dataset containing questions and prompts.\n",
        "        models (list): A list of initialized model objects.\n",
        "        debug (bool): If True, only process the first 10 questions.\n",
        "    \"\"\"\n",
        "    print(\"Clearing previous results for each model...\")\n",
        "    for model in models:\n",
        "        model.results = pd.DataFrame(columns=['Question ID', 'Question', 'Answer', 'Reasoning'])\n",
        "        print(f\"  Cleared results for {model.name}\")\n",
        "    print(\"Starting sequential testing (by question)...\")\n",
        "\n",
        "    # Determine the number of questions to process\n",
        "    num_questions_to_process = 10 if debug else len(df)\n",
        "\n",
        "    # Iterate over questions first\n",
        "    for index, row in df.head(num_questions_to_process).iterrows():\n",
        "        question_num = row['Question Num']\n",
        "        prompt = row['Full Prompt 1']\n",
        "        print(f\"\\nProcessing Question {question_num}\")\n",
        "\n",
        "        # Iterate over models for the current question\n",
        "        for model in models:\n",
        "            try:\n",
        "                print(f\"  Testing with model: {model.name}\")\n",
        "                # Call GetRAC and add the result to the model's self.results\n",
        "                reasoning, answer_confidence = model.GetRAC(prompt=prompt)\n",
        "\n",
        "                # Add the results to the model's self.results DataFrame\n",
        "                new_row = pd.DataFrame([{\n",
        "                    'Question ID': question_num,\n",
        "                    'Question': prompt,\n",
        "                    'Answer': answer_confidence,\n",
        "                    'Reasoning': reasoning\n",
        "                }])\n",
        "                model.results = model.results._append(new_row, ignore_index=True)\n",
        "                filename = f\"{model.name.replace('/', '_').replace('-', '_')}_test_results.csv\"\n",
        "                model.results.to_csv(filename, index=False)\n",
        "            except Exception as e:\n",
        "                print(f\"  Error testing {model.name} on Question {question_num}: {e}\")\n",
        "                # Optionally add an error entry to the results\n",
        "                error_row = pd.DataFrame([{\n",
        "                    'Question ID': question_num,\n",
        "                    'Question': prompt,\n",
        "                    'Answer': f\"Error: {e}\",\n",
        "                    'Reasoning': f\"Error: {e}\"\n",
        "                }])\n",
        "                model.results = model.results._append(error_row, ignore_index=True)\n",
        "                filename = f\"{model.name.replace('/', '_').replace('-', '_')}_test_results.csv\"\n",
        "                model.results.to_csv(filename, index=False)\n",
        "    print(\"\\nSequential testing complete.\")\n",
        "\n",
        "    # After processing all questions, save the results for each model\n",
        "    for model in models:\n",
        "        filename = f\"{model.name.replace('/', '_').replace('-', '_')}_test_results.csv\"\n",
        "        model.results.to_csv(filename, index=False)\n",
        "        print(f\"Results for {model.name} saved to '{filename}'\")\n",
        "\n",
        "\n",
        "## Testing with debug = True\n",
        "test_models_sequential_by_question(new_dataset, closed_models, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIdV82WFAK4i",
        "outputId": "33303705-93de-458d-e6f4-710bc8950daa"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clearing previous results for each model...\n",
            "  Cleared results for gpt-4\n",
            "  Cleared results for gpt-3.5-turbo\n",
            "  Cleared results for claude-3-haiku-20240307\n",
            "  Cleared results for gemini-1.5-flash\n",
            "Starting sequential testing (by question)...\n",
            "\n",
            "Processing Question 199106_2-G_1_1\n",
            "  Testing with model: gpt-4\n",
            "  Testing with model: gpt-3.5-turbo\n",
            "  Testing with model: claude-3-haiku-20240307\n",
            "  Error testing claude-3-haiku-20240307 on Question 199106_2-G_1_1: cannot unpack non-iterable NoneType object\n",
            "  Testing with model: gemini-1.5-flash\n",
            "  Error testing gemini-1.5-flash on Question 199106_2-G_1_1: cannot unpack non-iterable NoneType object\n",
            "\n",
            "Processing Question 199106_2-G_1_2\n",
            "  Testing with model: gpt-4\n",
            "  Testing with model: gpt-3.5-turbo\n",
            "  Testing with model: claude-3-haiku-20240307\n",
            "  Error testing claude-3-haiku-20240307 on Question 199106_2-G_1_2: cannot unpack non-iterable NoneType object\n",
            "  Testing with model: gemini-1.5-flash\n",
            "  Error testing gemini-1.5-flash on Question 199106_2-G_1_2: cannot unpack non-iterable NoneType object\n",
            "\n",
            "Processing Question 199106_2-G_1_3\n",
            "  Testing with model: gpt-4\n",
            "  Testing with model: gpt-3.5-turbo\n",
            "  Testing with model: claude-3-haiku-20240307\n",
            "  Error testing claude-3-haiku-20240307 on Question 199106_2-G_1_3: cannot unpack non-iterable NoneType object\n",
            "  Testing with model: gemini-1.5-flash\n",
            "  Error testing gemini-1.5-flash on Question 199106_2-G_1_3: cannot unpack non-iterable NoneType object\n",
            "\n",
            "Processing Question 199106_2-G_1_4\n",
            "  Testing with model: gpt-4\n",
            "  Testing with model: gpt-3.5-turbo\n",
            "  Testing with model: claude-3-haiku-20240307\n",
            "  Error testing claude-3-haiku-20240307 on Question 199106_2-G_1_4: cannot unpack non-iterable NoneType object\n",
            "  Testing with model: gemini-1.5-flash\n",
            "  Error testing gemini-1.5-flash on Question 199106_2-G_1_4: cannot unpack non-iterable NoneType object\n",
            "\n",
            "Processing Question 199106_2-G_1_5\n",
            "  Testing with model: gpt-4\n",
            "  Testing with model: gpt-3.5-turbo\n",
            "  Testing with model: claude-3-haiku-20240307\n",
            "  Error testing claude-3-haiku-20240307 on Question 199106_2-G_1_5: cannot unpack non-iterable NoneType object\n",
            "  Testing with model: gemini-1.5-flash\n",
            "  Error testing gemini-1.5-flash on Question 199106_2-G_1_5: cannot unpack non-iterable NoneType object\n",
            "\n",
            "Processing Question 199106_2-G_1_6\n",
            "  Testing with model: gpt-4\n",
            "  Testing with model: gpt-3.5-turbo\n",
            "  Testing with model: claude-3-haiku-20240307\n",
            "  Error testing claude-3-haiku-20240307 on Question 199106_2-G_1_6: cannot unpack non-iterable NoneType object\n",
            "  Testing with model: gemini-1.5-flash\n",
            "  Error testing gemini-1.5-flash on Question 199106_2-G_1_6: cannot unpack non-iterable NoneType object\n",
            "\n",
            "Processing Question 199106_2-G_1_7\n",
            "  Testing with model: gpt-4\n",
            "  Testing with model: gpt-3.5-turbo\n",
            "  Testing with model: claude-3-haiku-20240307\n",
            "  Error testing claude-3-haiku-20240307 on Question 199106_2-G_1_7: cannot unpack non-iterable NoneType object\n",
            "  Testing with model: gemini-1.5-flash\n",
            "  Error testing gemini-1.5-flash on Question 199106_2-G_1_7: cannot unpack non-iterable NoneType object\n",
            "\n",
            "Processing Question 199106_2-G_2_8\n",
            "  Testing with model: gpt-4\n",
            "  Testing with model: gpt-3.5-turbo\n",
            "  Testing with model: claude-3-haiku-20240307\n",
            "  Error testing claude-3-haiku-20240307 on Question 199106_2-G_2_8: cannot unpack non-iterable NoneType object\n",
            "  Testing with model: gemini-1.5-flash\n",
            "  Error testing gemini-1.5-flash on Question 199106_2-G_2_8: cannot unpack non-iterable NoneType object\n",
            "\n",
            "Processing Question 199106_2-G_2_9\n",
            "  Testing with model: gpt-4\n",
            "  Testing with model: gpt-3.5-turbo\n",
            "  Testing with model: claude-3-haiku-20240307\n",
            "  Error testing claude-3-haiku-20240307 on Question 199106_2-G_2_9: cannot unpack non-iterable NoneType object\n",
            "  Testing with model: gemini-1.5-flash\n",
            "  Error testing gemini-1.5-flash on Question 199106_2-G_2_9: cannot unpack non-iterable NoneType object\n",
            "\n",
            "Processing Question 199106_2-G_2_10\n",
            "  Testing with model: gpt-4\n",
            "  Testing with model: gpt-3.5-turbo\n",
            "  Testing with model: claude-3-haiku-20240307\n",
            "  Error testing claude-3-haiku-20240307 on Question 199106_2-G_2_10: cannot unpack non-iterable NoneType object\n",
            "  Testing with model: gemini-1.5-flash\n",
            "  Error testing gemini-1.5-flash on Question 199106_2-G_2_10: cannot unpack non-iterable NoneType object\n",
            "\n",
            "Sequential testing complete.\n",
            "Results for gpt-4 saved to 'gpt_4_test_results.csv'\n",
            "Results for gpt-3.5-turbo saved to 'gpt_3.5_turbo_test_results.csv'\n",
            "Results for claude-3-haiku-20240307 saved to 'claude_3_haiku_20240307_test_results.csv'\n",
            "Results for gemini-1.5-flash saved to 'gemini_1.5_flash_test_results.csv'\n"
          ]
        }
      ]
    }
  ]
}